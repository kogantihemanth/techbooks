
<!DOCTYPE html>
<html>

<head>
	<title>something</title>
	<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.js"></script>
	<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO"
		crossorigin="anonymous">
</head>

<body>
	<nav class="navbar navbar-dark bg-dark">
		<a href="#" class="navbar-brand">The quizzes</a>
		<p class="text-info mb-0 mr-0">选择题的选项由上至下分别对应a,b,c,d,e...以此类推</p>
	</nav>
	<div class="container-fluid">
		<div class="row">
			<nav class="col-3 navbar navbar-light bg-light" style="align-items: start">
				<div class="sidebar-sticky">
					<a class="navbar-brand" href="#">Chapter</a>
					<nav class="nav nav-pills flex-column" style="font-size: 14px">
						<ul class="list-group list-group-flush">

						</ul>
					</nav>

				</div>
			</nav>
			<div class="col-9" style="background-color: #f3ffc4">
				<div class="container">

				</div>
			</div>

		</div>


	</div>

	<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49"
		crossorigin="anonymous"></script>
	<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy"
		crossorigin="anonymous"></script>
	<script type="text/javascript">
		var None = null;
		var True = true
		$(document).ready(function () {
	
				var json_data = [{'quizzes': [{'type': 'practice-test', 'quiz_data': {'count': 65, 'results': [{'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a well-funded financial startup that has a cryptocurrency exchange platform hosted in a fleet of auto-scaled EC2 instances placed in two different Availability Zones and then placed behind an Application Load Balancer. The cryptocurrency exchange platform uses an S3 bucket to store media files and DynamoDB for managing user registration and transaction data. As part of the mandatory financial compliance, they are required to provide comprehensive logs of all API calls made from the AWS resources. As a Solutions Architect, you recommended to use Amazon CloudTrail to meet the requirement, however, your manager is worried about the scope of the logs that CloudTrail can cover.\xa0 \xa0In which places can CloudTrail provide event history for all API calls?', '_class': 'assessment', 'created': '2018-11-21T07:22:45Z', 'id': 6180418, 'original_assessment_id': 2566848, 'section': 'CloudTrail', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>AWS CloudTrail is a service that enables governance, compliance, operational auditing, and risk auditing of your AWS account. With CloudTrail, you can log, continuously monitor, and retain account activity related to actions across your AWS infrastructure.</p> <p>CloudTrail provides event history of your AWS account activity, including actions taken through the AWS Management Console, AWS SDKs, command line tools, and other AWS services. This event history simplifies security analysis, resource change tracking, and troubleshooting.</p> <p>&nbsp;</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/cloudtrail/">https://aws.amazon.com/cloudtrail/</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['<p>Command line tools</p>', '<p>AWS SDK</p>', '<p>AWS Console</p>', '<p>Command line tools, AWS SDK, and AWS Console</p>', '<p>Command line tools and AWS SDK only</p>', '<p>Command line tools and AWS Console only</p>'], 'question': '<p>You are working for a well-funded financial startup that has a cryptocurrency exchange platform hosted in a fleet of auto-scaled EC2 instances placed in two different Availability Zones and then placed behind an Application Load Balancer. The cryptocurrency exchange platform uses an S3 bucket to store media files and DynamoDB for managing user registration and transaction data. As part of the mandatory financial compliance, they are required to provide comprehensive logs of all API calls made from the AWS resources. As a Solutions Architect, you recommended to use Amazon CloudTrail to meet the requirement, however, your manager is worried about the scope of the logs that CloudTrail can cover.\xa0 \xa0</p><p>In which places can CloudTrail provide event history for all API calls?</p>'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:22:45Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'An online health record system that provides centralized health records of all citizens has been migrated to AWS. The system is hosted in one large EBS-backed EC2 instance which hosts both its web server and database.\xa0 \xa0Which of the following does not happen when you stop a running EBS-backed EC2 instance?', '_class': 'assessment', 'created': '2018-11-21T07:22:45Z', 'id': 6180420, 'original_assessment_id': 2566850, 'section': 'EC2', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>All of these happen when you stop a running EBS-backed EC2 instance except for option 4. The instance retains its associated Elastic IP addresses if it is in the EC2-VPC platform and not on&nbsp;EC2-Classic.</p> <p>When you stop a running instance, the following happens:</p> <div> <ul> <li>The instance performs a normal shutdown and stops running; its status changes to&nbsp;<code>stopping</code>&nbsp;and then&nbsp;<code>stopped</code>.</li> <li>Any Amazon EBS volume remains attached to the instance, and their data persists.</li> <li>Any data stored in the RAM of the host computer or the instance store volumes of the host computer are gone.</li> <li>In most cases, the instance is migrated to a new underlying host computer when it\'s started.</li> <li>EC2-Classic: AWS releases the public and private IPv4 addresses for the instance when you stop the instance, and assign new ones when you restart it.</li> <li>EC2-VPC: The instance retains its private IPv4 addresses and any IPv6 addresses when stop and restart. AWS releases the public IPv4 address and assigns a new one when you restart it.</li> <li>EC2-Classic: AWS disassociates any Elastic IP address that\'s associated with the instance. You\'re charged for Elastic IP addresses that aren\'t associated with an instance. When you restart the instance, you must associate the Elastic IP address with the instance; AWS doesn\'t do this automatically.</li> <li>EC2-VPC: The instance retains its associated Elastic IP addresses. You\'re charged for any Elastic IP addresses associated with a stopped instance</li> </ul> </div> <p><strong>Reference:</strong></p> <p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Stop_Start.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Stop_Start.html</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['Any Amazon EBS volumes remain attached to the instance, and their data persists.', "<p>In most cases, the instance is migrated to a new underlying host computer when it's restarted.\xa0 </p>", '<p>Any data stored in the RAM of the underlying host computer or the instance store volumes of the host computer are gone.\xa0 </p>', 'If it is in the EC2-Classic platform, the instance retains its associated Elastic IP addresses.'], 'question': '<p>An online health record system that provides centralized health records of all citizens has been migrated to AWS. The system is hosted in one large EBS-backed EC2 instance which hosts both its web server and database.\xa0 \xa0</p><p>Which of the following does not happen when you stop a running EBS-backed EC2 instance?\xa0 </p>'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:22:45Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You started a tech startup that provides online training and software development courses to various students across the globe. Your team has developed an online portal in AWS where the students can log into and access the courses they subscribed to. Since you are in the early phase of the startup and the funding is still hard to come by, which service can help you manage the budgets for all your AWS resources?', '_class': 'assessment', 'created': '2018-11-21T07:22:45Z', 'id': 6180422, 'original_assessment_id': 2566852, 'section': 'Billing and Cost Management', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>AWS Budgets gives you the ability to set custom budgets that alert you when your costs or usage exceed (or are forecasted to exceed) your budgeted amount.</p> <p>Budgets can be tracked at the monthly, quarterly, or yearly level, and you can customize the start and end dates. You can further refine your budget to track costs associated with multiple dimensions, such as AWS service, linked account, tag, and others. Budget alerts can be sent via email and/or Amazon Simple Notification Service (SNS) topic.</p> <p>You can also use AWS Budgets to set a custom reservation utilization target and receive alerts when your utilization drops below the threshold you define. RI utilization alerts support Amazon EC2, Amazon RDS, Amazon Redshift, and Amazon ElastiCache reservations.</p> <p>Budgets can be created and tracked from the AWS Budgets dashboard or via the Budgets API.</p> <p>&nbsp;</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/aws-cost-management/aws-budgets/">https://aws.amazon.com/aws-cost-management/aws-budgets/</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['Cost Explorer', 'Cost Allocation Tags', 'AWS Budgets', 'Payment History'], 'question': '<p>You started a tech startup that provides online training and software development courses to various students across the globe. Your team has developed an online portal in AWS where the students can log into and access the courses they subscribed to. <br><br>Since you are in the early phase of the startup and the funding is still hard to come by, which service can help you manage the budgets for all your AWS resources?</p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:22:45Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are trying to establish an SSH connection to a newly created Amazon EC2 instance using the PuTTY tool. However, you are getting the following error message: Error: No supported authentication methods availableWhat steps should you take to fix this issue? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:22:45Z', 'id': 6180424, 'original_assessment_id': 2566854, 'section': 'EC2', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>If you use PuTTY to connect to your instance via SSH and get either of the following errors,&nbsp;<code>Error: Server refused our key</code>&nbsp;or&nbsp;<code>Error: No supported authentication methods available</code>, verify that you are connecting with the appropriate user name for your AMI. Enter the user name in the&nbsp;<strong>User name</strong>&nbsp;box in the&nbsp;<strong>PuTTY Configuration</strong>&nbsp;window.</p> <p>The appropriate user names are as follows:</p> <div> <ul> <li>For an Amazon Linux AMI, the user name is&nbsp;<code>ec2-user</code>.</li> <li>For a RHEL AMI, the user name is&nbsp;<code>ec2-user</code>&nbsp;or&nbsp;<code>root</code>.</li> <li>For an Ubuntu AMI, the user name is&nbsp;<code>ubuntu</code>&nbsp;or&nbsp;<code>root</code>.</li> <li>For a Centos AMI, the user name is&nbsp;<code>centos</code>.</li> <li>For a Debian AMI, the user name is&nbsp;<code>admin</code>&nbsp;or&nbsp;<code>root</code>.</li> <li>For a Fedora AMI, the user name is&nbsp;<code>ec2-user</code>.</li> <li>For a SUSE AMI, the user name is&nbsp;<code>ec2-user</code>&nbsp;or&nbsp;<code>root</code>.</li> <li>Otherwise, if&nbsp;<code>ec2-user</code>&nbsp;and&nbsp;<code>root</code>&nbsp;don\'t work, check with the AMI provider.</li> </ul> </div> <p>You should also verify that your private key (.pem) file has been correctly converted to the format recognized by PuTTY (.ppk).&nbsp;</p> <p>Options 2 and 4 are incorrect because both an IAM user and&nbsp;IAM role policy have nothing to do with this issue.&nbsp;</p> <p>Option 5 is incorrect because you don\'t need to wait an hour in order to connect to a new EC2 instance as you can immediately connect to it once it is created.</p> <p>Option 6 is incorrect because there is no <code>Enable SSH Connection</code> feature in EC2 service.</p> <p><code></code></p> <p><strong>Reference:</strong></p> <p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/TroubleshootingInstancesConnecting.html#TroubleshootingInstancesConnectingPuTTY">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/TroubleshootingInstancesConnecting.html#TroubleshootingInstancesConnectingPuTTY</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Verify if your private key (.pem) file has been correctly converted to the format recognized by PuTTY (.ppk).', 'Verify that your IAM user policy has permission to launch Amazon EC2 instances.', 'Verify that you are connecting with the appropriate user name for your AMI such as <code>ec2-user</code> for Linux AMI, <code>centos</code> for Centos AMI or <code>admin</code> for Debian AMI', 'Verify that the Amazon EC2 Instance was launched with the proper IAM role.', 'Verify that you had waited at least 1 hour after the EC2 instance was created before connecting via SSH.', 'Verify that the <code>Enable SSH Connection</code> feature is enabled in EC2 instance.'], 'question': '<p>You are trying to establish an SSH connection to a newly created Amazon EC2 instance using the PuTTY tool. However, you are getting the following error message: <br><br><code>Error: No supported authentication methods available</code><br><br>What steps should you take to fix this issue? (Choose 2)</p>'}, 'related_lectures': [], 'correct_response': ['a', 'c'], 'updated': '2018-11-21T07:22:45Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A financial application that calculates accruals, interests, and other data is hosted on a fleet of Spot EC2 instances that are configured with Auto Scaling. The application is used by an external reporting application that provides the total calculation for each user account and transaction. You used CloudWatch to automatically monitor the EC2 instance without manually checking the server for high CPU Utilization or crashes.\xa0 \xa0What is the time period of data that Amazon CloudWatch receives and aggregates from EC2 by default?', '_class': 'assessment', 'created': '2018-11-21T07:22:45Z', 'id': 6180426, 'original_assessment_id': 2566856, 'section': 'CloudWatch', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>By default, your instance is enabled for basic monitoring. You can optionally enable detailed monitoring. After you enable detailed monitoring, the Amazon EC2 console displays monitoring graphs with a 1-minute period for the instance. The following table describes basic and detailed monitoring for instances.</p> <ul> <li><strong>Basic</strong> -&nbsp;Data is available automatically in 5-minute periods at no charge.</li> <li><strong>Detailed</strong> -&nbsp;Data is available in 1-minute periods for an additional cost. To get this level of data, you must specifically enable it for the instance. For the instances where you\'ve enabled detailed monitoring, you can also get aggregated data across groups of similar instances.</li> </ul> <p>&nbsp;</p> <p><strong>References:<strong></p> <p><a href="https://aws.amazon.com/cloudwatch/faqs/">https://aws.amazon.com/cloudwatch/faqs/</a></p> <p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-cloudwatch-new.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-cloudwatch-new.html</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', '', ''], 'answers': ['One second', 'Five seconds', 'One minute', 'Three minutes', 'Five minutes'], 'question': '<p>A financial application that calculates accruals, interests, and other data is hosted on a fleet of Spot EC2 instances that are configured with Auto Scaling. The application is used by an external reporting application that provides the total calculation for each user account and transaction. You used CloudWatch to automatically monitor the EC2 instance without manually checking the server for high CPU Utilization or crashes.\xa0 \xa0</p><p>What is the time period of data that Amazon CloudWatch receives and aggregates from EC2 by default?\xa0 </p>'}, 'related_lectures': [], 'correct_response': ['e'], 'updated': '2018-11-21T07:22:45Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are a Solutions Architect of a bank, designing various CloudFormation templates for a new online trading platform that your department will build.How much does it cost to use CloudFormation templates?', '_class': 'assessment', 'created': '2018-11-21T07:22:45Z', 'id': 6180428, 'original_assessment_id': 2566858, 'section': 'Cloudformation', 'prompt': {'explanation': '<p>There is no additional charge for AWS CloudFormation. You only pay for the AWS resources that are created (e.g. Amazon EC2 instances, Elastic Load Balancing load balancers, etc.)</p><br /><p>References:</p><p><a href="https://aws.amazon.com/cloudformation/faqs/" target="_blank" rel="noopener">https://aws.amazon.com/cloudformation/faqs/</a>', 'answers': ['There is no additional charge for AWS CloudFormation. You only pay for the AWS resources that are created.', 'The cost is based on the file size of the template.', 'It is charged per hour.', 'The cost is based on the size of the template.'], 'question': 'You are a Solutions Architect of a bank, designing various CloudFormation templates for a new online trading platform that your department will build.<br /><br />How much does it cost to use CloudFormation templates?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:22:45Z'}, {'assessment_type': 'multi-select', 'question_plain': 'One of the DevOps engineers in your team has deployed an EBS-backed On-Demand EC2 instance with automated snapshots to host a front-end application written in Angular. Your company just recently hired a new manager to handle the new web application but he is not knowledgeable enough about AWS cloud computing. The DevOps engineer asked for your help in explaining the current architecture to the new manager. \n\nWhich of the following statements are correct regarding EBS volumes and snapshots? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:22:45Z', 'id': 6180430, 'original_assessment_id': 2566860, 'section': 'EBS', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>If your current-generation Amazon EBS volume is attached to a current-generation EC2 instance type, you can increase its size, change its volume type, or (for an&nbsp;<code class="code">io1</code>&nbsp;volume) adjust its IOPS performance, all without detaching it from the instance. You can apply these changes to detached volumes as well.&nbsp;</p> <p>EBS snapshots broadly support EBS encryption for these scenarios:</p> <ul> <li>-Snapshots of encrypted volumes are automatically encrypted.</li> <li>-Volumes that are created from encrypted snapshots are automatically encrypted.</li> <li>-When you copy an unencrypted snapshot that you own, you can encrypt it during the copy process.</li> <li>-When you copy an encrypted snapshot that you own, you can reencrypt it with a different key during the copy process.</li> </ul> <p>&nbsp;</p> <p><strong>References:&nbsp;</strong></p> <p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-modify-volume.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-modify-volume.html</a></p> <p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['EBS volumes are resizable.', 'Snapshots of encrypted volumes are not automatically encrypted.', 'You can change the size of the volume even when it is attached to an instance.', 'You can only change the size of the volume if it is not attached to an instance.', 'Volumes that are created from encrypted snapshots are automatically encrypted.', '<p>EBS volumes are not resizable.</p>'], 'question': '<p>One of the DevOps engineers in your team has deployed an EBS-backed On-Demand EC2 instance with automated snapshots to host a front-end application written in Angular. Your company just recently hired a new manager to handle the new web application but he is not knowledgeable enough about AWS cloud computing. The DevOps engineer asked for your help in explaining the current architecture to the new manager. </p>\n\n<p>Which of the following statements are correct regarding EBS volumes and snapshots? (Choose 3)</p>'}, 'related_lectures': [], 'correct_response': ['a', 'c', 'e'], 'updated': '2018-11-21T07:22:45Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'There is a new DevOps engineer hired in your team that just recently graduated from college. She has a basic understanding of cloud computing and minimal AWS experience. Your manager instructed you to mentor the new starter and specifically teach the difference between Infrastructure, Container, and Abstract services in AWS. The new hire asked you which Infrastructure service launches a number of Amazon EC2 instances as part of its service and then allows the customer to retain full admin privileges of those underlying EC2 instances. \n\nWhat answer will you give to the new hire?', '_class': 'assessment', 'created': '2018-11-21T07:22:45Z', 'id': 6180432, 'original_assessment_id': 2566862, 'section': 'EC2', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>Amazon EMR is a web service that enables businesses, researchers, data analysts, and developers to easily and cost-effectively process vast amounts of data. It utilizes a hosted Hadoop framework running on the web-scale infrastructure of Amazon Elastic Compute Cloud (Amazon EC2) and Amazon Simple Storage Service (Amazon S3).</p> <p>This means that Amazon EMR launches a number of EC2 instances for its Hadoop data processing engine. These created EC2 instances are accessible and manageable by the customer, including full administrative privileges.</p> <p>Amazon ElastiCache and Amazon DynamoDB are incorrect because both of them are fully managed services. Remember that the term <em>fully managed</em> means that it is AWS that fully manages all of the required resources of that service, including the needed server, OS patching, scaling and many others. Hence, the customer does not have access to the underlying EC2 instances and other resources of that service.</p> <p>Amazon Relational Database Service is a <em>managed</em> database service, which means that you have partial control of the underlying database server, unlike a <em>fully</em> managed service which AWS totally controls. However, customers do not have full admin privileges to the underlying resources of RDS which renders this option incorrect.</p> <p>&nbsp;</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/emr/faqs/">https://aws.amazon.com/emr/faqs/</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['Amazon Relational Database Service', 'Amazon Elastic Map Reduce', 'Amazon ElastiCache', 'Amazon DynamoDB'], 'question': '<p>There is a new DevOps engineer hired in your team that just recently graduated from college. She has a basic understanding of cloud computing and minimal AWS experience. Your manager instructed you to mentor the new starter and specifically teach the difference between Infrastructure, Container, and Abstract services in AWS. The new hire asked you which Infrastructure service launches a number of Amazon EC2 instances as part of its service and then allows the customer to retain full admin privileges of those underlying EC2 instances. </p>\n\n<p>What answer will you give to the new hire?</p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:22:45Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have one security group associated with 10 On-Demand EC2 instances. You configured the security group to allow all inbound SSH traffic and then right after that, you created two new EC2 instances in the same security group. When will be the changes be applied to the EC2 instances?', '_class': 'assessment', 'created': '2018-11-21T07:22:45Z', 'id': 6180434, 'original_assessment_id': 2566864, 'section': 'Security', 'prompt': {'explanation': '<p>Changes made in a Security Group is immediately implemented to all associated EC2 instances.</p><p>A&nbsp;<em>security group</em>&nbsp;acts as a virtual firewall for your instance to control inbound and outbound traffic. When you launch an instance in a VPC, you can assign up to five security groups to the instance. Security groups act at the instance level, not the subnet level. Therefore, each instance in a subnet in your VPC could be assigned to a different set of security groups. If you don\'t specify a particular group at launch time, the instance is automatically assigned to the default security group for the VPC.</p><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html</a></p>', 'answers': ['Immediately to all 12 instances in the security group.', 'Immediately to the new instances only.', 'Immediately to the new instances, but not for the old ones which must be restarted before the changes take effect.', 'The changes will apply to all 12 instances after an hour when the propagation is complete.'], 'question': 'You have one security group associated with 10 On-Demand EC2 instances. You configured the security group to allow all inbound SSH traffic and then right after that, you created two new EC2 instances in the same security group. <br /><br />When will be the changes be applied to the EC2 instances? '}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:22:45Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'The company that you are working for has a highly available architecture consisting of an elastic load balancer and several EC2 instances configured with auto-scaling in three Availability Zones. You want to monitor your EC2 instances based on a particular metric, which is not readily available in CloudWatch.\xa0 \xa0Which of the following is a custom metric in CloudWatch which you have to manually set up?', '_class': 'assessment', 'created': '2018-11-21T07:22:45Z', 'id': 6180436, 'original_assessment_id': 2566866, 'section': 'CloudWatch', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>CloudWatch has available Amazon EC2 Metrics for you to use for monitoring CPU utilization, Network utilization, Disk performance and Disk Reads/Writes. In case that you need to monitor the below items,&nbsp;you need to prepare a custom metric using a Perl or other shell script, as there are no ready to use metrics for these:</p><ul><li>Memory utilization</li><li>disk swap utilization</li><li>disk space utilization</li><li>page file utilization</li><li>log collection</li></ul><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/products/databases/">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring_ec2.html</a></p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/mon-scripts.html#using_put_script">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/mon-scripts.html#using_put_script</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['Memory Utilization of an EC2 instance', 'CPU Utilization of an EC2 instance', 'Disk Reads activity of an EC2 instance', 'Networks packets out of an EC2 instance'], 'question': '<p>The company that you are working for has a highly available architecture consisting of an elastic load balancer and several EC2 instances configured with auto-scaling in three Availability Zones. You want to monitor your EC2 instances based on a particular metric, which is not readily available in CloudWatch.\xa0 \xa0</p><p>Which of the following is a custom metric in CloudWatch which you have to manually set up?</p>'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:22:45Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are leading a software development team which uses serverless computing with AWS Lambda to build and run applications without having to set up or manage servers. You have a Lambda function that connects to a MongoDB Atlas, which is a popular Database as a Service (DBaaS) platform and also uses a third party API to fetch certain data for your application. You instructed one of your junior developers to create the environment variables for the MongoDB database hostname, username, and password as well as the API credentials that will be used by the Lambda function for DEV, SIT, UAT and PROD environments.\xa0 Considering that the Lambda function is storing sensitive database and API credentials, how can you secure this information to prevent other developers in your team, or anyone, from seeing these credentials in plain text? Select the best option that provides the maximum security.', '_class': 'assessment', 'created': '2018-11-21T07:22:45Z', 'id': 6180438, 'original_assessment_id': 2566868, 'section': 'Lambda', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>When you create or update Lambda functions that use environment variables, AWS Lambda encrypts them using the AWS Key Management Service. When your Lambda function is invoked, those values are decrypted and made available to the Lambda code.</p> <p>The first time you create or update Lambda functions that use environment variables in a region, a default service key is created for you automatically within AWS KMS. This key is used to encrypt environment variables. However, if you wish to use encryption helpers and use KMS to encrypt environment variables after your Lambda function is created, you must create your own AWS KMS key and choose it instead of the default key. The default key will give errors when chosen. Creating your own key gives you more flexibility, including the ability to create, rotate, disable, and define access controls, and to audit the encryption keys used to protect your data.</p> <p>&nbsp;</p> <p><strong>Reference:</strong></p> <p><a href="https://docs.aws.amazon.com/lambda/latest/dg/env_variables.html#env_encrypt">https://docs.aws.amazon.com/lambda/latest/dg/env_variables.html#env_encrypt</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p>There is no need to do anything because, by default, AWS Lambda already encrypts the environment variables using the AWS Key Management Service.</p>', '<p>Enable SSL encryption that leverages on AWS CloudHSM to store and encrypt the sensitive information.</p>', '<p>AWS Lambda does not provide encryption for the environment variables. Deploy your code to an EC2 instance instead.</p>', '<p>Create a new KMS key and use it to enable encryption helpers that leverage on AWS Key Management Service to store and encrypt the sensitive information.</p>'], 'question': '<p>You are leading a software development team which uses serverless computing with AWS Lambda to build and run applications without having to set up or manage servers. You have a Lambda function that connects to a MongoDB Atlas, which is a popular Database as a Service (DBaaS) platform and also uses a third party API to fetch certain data for your application. You instructed one of your junior developers to create the environment variables for the MongoDB database hostname, username, and password as well as the API credentials that will be used by the Lambda function for DEV, SIT, UAT and PROD environments.\xa0 </p><p>Considering that the Lambda function is storing sensitive database and API credentials, how can you secure this information to prevent other developers in your team, or anyone, from seeing these credentials in plain text? Select the best option that provides the maximum security.</p>'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:22:45Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'In your AWS VPC, you need to add a new subnet that will allow you to host a total of 20 EC2 instances. Which of the following IPv4 CIDR block can you use for this scenario?', '_class': 'assessment', 'created': '2018-11-21T07:22:45Z', 'id': 6180440, 'original_assessment_id': 2566870, 'section': 'VPC', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>To calculate the total number of IP addresses of a given CIDR Block, you simply need to follow the 2 easy steps below. Let\'s say you have a CIDR block <strong>/27</strong>:&nbsp;</p> <p style="padding-left: 30px;">1. Subtract <strong>32</strong> with the mask number :&nbsp;</p> <p style="padding-left: 60px;">(32 - 27) = <strong>5</strong></p> <p style="padding-left: 30px;">2. Raise&nbsp;the number&nbsp;<strong>2</strong> to the power of the answer in Step #1 :&nbsp;</p> <p style="padding-left: 60px;">2^ <strong>5</strong> = (2 * 2 * 2 * 2 * 2)</p> <p style="padding-left: 90px;">&nbsp; = <strong>32</strong></p> <p>The answer to Step #2 is the total number of IP addresses available in the given CIDR netmask. Don\'t forget that in AWS, the first 4 IP addresses and the last IP address in each subnet CIDR block are not available for you to use, and cannot be assigned to an instance.&nbsp;In addition, you can always associate a netmask of /27 which also has the same number of usable IP addresses (27) to help you with your exam.</p> <p>Option 1 is the correct answer because the CIDR block of 172.0.0.0/27, with a netmask of /27, has an equivalent of 27 <em>usable</em> IP addresses. Take note that a netmask of /27 originally provides you with 32 IP addresses but in AWS, there are 5 IP addresses that are reserved which you cannot use. The first 4 IP addresses and the last IP address in each subnet CIDR block are not available in your VPC which means that you have to <strong>always</strong> subtract 5 IP addresses, hence 32 - 5 = 27.&nbsp;</p> <p>Option 2 is incorrect as&nbsp;a netmask of /28 only supports 16 IP Addresses.</p> <p>Options 3 and 4 are incorrect as the only allowed block size is between&nbsp;a /28 netmask and /16 netmask.&nbsp;</p> <p>To add a CIDR block to your VPC, the following rules apply:</p> <div> <ul> <li> <p>The allowed block size is between a&nbsp;<code>/28</code>&nbsp;netmask and&nbsp;<code>/16</code>&nbsp;netmask.</p> </li> <li> <p>The CIDR block must not overlap with any existing CIDR block that\'s associated with the VPC.</p> </li> <li> <p>You cannot increase or decrease the size of an existing CIDR block.</p> </li> <li> <p>You have a limit on the number of CIDR blocks you can associate with a VPC and the number of routes you can add to a route table. You cannot associate a CIDR block if this results in you exceeding your limits.</p> </li> <li> <p>The CIDR block must not be the same or larger than the CIDR range of a route in any of the VPC route tables. For example, if you have a route with a destination of&nbsp;<code>10.0.0.0/24</code>&nbsp;to a virtual private gateway, you cannot associate a CIDR block of the same range or larger. However, you can associate a CIDR block of&nbsp;<code>10.0.0.0/25</code>&nbsp;or smaller.</p> </li> <li>The first four IP addresses and the last IP address in each subnet CIDR block are not available for you to use, and cannot be assigned to an instance.</li> </ul> </div> <p><strong>Reference:</strong></p> <p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p>172.0.0.0/27</p>', '<p>172.0.0.0/28</p>', '<p>172.0.0.0/29</p>', '<p>172.0.0.0/30</p>'], 'question': '<p>In your AWS VPC, you need to add a new subnet that will allow you to host a total of 20 EC2 instances. <br><br>Which of the following IPv4 CIDR block can you use for this scenario?</p>'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:22:45Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A traffic monitoring and reporting application uses Kinesis to accept real-time data. In order to process and store the data, they used Amazon Kinesis Data Firehose to load the streaming data to various AWS resources. In this scenario, which services can you load streaming data into, which is coming from Kinesis?', '_class': 'assessment', 'created': '2018-11-21T07:22:45Z', 'id': 6180442, 'original_assessment_id': 2566872, 'section': 'Kinesis', 'prompt': {'relatedLectureIds': '', 'explanation': '<div><p>Amazon Kinesis Data Firehose is the easiest way to load streaming data into data stores and analytics tools. It can capture, transform, and load streaming data into Amazon S3, Amazon Redshift, Amazon Elasticsearch Service, and Splunk, enabling near real-time analytics with existing business intelligence tools and dashboards you&rsquo;re already using today.</p><p>It is a fully managed service that automatically scales to match the throughput of your data and requires no ongoing administration. It can also batch, compress, and encrypt the data before loading it, minimizing the amount of storage used at the destination and increasing security.</p><div>&nbsp;</div></div><p>References:</p><p><a href="https://aws.amazon.com/kinesis/data-firehose/">https://aws.amazon.com/kinesis/data-firehose/</a></p><p>&nbsp;</p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Amazon S3', 'Amazon Redshift', 'Amazon Elasticsearch Service', 'Splunk', 'All of the above', 'All of the above except for Splunk'], 'question': '<p>A traffic monitoring and reporting application uses Kinesis to accept real-time data. In order to process and store the data, they used Amazon Kinesis Data Firehose to load the streaming data to various AWS resources. </p><p>In this scenario, which services can you load streaming data into, which is coming from Kinesis?</p>'}, 'related_lectures': [], 'correct_response': ['e'], 'updated': '2018-11-21T07:22:45Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are deploying a NodeJS application to a large On-Demand EC2 instance in your VPC. In the EC2 Launch Wizard, there are various selections that you can choose from such as the operating system, architecture type and root device type which can either be an Instance Store or EBS.\xa0 \xa0In this scenario, what is the difference between an Instance store and an EBS root device type?', '_class': 'assessment', 'created': '2018-11-21T07:22:45Z', 'id': 6180444, 'original_assessment_id': 2566874, 'section': 'EC2', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>Amazon EBS-backed instances can be stopped and restarted unlike Amazon Instance Store-Backed instances which cannot be stopped. An Instance Store-Backed instance is either running or terminated. Hence, option 1 is correct and conversely, option 2 is incorrect.</p><p>Option 3 is incorrect because Auto Scaling can be done on both types of instances.</p><p>Option 4 is incorrect because VPC supports both types of instances.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ComponentsAMIs.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ComponentsAMIs.html</a></p><p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'answers': ['Amazon EBS-backed instances can be stopped and restarted.', 'Instance-store backed instances can be stopped and restarted.', 'Auto Scaling is only applicable for EBS-backed instances.', 'Virtual Private Cloud only supports EBS backed instances.'], 'question': '<p>You are deploying a NodeJS application to a large On-Demand EC2 instance in your VPC. In the EC2 Launch Wizard, there are various selections that you can choose from such as the operating system, architecture type and root device type which can either be an Instance Store or EBS.\xa0 \xa0</p><p>In this scenario, what is the difference between an Instance store and an EBS root device type?</p>'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:22:45Z'}, {'assessment_type': 'multi-select', 'question_plain': 'There was an incident in your production environment where the user data stored in the S3 bucket has been accidentally deleted by one of the Junior DevOps Engineers. The issue was escalated to your manager and after a few days, you were instructed to improve the security and protection of your AWS resources.\xa0 \xa0 What combination of the following options will protect the S3 objects in your bucket from both accidental deletion and overwriting? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180446, 'original_assessment_id': 2566876, 'section': 'S3', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>By using Versioning and enabling MFA (Multi-Factor Authentication) Delete, you can secure and recover your S3 objects from accidental deletion or overwrite.&nbsp;</p> <p>Versioning is a means of keeping multiple variants of an object in the same bucket. Versioning-enabled buckets enable you to recover objects from accidental deletion or overwrite. You can use versioning to preserve, retrieve, and restore every version of every object stored in your Amazon S3 bucket. With versioning, you can easily recover from both unintended user actions and application failures.</p> <p>You can also optionally add another layer of security by configuring a bucket to enable MFA (Multi-Factor Authentication) Delete, which requires additional authentication for either of the following operations:</p> <ul> <li>Change the versioning state of your bucket</li> <li>Permanently delete an object version</li> </ul> <p>&nbsp;</p> <p>MFA Delete requires two forms of authentication together:</p> <ul> <li>Your security credentials</li> <li>The concatenation of a valid serial number, a space, and the six-digit code displayed on an approved authentication device</li> </ul> <p>&nbsp;</p> <p><strong>Reference:&nbsp;</strong></p> <p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html">https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Enable Versioning', '<p>Provide access to S3 data strictly through pre-signed URL only</p>', 'Disallow S3 Delete using an IAM bucket policy', 'Enable S3 RRS', 'Enable Multi-Factor Authentication Delete', '<p>Use an S3 One Zone-Infrequent Access bucket</p>'], 'question': '<p>There was an incident in your production environment where the user data stored in the S3 bucket has been accidentally deleted by one of the Junior DevOps Engineers. The issue was escalated to your manager and after a few days, you were instructed to improve the security and protection of your AWS resources.\xa0 \xa0 </p><p>What combination of the following options will protect the S3 objects in your bucket from both accidental deletion and overwriting? (Choose 2)</p>'}, 'related_lectures': [], 'correct_response': ['a', 'e'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have a web application deployed in AWS which is currently running in the eu-central-1 region. You have an Auto Scaling group of On-Demand EC2 instances which are using pre-built AMIs. Your manager instructed you to implement a disaster recovery of your system so in the event that the application goes down in the eu-central-1 region, a new instance can be started in the us-west-2 region.\xa0 As part of your disaster recovery plan, which of the following should you take into consideration?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180448, 'original_assessment_id': 2566878, 'section': 'AMI', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>In this scenario, the EC2 instances you are currently using depends on a pre-built AMI. This AMI is not accessible to another region hence,&nbsp; you have to copy it to the&nbsp;us-west-2 region to properly establish your disaster recovery instance.</p><p>You can copy an Amazon Machine Image (AMI) within or across an AWS region using the AWS Management Console, the AWS command line tools or SDKs, or the Amazon EC2 API, all of which support the&nbsp;<code class="code">CopyImage </code>action. You can copy both Amazon EBS-backed AMIs and instance store-backed AMIs. You can copy encrypted AMIs and AMIs with encrypted snapshots.</p><p>&nbsp;</p><p>Options 1 and 3 are incorrect because the AMI&nbsp;does not have a Network Access Control nor a Share functionality.</p><p>Option 4 is incorrect as you can use a unique or pre-built AMI to a specific region only.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['In the AMI dashboard, add the us-west-2 region to the Network Access Control List which contains the regions  that are allowed to use the AMI.', '<p>Copy the AMI from the eu-central-1 region to the us-west-2 region. Afterwards, change the Auto Scaling group in the us-west-2 region to use this new AMI ID.</p>', 'Share the AMI to the us-west-2 region.', 'None. AMIs can be used in any region hence, there is no problem using it in the us-west-2 region.'], 'question': '<p>You have a web application deployed in AWS which is currently running in the eu-central-1 region. You have an Auto Scaling group of On-Demand EC2 instances which are using pre-built AMIs. Your manager instructed you to implement a disaster recovery of your system so in the event that the application goes down in the eu-central-1 region, a new instance can be started in the us-west-2 region.\xa0 </p><p>As part of your disaster recovery plan, which of the following should you take into consideration?</p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': "A popular mobile game uses CloudFront, Lambda, and DynamoDB for its backend services. The player data is persisted on a DynamoDB table and the static assets are distributed by CloudFront. However, there are a lot of complaints that saving and retrieving player information is taking a lot of time.\xa0 \xa0To improve the game's performance, which AWS service can you use to reduce DynamoDB response times from milliseconds to microseconds?", '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180450, 'original_assessment_id': 2566880, 'section': 'DynamoDB', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>Amazon DynamoDB Accelerator (DAX) is a fully managed, highly available, in-memory cache that can reduce Amazon DynamoDB response times from milliseconds to microseconds, even at millions of requests per second.</p> <p>Option 4 is incorrect as there is no such thing as&nbsp;Amazon DynamoDB NextGen.</p> <p>Options 1, 2, and 3 are incorrect because they cannot reduce Amazon DynamoDB response times.</p> <p>Option 6 is incorrect because the AWS Device Farm is an app testing service that lets you test and interact with your Android, iOS, and web apps on many devices at once, or reproduce issues on a device in real time.</p> <p><strong>References:</strong></p> <p><a href="https://aws.amazon.com/dynamodb/">https://aws.amazon.com/dynamodb/</a></p> <p><a href="https://aws.amazon.com/device-farm">https://aws.amazon.com/device-farm</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['AWS ElastiCache Memcached', 'Amazon Simple Storage Service', 'Amazon EC2 Instance Storage', 'Amazon DynamoDB NextGen', 'Amazon DynamoDB Accelerator (DAX)', '<p>AWS Device Farm\xa0 </p>'], 'question': "<p>A popular mobile game uses CloudFront, Lambda, and DynamoDB for its backend services. The player data is persisted on a DynamoDB table and the static assets are distributed by CloudFront. However, there are a lot of complaints that saving and retrieving player information is taking a lot of time.\xa0 \xa0</p><p>To improve the game's performance, which AWS service can you use to reduce DynamoDB response times from milliseconds to microseconds?</p>"}, 'related_lectures': [], 'correct_response': ['e'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You have launched a new enterprise application with a web server and a database. You are using an EC2 Instance with one 500 GB EBS volume to host a relational database. Upon checking the performance, it shows that write throughput to the database needs to be increased. Which of the following approaches can help you achieve this? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180452, 'original_assessment_id': 2566882, 'section': 'EC2', 'prompt': {'explanation': '<p>The goal here is to increase the write performance of the database hosted in an EC2 instance. You can achieve this by either setting up a standard RAID configuration or simply by increasing the size of the EC2 instance.</p><p>Some EC2 instance types can drive more I/O throughput than what you can provision for a single EBS volume. You can join multiple&nbsp;<code class="code">gp2</code>,&nbsp;<code class="code">io1</code>,&nbsp;<code class="code">st1</code>, or&nbsp;<code class="code">sc1</code>&nbsp;volumes together in a RAID 0 configuration to use the available bandwidth for these instances.</p><p>With Amazon EBS, you can use any of the standard RAID configurations that you can use with a traditional bare metal server, as long as that particular RAID configuration is supported by the operating system for your instance. This is because all RAID is accomplished at the software level. For greater I/O performance than you can achieve with a single volume, RAID 0 can stripe multiple volumes together; for on-instance redundancy, RAID 1 can mirror two volumes together.</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/raid-config.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/raid-config.html</a></p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSPerformance.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSPerformance.html</a></p>', 'answers': ['Use a standard RAID configuration', 'Enable Multi-AZ mode', 'Place the instance that hosts the database in an Auto Scaling Group', 'Add an EBS volume and place into RAID 5', 'Increase the size of the EC2 Instance', 'Put the database behind an Network Load Balancer'], 'question': 'You have launched a new enterprise application with a web server and a database. You are using an EC2 Instance with one 500 GB EBS volume to host a relational database. Upon checking the performance, it shows that write throughput to the database needs to be increased. <br /><br />Which of the following approaches can help you achieve this? (Choose 2)'}, 'related_lectures': [], 'correct_response': ['a', 'e'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multi-select', 'question_plain': 'In a government agency that you are working for, you have been assigned a task to put confidential tax documents on AWS cloud. However, there is a concern from a security perspective on what can be put on AWS. What are the features in AWS that can ensure data security to your confidential documents? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180454, 'original_assessment_id': 2566884, 'section': 'Security', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>You can secure the privacy of your data in AWS, both at rest and in-transit, through encryption. If your data is stored in EBS Volumes, you can enable EBS Encryption and if it is stored on Amazon S3, you can enable client-side and server-side encryption.</p><p>Option 4 is incorrect as public data sets are designed to be publicly accessible.&nbsp;</p><p>Options 5 and 6 are incorrect as there is no such thing as On-Premise Data Encryption for S3 and EBS - these services are in the AWS cloud and not on your on-premise network.&nbsp;</p><p>&nbsp;</p><p>Resources:</p><p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingEncryption.html">https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingEncryption.html</a></p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html</a></p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-public-data-sets.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-public-data-sets.html</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['<p>EBS Encryption</p>', 'S3 Server-Side Encryption', 'S3 Client-Side Encryption', 'Public Data Set Volume Encryption', 'S3 On-Premise Data Encryption', 'EBS On-Premise Data Encryption'], 'question': 'In a government agency that you are working for, you have been assigned a task to put confidential tax documents on AWS cloud. However, there is a concern from a security perspective on what can be put on AWS. <br><br>What are the features in AWS that can ensure data security to your confidential documents? (Choose 3)'}, 'related_lectures': [], 'correct_response': ['a', 'b', 'c'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a large pharmaceutical company that has resources hosted on both their on-premise network and in AWS cloud. They want all of their Software Architects to access resources on both environments using their on-premise credentials, which is stored in Active Directory. In this scenario, which of the following can be used to fulfill this requirement?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180456, 'original_assessment_id': 2566886, 'section': 'IAM', 'prompt': {'explanation': '<p>Since the company is using&nbsp;Microsoft Active Directory which implements&nbsp;Security Assertion Markup Language (SAML),&nbsp; you can set up a&nbsp;SAML-Based Federation for API Access to your AWS cloud. In this way, you can easily connect to AWS using the login credentials of your on-premise network.</p><p>AWS supports identity federation with SAML 2.0, an open standard that many identity providers (IdPs) use. This feature enables federated single sign-on (SSO), so users can log into the AWS Management Console or call the AWS APIs without you having to create an IAM user for everyone in your organization. By using SAML, you can simplify the process of configuring federation with AWS, because you can use the IdP\'s service instead of writing custom identity proxy code.</p><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_saml.html">http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_saml.html</a></p><p>&nbsp;</p><p>&nbsp;</p>', 'answers': ['Use Web Identity Federation', 'Use SAML Federation', 'Use IAM users', 'Use AWS VPC', 'Use S3'], 'question': 'You are working for a large pharmaceutical company that has resources hosted on both their on-premise network and in AWS cloud. They want all of their Software Architects to access resources on both environments using their on-premise credentials, which is stored in Active Directory. <br /><br />In this scenario, which of the following can be used to fulfill this requirement?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are a Solutions Architect working for a major telecommunications company in Europe. You deployed an On-Demand EC2 instance that is transferring large amounts of data to an Amazon S3 bucket in the same region.  Your manager is worried about infrastructure cost considering the vast amounts of data being transferred to the bucket. What will you say to justify this architecture?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180458, 'original_assessment_id': 2566888, 'section': 'EC2', 'prompt': {'explanation': '<p>Transferring data from an EC2 instance to Amazon S3, Amazon Glacier, Amazon DynamoDB, Amazon SES, Amazon SQS, or Amazon SimpleDB in the same AWS Region has no cost at all. Refer to the Amazon EC2 Pricing on the link below for reference.&nbsp;</p><p>Options 1 and 4 are incorrect since an On-Demand instance costs more than a Spot instance.</p><p>Option 3 is incorrect as there is no such thing as 50% discount when transferring data from an EC2 instance to an S3 bucket in the same region.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/ec2/pricing/on-demand/#Data_Transfer">https://aws.amazon.com/ec2/pricing/on-demand/#Data_Transfer</a></p>', 'answers': ['You are only using an On-Demand EC2 instance which is exactly the same price as Spot instance.', 'Transferring data from an EC2 instance to an S3 bucket in the same region has no cost at all.', 'Transferring data from an EC2 instance to an S3 bucket in the same region has a 50% discount based on the AWS Pricing.', 'You are only using an On-Demand EC2 instance so the cost will be lower than a Spot instance.'], 'question': 'You are a Solutions Architect working for a major telecommunications company in Europe. You deployed an On-Demand EC2 instance that is transferring large amounts of data to an Amazon S3 bucket in the same region.  Your manager is worried about infrastructure cost considering the vast amounts of data being transferred to the bucket. <br /><br />What will you say to justify this architecture?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multi-select', 'question_plain': 'A telecommunications company is planning to give AWS Console access to developers. Company policy mandates the use of identity federation and role-based access control. Currently, the roles are already assigned using groups in the corporate Active Directory. In this scenario, what combination of the following services can provide developers access to the AWS console? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180460, 'original_assessment_id': 2566892, 'section': 'Directory Service', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>Considering the company is using a corporate Active Directory, it is best to use&nbsp;AWS Directory Service AD Connector for easier integration. In addition, since the roles are already assigned using groups in the corporate Active Directory, it would be better to&nbsp;also use IAM Roles.</p><p>AWS Directory Service provides multiple ways to use Amazon Cloud Directory and Microsoft Active Directory (AD) with other AWS services. Directories store information about users, groups, and devices, and administrators use them to manage access to information and resources. AWS Directory Service provides multiple directory choices for customers who want to use existing Microsoft AD or Lightweight Directory Access Protocol (LDAP)&ndash;aware applications in the cloud. It also offers those same choices to developers who need a directory to manage users, groups, devices, and access.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/blogs/security/how-to-connect-your-on-premises-active-directory-to-aws-using-ad-connector/">https://aws.amazon.com/blogs/security/how-to-connect-your-on-premises-active-directory-to-aws-using-ad-connector/</a></p><p>&nbsp;</p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['AWS Directory Service AD Connector', 'AWS Directory Service Simple AD', 'IAM Groups', 'IAM Roles', 'IAM Users', '<p>Lambda</p>'], 'question': 'A telecommunications company is planning to give AWS Console access to developers. Company policy mandates the use of identity federation and role-based access control. Currently, the roles are already assigned using groups in the corporate Active Directory. <br><br>In this scenario, what combination of the following services can provide developers access to the AWS console? (Choose 2)'}, 'related_lectures': [], 'correct_response': ['a', 'd'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have a new VPC with private and public subnets. You will be creating a new mySQL database server. In which subnet should you launch the new database server into?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180462, 'original_assessment_id': 2566894, 'section': 'VPC', 'prompt': {'explanation': '<div><p>In an ideal and secure VPC architecture, you launch the web servers or elastic load balancers in the public subnet and the database servers in the private subnet. If you launch your database server in the public subnet, it will be publicly accessible all over the Internet which has a higher security risk. Hence, it is better to launch your database in the private subnet.</p><p>&nbsp;</p></div><p>References:</p><p><a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario2.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario2.html</a></p><p>&nbsp;</p>', 'answers': ['The public subnet', 'The private subnet', 'Either public or private subnet', 'Ideally be launched outside the Amazon VPC'], 'question': 'You have a new VPC with private and public subnets. You will be creating a new mySQL database server. In which subnet should you launch the new database server into?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'An application is deployed in a fleet of Spot EC2 instances and uses a MySQL RDS database instance. Currently, there is only one RDS instance running in one Availability Zone. You plan to improve the database to ensure high availability and scalability by synchronous data replication to another RDS instance.\xa0 \xa0Which of the following performs synchronous data replication in RDS?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180464, 'original_assessment_id': 2566896, 'section': 'RDS', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>When you create or modify your DB instance to run as a Multi-AZ deployment, Amazon RDS automatically provisions and maintains a synchronous <strong>standby&nbsp;</strong>replica in a different Availability Zone. Updates to your DB Instance are synchronously replicated across Availability Zones to the standby in order to keep both in sync and protect your latest database updates against DB instance failure.&nbsp;</p> <p>Option 2 is incorrect as a Read Replica provides an asynchronous replication instead of synchronous. In addition, a Read Replica is only available in Aurora, MySQL, MariaDB, and PostgreSQL database engines.&nbsp;</p> <p>Options 3 and 4 are wrong answers as both DynamoDB and CloudFront do not have a Read Replica feature.</p> <p>&nbsp;</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/rds/details/multi-az/" target="_blank" rel="noopener">https://aws.amazon.com/rds/details/multi-az/</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['RDS DB instance running as a Multi-AZ deployment', 'RDS Read Replica in Oracle Database', 'DynamoDB Read Replica', 'Cloudfront running as a Multi-AZ deployment'], 'question': '<p>An application is deployed in a fleet of Spot EC2 instances and uses a MySQL RDS database instance. Currently, there is only one RDS instance running in one Availability Zone. You plan to improve the database to ensure high availability and scalability by synchronous data replication to another RDS instance.\xa0 \xa0</p><p>Which of the following performs synchronous data replication in RDS?</p>'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are a newly-hired Solutions Architect in a leading utilities provider which in the process of migrating their applications to AWS. You created an EBS-Backed EC2 instance with ephemeral0 and ephemeral1 instance store volumes attached to host a web application that fetches and stores data from a web API service.\xa0 \xa0If this instance is stopped, what will happen to the data on the ephemeral store volumes?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180466, 'original_assessment_id': 2566898, 'section': 'EC2', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>The virtual devices for instance store volumes are named as&nbsp;<code>ephemeral[0-23]</code>. Instance types that support one instance store volume have&nbsp;<code>ephemeral0</code>. Instance types that support two instance store volumes have&nbsp;<code>ephemeral0</code>&nbsp;and&nbsp;<code>ephemeral1</code>, and so on until&nbsp;<code>ephemeral23</code>&nbsp;</p><p>The data in an instance store persists only during the lifetime of its associated instance. If an instance reboots (intentionally or unintentionally), data in the instance store persists. However, data in the instance store is lost under the following circumstances:</p><ul><li>-The underlying disk drive fails</li><li>-The instance stops</li><li>-The instance terminates</li></ul><br /><p>The word&nbsp;<em>ephemeral</em>&nbsp;means short-lived or temporary in the English dictionary. Hence, when you see this word in AWS, always consider this as just a temporary memory or a short-lived storage.&nbsp;</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html?shortFooter=true#instance-store-lifetime">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html?shortFooter=true#instance-store-lifetime</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['Data is automatically saved in an EBS volume.', 'Data is unavailable until the instance is restarted.', 'Data will be deleted.', 'Data is automatically saved as an EBS snapshot.'], 'question': '<p>You are a newly-hired Solutions Architect in a leading utilities provider which in the process of migrating their applications to AWS. You created an EBS-Backed EC2 instance with <code>ephemeral0</code> and <code>ephemeral1</code> instance store volumes attached to host a web application that fetches and stores data from a web API service.\xa0 \xa0</p><p>If this instance is stopped, what will happen to the data on the ephemeral store volumes? </p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': "You are building the development, testing, UAT, and production enviroment of your company's new cloud infrastructure. All of the environments will only be under one VPC. In this scenario, how can you categorize your EC2 resources in different ways such as by purpose, owner, or environment?", '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180468, 'original_assessment_id': 2566900, 'section': 'EC2', 'prompt': {'explanation': '<p>Tags enable you to categorize your AWS resources in different ways, for example, by purpose, owner, or environment. This is useful when you have many resources of the same type &mdash; you can quickly identify a specific resource based on the tags you\'ve assigned to it. Each tag consists of a&nbsp;<em>key</em>&nbsp;and an optional&nbsp;<em>value</em>, both of which you define. For example, you could define a set of tags for your account\'s Amazon EC2 instances that helps you track each instance\'s owner and stack level. We recommend that you devise a set of tag keys that meets your needs for each resource type. Using a consistent set of tag keys makes it easier for you to manage your resources. You can search and filter the resources based on the tags you add.</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Using_Tags.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Using_Tags.html</a></p><p>&nbsp;</p>', 'answers': ['wildcards', 'pointers', 'Tags', 'custom filters', 'Availability Zone'], 'question': "You are building the development, testing, UAT, and production enviroment of your company's new cloud infrastructure. All of the environments will only be under one VPC. <br /><br />In this scenario, how can you categorize your EC2 resources in different ways such as by purpose, owner, or environment?"}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are working as a Solutions Architect in a startup company which has a project that requires a notification service. You are planning to use Amazon SNS as it uses a publish/subscribe model for push delivery of messages.\xa0 \xa0What are the different delivery formats or transports available for receiving notifications from this service? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180470, 'original_assessment_id': 2566902, 'section': 'SNS', 'prompt': {'relatedLectureIds': '', 'explanation': '<div><p>Amazon SNS supports notifications over multiple transport protocols in order for customers to have broad flexibility of delivery mechanisms. Customers can select one the following transports as part of the subscription requests:</p><ul><li><strong>HTTP, HTTPS</strong> &ndash; Subscribers specify a URL as part of the subscription registration; notifications will be delivered through an HTTP POST to the specified URL.</li><li><strong>Email, Email-JSON</strong> &ndash; Messages are sent to registered addresses as email. Email-JSON sends notifications as a JSON object, while Email sends text-based email.</li><li><strong>SQS</strong> &ndash; Users can specify an SQS standard queue as the endpoint; Amazon SNS will enqueue a notification message to the specified queue (which subscribers can then process using SQS APIs such as ReceiveMessage, DeleteMessage, etc.). Note that FIFO queues are not currently supported.</li><li><strong>SMS</strong> &ndash; Messages are sent to registered phone numbers as SMS text messages.</li></ul></div><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/sns/faqs/">https://aws.amazon.com/sns/faqs/</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Email', 'CloudFront distribution', 'File Transfer Protocol', 'Short Message Service', 'Simple Network Management Protocol', 'Simple Queue Service'], 'question': '<p>You are working as a Solutions Architect in a startup company which has a project that requires a notification service. You are planning to use Amazon SNS as it uses a publish/subscribe model for push delivery of messages.\xa0 \xa0</p><p>What are the different delivery formats or transports available for receiving notifications from this service? (Choose 3)</p>'}, 'related_lectures': [], 'correct_response': ['a', 'd', 'f'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are a Solutions Architect for a leading Enterprise Resource Planning (ERP) solutions provider and you are instructed to design and set up the architecture of your ERP application in AWS. Your manager instructed you to avoid using fully-managed AWS services and instead, only use specific services which allows you to access the underlying operating system for the resource. This is to allow the company to have a much better control of the underlying resources that their systems are using in the AWS cloud.\xa0 \xa0Which of the following services should you choose to satisfy this requirement? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180472, 'original_assessment_id': 2566904, 'section': 'EC2', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>Amazon EC2 provides you access to the operating system of the instance that you created.&nbsp;</p> <p>Amazon EMR provides you a managed Hadoop framework that makes it easy, fast, and cost-effective to process vast amounts of data across dynamically scalable Amazon EC2 instances. You can access the operating system of these EC2 instances that were created by Amazon EMR.</p> <p>Options 1, 4, 5 and 6 are incorrect as these ones are managed services, which means that AWS manages the underlying operating system and other server configurations that these databases use.</p> <p>&nbsp;</p> <p><strong>References:</strong></p> <p><a href="https://aws.amazon.com/ec2/">https://aws.amazon.com/ec2/</a></p> <p><a href="https://aws.amazon.com/emr/">https://aws.amazon.com/emr/</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Amazon RDS', 'Amazon EMR', 'Amazon EC2', 'DynamoDB', '<p>Amazon Neptune</p>', '<p>Amazon Athena</p>'], 'question': '<p>You are a Solutions Architect for a leading Enterprise Resource Planning (ERP) solutions provider and you are instructed to design and set up the architecture of your ERP application in AWS. Your manager instructed you to avoid using fully-managed AWS services and instead, only use specific services which allows you to access the underlying operating system for the resource. This is to allow the company to have a much better control of the underlying resources that their systems are using in the AWS cloud.\xa0 \xa0</p><p>Which of the following services should you choose to satisfy this requirement? (Choose 2)</p>'}, 'related_lectures': [], 'correct_response': ['b', 'c'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'In the VPC that you are managing, it has one EC2 instance that have its data stored in an instance store. The instance was shut down by a 2nd level support staff over the weekend to save costs. When you arrived in the office the next Monday, you noticed that all data is lost and is no longer available on the EC2 instance. What might be the cause of this?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180474, 'original_assessment_id': 2566906, 'section': 'EC2', 'prompt': {'explanation': '<div><p>Since your are using an EC2 instance with an Instance store, the data is ephemeral and it is expected to be erased once the instance is terminated. You may argue that the instance was only shut down but remember that the Operating system shutdown commands always terminate an instance store-backed instance. That is why the right answer is Option 1.</p><p>Amazon EC2 provides you with flexible, cost-effective, and easy-to-use data storage options for your instances. Each option has a unique combination of performance and durability. These storage options can be used independently or in combination to suit your requirements.&nbsp;These storage options include the following:</p><ul><li>-Amazon Elastic Block Store (EBS)</li><li>-Amazon EC2 Instance Store</li><li>-Amazon Elastic File System (Amazon EFS)</li><li>-Amazon Simple Storage Service (Amazon S3)&nbsp;</li></ul><br /><p>If you used Amazon Elastic Block Store as the storage option of your instance, the data will exist independently of the life of your instance. This means that you configure the EBS volume to still exist even if you terminate your instance. If you are using an Instance Store as a storage option, the data is ephemeral and as the name implies, your data&nbsp;lasts for a very short time and would not exist once your EC2 instance is terminated.&nbsp;</p><p>&nbsp;</p></div><p>Resources:</p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html</a></p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Storage.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Storage.html</a></p><p>&nbsp;</p>', 'answers': ['The EC2 instance was using an instance store hence, the data is erased when the instance is terminated.', 'The EC2 instance was using EBS backed root volumes hence, the data is erased when the instance is terminated.', 'AWS automatically erased the data due to a virus found on the EC2 instance.', 'The EC2 instance has been hacked.'], 'question': 'In the VPC that you are managing, it has one EC2 instance that have its data stored in an instance store. The instance was shut down by a 2nd level support staff over the weekend to save costs. When you arrived in the office the next Monday, you noticed that all data is lost and is no longer available on the EC2 instance. <br /><br />What might be the cause of this?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have a requirement to make sure that an On-Demand EC2 instance can only be accessed from this IP address (110.238.98.71) via an SSH connection. Which configuration below will satisfy this requirement?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180476, 'original_assessment_id': 2566908, 'section': 'Security', 'prompt': {'relatedLectureIds': '', 'explanation': '<div>The SSH protocol uses TCP and port 22. Hence, Options 2 and 4 are incorrect as they are using UDP. Options 1 and 3 have one major difference and that is their CIDR block</div> <div>&nbsp;</div> <div>The requirement is to only allow&nbsp;the individual IP of the client and not the entire network. Therefore,&nbsp;the proper CIDR notation should be used. The <strong>/32</strong> denotes one IP address and the <strong>/0</strong> refers to the entire network. That is why Option 3 is incorrect as it allowed the entire network instead of a single IP.</div> <p>&nbsp;</p> <p>References:</p> <p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-network-security.html#security-group-rules">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-network-security.html#security-group-rules</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'answers': ['Security Group Inbound Rule: Protocol – TCP. Port Range – 22, Source 110.238.98.71/32', 'Security Group Inbound Rule: Protocol – UDP, Port Range – 22, Source 110.238.98.71/32', 'Security Group Inbound Rule: Protocol – TCP. Port Range – 22, Source 110.238.98.71/0', 'Security Group Inbound Rule: Protocol – UDP, Port Range – 22, Source 110.238.98.71/0'], 'question': 'You have a requirement to make sure that an On-Demand EC2 instance can only be accessed from this IP address (110.238.98.71) via an SSH connection. Which configuration below will satisfy this requirement?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'There are many clients complaining that the online trading application of an investment bank is always down. Your manager instructed you to re-design the architecture of the application to prevent the unnecessary service interruptions. To ensure high availability, you set up the application to use an ELB to distribute the incoming requests across an auto-scaled group of EC2 instances in two single Availability Zones.\xa0 \xa0In this scenario, what happens when an EC2 instance behind an ELB fails a health check?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180478, 'original_assessment_id': 2566912, 'section': 'ELB', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>The load balancer routes requests only to the healthy instances. When the load balancer determines that an instance is unhealthy, it stops routing requests to that instance. The load balancer resumes routing requests to the instance when it has been restored to a healthy state.</p><p>References:</p><p><a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-healthchecks.html">https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-healthchecks.html</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['The EC2 instance gets terminated automatically by the ELB.', 'The EC2 instance gets quarantined by the ELB for root cause analysis.', 'The EC2 instance is replaced automatically by the ELB.', 'The ELB stops sending traffic to the EC2 instance'], 'question': '<p>There are many clients complaining that the online trading application of an investment bank is always down. Your manager instructed you to re-design the architecture of the application to prevent the unnecessary service interruptions. To ensure high availability, you set up the application to use an ELB to distribute the incoming requests across an auto-scaled group of EC2 instances in two single Availability Zones.\xa0 \xa0</p><p>In this scenario, what happens when an EC2 instance behind an ELB fails a health check?</p>'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multi-select', 'question_plain': 'A tech company that you are working for has undertaken a Total Cost Of Ownership (TCO) analysis evaluating the use of Amazon S3 versus acquiring more storage hardware. The result was that all 1200 employees would be granted access to use Amazon S3 for storage of their personal documents. Which of the following will you need to consider so you can set up a solution that incorporates single sign-on feature from your corporate AD or LDAP directory and also  restricts access for each individual user to a designated user folder in an S3 bucket? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180480, 'original_assessment_id': 2566916, 'section': 'STS', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>The question refers to one of the common scenarios for temporary credentials in AWS. Temporary credentials are useful in scenarios that involve identity federation, delegation, cross-account access, and IAM roles. In this example, it is called <strong>enterprise identity federation</strong> considering that you also need to set up a&nbsp;single sign-on (SSO) capability.</p> <p>The correct answers are:</p> <ul> <li>Setup a Federation proxy or an Identity provider</li> <li>Setup an AWS Security Token Service to generate temporary tokens</li> <li>Configure an IAM role&nbsp;</li> </ul> <p>In an enterprise identity federation, you can authenticate users in your organization\'s network, and then provide those users access to AWS without creating new AWS identities for them and requiring them to sign in with a separate user name and password. This is known as the&nbsp;<em>single sign-on</em>&nbsp;(SSO) approach to temporary access. AWS STS supports open standards like Security Assertion Markup Language (SAML) 2.0, with which you can use Microsoft AD FS to leverage your Microsoft Active Directory. You can also use SAML 2.0 to manage your own solution for federating user identities.</p> <p><strong>Reference:</strong></p> <p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-network-security.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-network-security.html</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Setup a Federation proxy or an Identity provider.', 'Setup an AWS Security Token Service to generate temporary tokens.', 'Use a resource tag on each folder in the S3 bucket.', 'Configure an IAM role.', 'Setup up a matching IAM user for each 1200 users in your corporate directory that needs access to a folder in the S3 bucket.', '<p>Use 3rd party Single Sign-On solutions such as Atlassian Crowd, OKTA, OneLogin and many others.</p>'], 'question': 'A tech company that you are working for has undertaken a Total Cost Of Ownership (TCO) analysis evaluating the use of Amazon S3 versus acquiring more storage hardware. The result was that all 1200 employees would be granted access to use Amazon S3 for storage of their personal documents. <br><br>Which of the following will you need to consider so you can set up a solution that incorporates single sign-on feature from your corporate AD or LDAP directory and also  restricts access for each individual user to a designated user folder in an S3 bucket? (Choose 3)'}, 'related_lectures': [], 'correct_response': ['a', 'b', 'd'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have a web application hosted in EC2 that consumes messages from an SQS queue and is integrated with SNS to send out an email to you once the process is complete. You received 5 orders but after a few hours, you saw more than 20 email notifications in your inbox. Which of the following could be the possible culprit for this issue?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180482, 'original_assessment_id': 2566918, 'section': 'SQS', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>Always remember that the messages in the SQS queue will continue to exist even after the EC2 instance has processed it, until you delete that message.</p><p>Refer to the third step of the SQS Message Lifecycle:</p><ol><li>Component 1 sends Message A to a queue, and the message is distributed across the Amazon SQS servers redundantly.</li><li>When Component 2 is ready to process a message, it consumes messages from the queue, and Message A is returned. While Message A is being processed, it remains in the queue and isn\'t returned to subsequent receive requests for the duration of the visibility timeout.&nbsp;</li><li>Component 2 <strong>deletes</strong> Message A from the queue to prevent the message from being received and processed again once the visibility timeout expires.</li></ol><p>References:</p><p><a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-message-lifecycle.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-message-lifecycle.html</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['The web application is set for long polling so the messages are being sent twice.', 'The web application is not deleting the messages in the SQS queue after it has processed them.', 'The web application is set to short polling so some messages are not being picked up', 'The web application does not have permission to consume messages in the SQS queue. '], 'question': '<p>You have a web application hosted in EC2 that consumes messages from an SQS queue and is integrated with SNS to send out an email to you once the process is complete. You received 5 orders but after a few hours, you saw more than 20 email notifications in your inbox. <br><br>Which of the following could be the possible culprit for this issue?</p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A company is using Redshift for its online analytic processing (OLAP) application which processes complex queries against large datasets. There is a requirement in which you have to define the number of query queues that are available and how queries are routed to those queues for processing. \n\nWhich of the following will you use to meet this requirement?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180484, 'original_assessment_id': 2566920, 'section': 'Redshift', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>In Amazon Redshift, you use workload management (WLM) to define the number of query queues that are available, and how queries are routed to those queues for processing. WLM is part of parameter group configuration. A cluster uses the WLM configuration that is specified in its associated parameter group.</p> <p>When you create a parameter group, the default WLM configuration contains one queue that can run up to five queries concurrently. You can add additional queues and configure WLM properties in each of them if you want more control over query processing. Each queue that you add has the same default WLM configuration until you configure its properties. When you add additional queues, the last queue in the configuration is the <em>default queue</em>. Unless a query is routed to another queue based on criteria in the WLM configuration, it is processed by the default queue. You cannot specify user groups or query groups for the default queue.</p> <p>As with other parameters, you cannot modify the WLM configuration in the default parameter group. Clusters associated with the default parameter group always use the default WLM configuration. If you want to modify the WLM configuration, you must create a parameter group and then associate that parameter group with any clusters that require your custom WLM configuration.</p> <p>&nbsp;</p> <p><strong>References</strong>:</p> <p><a href="https://docs.aws.amazon.com/redshift/latest/mgmt/workload-mgmt-config.html">https://docs.aws.amazon.com/redshift/latest/mgmt/workload-mgmt-config.html</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p>This is not possible with Redshift because it is not intended for OLAP application but rather, for OLTP. Use RDS database instead.</p>', '<p>Create a Lambda function that can accept the number of query queues and use this value to control Redshift.</p>', '<p>Use the workload management (WLM) in the parameter group configuration.</p>', '<p>This is not possible with Redshift because it is not intended for OLAP application but rather, for OLTP. Use a NoSQL DynamoDB database instead.</p>'], 'question': '<p>A company is using Redshift for its online analytic processing (OLAP) application which processes complex queries against large datasets. There is a requirement in which you have to define the number of query queues that are available and how queries are routed to those queues for processing. </p>\n\n<p>Which of the following will you use to meet this requirement?</p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A web application that you developed stores sensitive information on a non-boot, unencrypted Amazon EBS data volume attached to an Amazon EC2 instance. Which of the following ways could provide protection to the sensitive data of your Amazon EBS volume?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180486, 'original_assessment_id': 2566922, 'section': 'EBS', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>Amazon EBS encryption offers a simple encryption solution for your EBS volumes without the need to build, maintain, and secure your own key management infrastructure. When you create an encrypted EBS volume and attach it to a supported instance type, the following types of data are encrypted:</p> <ul> <li>Data at rest inside the volume</li> <li>All data moving between the volume and the instance</li> <li>All snapshots created from the volume</li> <li>All volumes created from those snapshots</li> </ul> <p>&nbsp;</p> <p>In this scenario, the EBS volume attached to the instance is already unencrypted. The best way to encrypt the data is to create and mount a new, encrypted Amazon EBS volume. Then move the data to the new volume and finally, delete the old, unencrypted Amazon EBS volume. Hence, Option 2 is the correct answer.</p> <p>Option 1 is incorrect because a missing step is missing for this option to be a valid answer. You need to copy the snapshot first, while applying encryption parameters, in order for the resulting target snapshot to be encrypted before restoring it to a new encrypted EBS volume.</p> <p>Option 3 is incorrect because you cannot encrypt the volume even if you unmount the volume. Remember that encryption has to be done during volume creation.</p> <p>Option 4 is incorrect because you cannot create an encrypted snapshot of an unencrypted volume or change existing volume from unencrypted to encrypted. You have to create new encrypted volume and transfer data to the new volume.</p> <p>&nbsp;</p> <p><strong>Reference:</strong></p> <p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['Create a new snapshot the current Amazon EBS volume. Restore the snapshot to a new, encrypted Amazon EBS volume. Mount the Amazon EBS volume.', 'Create and mount a new, encrypted Amazon EBS volume. Move the data to the new volume and finally, delete the old Amazon EBS volume.', 'Unmount the EBS volume and then set the encryption attribute to true. Afterwards, re-mount the Amazon EBS volume to the instance.', 'Associate the Amazon EBS volume with your AWS CloudHSM and then remount the Amazon EBS volume.'], 'question': 'A web application that you developed stores sensitive information on a non-boot, unencrypted Amazon EBS data volume attached to an Amazon EC2 instance. Which of the following ways could provide protection to the sensitive data of your Amazon EBS volume?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A leading telecommunications company wants to create standard templates of their infrastructure for AWS deployment. Which AWS service can be used in this scenario?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180488, 'original_assessment_id': 2566924, 'section': 'CloudFormation', 'prompt': {'explanation': '<p>AWS CloudFormation provides a common language for you to describe and provision all the infrastructure resources in your cloud environment. CloudFormation allows you to use a simple text file to model and provision, in an automated and secure manner, all the resources needed for your applications across all regions and accounts. This file serves as the single source of truth for your cloud environment. AWS CloudFormation is available at no additional charge, and you pay only for the AWS resources needed to run your applications.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/cloudformation/">https://aws.amazon.com/cloudformation/</a></p><p>&nbsp;</p>', 'answers': ['Amazon Simple Workflow Service', 'AWS Elastic Beanstalk', 'AWS CloudFormation', 'AWS OpsWorks'], 'question': 'A leading telecommunications company wants to create standard templates of their infrastructure for AWS deployment. Which AWS service can be used in this scenario?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A content management system (CMS) is hosted on a fleet of auto-scaled, On-Demand EC2 instances which use Amazon Aurora as its database. Currently, the system stores the file documents that the users uploaded in one of the attached EBS Volumes. Your manager noticed that the system performance is quite slow and he has instructed you to improve the architecture of the system. \n\nIn this scenario, what will you do to implement a scalable, high throughput file system?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180490, 'original_assessment_id': 2566926, 'section': 'EFS', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>This question tests your understanding between EBS, EFS and S3. In this scenario, there is a fleet of On-Demand EC2 instances that stores file documents from the users to one of the attached EBS Volumes. The system performance is quite slow because the architecture doesn\'t provide the EC2 instances a parallel shared access to the file documents. Remember that an EBS Volume can be attached to one EC2 instance at a time, hence, no other EC2 instance can connect to that EBS Volume. Take note as well that the type of storage needed here is a "file storage" which means that S3 is not the correct service to use because it is mainly used for "object storage". This is why the correct answer is EFS.</p> <p>Amazon Elastic File System (Amazon EFS) provides simple, scalable, elastic file storage for use with AWS Cloud services and on-premises resources. When mounted on Amazon EC2 instances, an Amazon EFS file system provides a standard file system interface and file system access semantics, allowing you to seamlessly integrate Amazon EFS with your existing applications and tools. Multiple Amazon EC2 instances can access an Amazon EFS file system at the same time, allowing Amazon EFS to provide a common data source for workloads and applications running on more than one Amazon EC2 instance.</p> <p>&nbsp;</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/efs/">https://aws.amazon.com/efs/</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p>Create an S3 bucket and use this as the storage for the CMS</p>', '<p>Use EFS</p>', '<p>Upgrade your existing EBS volumes to Provisioned IOPS SSD Volumes</p>', '<p>Use ElastiCache</p>'], 'question': '<p>A content management system (CMS) is hosted on a fleet of auto-scaled, On-Demand EC2 instances which use Amazon Aurora as its database. Currently, the system stores the file documents that the users uploaded in one of the attached EBS Volumes. Your manager noticed that the system performance is quite slow and he has instructed you to improve the architecture of the system. </p>\n\n<p>In this scenario, what will you do to implement a scalable, high throughput file system?</p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are an AWS Solution Architect designing an application environment on AWS cloud. Which service will allow you to monitor all API calls of your AWS resources and can also provide secured data for auditing and compliance purposes?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180492, 'original_assessment_id': 2566928, 'section': 'CloudTrail', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>AWS CloudTrail is a service that enables governance, compliance, operational auditing, and risk auditing of your AWS account. With CloudTrail, you can log, continuously monitor, and retain account activity related to actions across your AWS infrastructure. CloudTrail provides event history of your AWS account activity, including actions taken through the AWS Management Console, AWS SDKs, command line tools, and other AWS services. This event history simplifies security analysis, resource change tracking, and troubleshooting.</p> <p>Options 2, 3, and 4 are incorrect because these are not monitoring services.</p> <p>Option 5 is incorrect because although CloudWatch is a monitoring service, it does not provide detailed information about all API calls of your resources which is used for auditing.</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/cloudtrail/">https://aws.amazon.com/cloudtrail/</a></p>', 'feedbacks': ['', '', '', '', ''], 'answers': ['CloudTrail for security logs', 'Amazon S3', 'Kinesis', 'Lambda', 'CloudWatch'], 'question': 'You are an AWS Solution Architect designing an application environment on AWS cloud. Which service will allow you to monitor all API calls of your AWS resources and can also provide secured data for auditing and compliance purposes?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multi-select', 'question_plain': 'Your company is planning to use serverless applications in AWS to take advantage of its benefits such as flexible scaling, automated high availability and removing the need to provision or maintain any servers. The technical lead of the development team asked you about the available programming languages that they can use before starting the project.\xa0 \xa0In this scenario, what are the available programming languages supported by AWS Lambda? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180494, 'original_assessment_id': 2566930, 'section': 'Lambda', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>AWS Lambda supports Java, Node.js, C#, and Python with support for other languages coming in the future.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/lambda/features/" target="_blank" rel="noopener">https://aws.amazon.com/lambda/features/</a></p><p>&nbsp;</p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Node.js', 'AngularJS', 'Java', 'Python', 'COBOL', '<p>Swift</p>'], 'question': '<p>Your company is planning to use serverless applications in AWS to take advantage of its benefits such as flexible scaling, automated high availability and removing the need to provision or maintain any servers. The technical lead of the development team asked you about the available programming languages that they can use before starting the project.\xa0 \xa0</p><p>In this scenario, what are the available programming languages supported by AWS Lambda? (Choose 3)</p>'}, 'related_lectures': [], 'correct_response': ['a', 'c', 'd'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have acquired a new EC2 Spot Instance at a bid price of $0.03/hr. However, the Spot price increases to $0.05/hr after 40 minutes. What was the total EC2 compute cost of running your Spot Instance for that hour?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180496, 'original_assessment_id': 2566932, 'section': 'EC2', 'prompt': {'relatedLectureIds': '', 'explanation': '<div> <p>If your Spot instance is terminated or stopped by Amazon EC2 in the first instance hour, you will not be charged for that usage. However, if you terminate the instance yourself, you will be charged to the nearest second. If the Spot instance is terminated or stopped by Amazon EC2 in any subsequent hour, you will be charged for your usage to the nearest second. If you are running on Windows and you terminate the instance yourself, you will be charged for an entire hour.</p> <p><br />Remember that AWS automatically terminates the instance when the Spot price exceeds your maximum price. Since there was an increase in price after 40 minutes (which is within the first instance hour) the EC2 instance was terminated by AWS. The following are the possible reasons why Amazon EC2 will interrupt your Spot Instances:</p> <div> <ul type="disc"> <li> <p>Price &ndash; The Spot price is greater than your maximum price.</p> </li> <li> <p>Capacity &ndash; If there are not enough unused EC2 instances to meet the demand for Spot Instances, Amazon EC2 interrupts Spot Instances. The order in which the instances are interrupted is determined by Amazon EC2.</p> </li> <li> <p>Constraints &ndash; If your request includes a constraint such as a launch group or an Availability Zone group, these Spot Instances are terminated as a group when the constraint can no longer be met.</p> </li> </ul> <p>&nbsp;</p> </div> </div> <p><strong>References:</strong></p> <p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-interruptions.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-interruptions.html</a></p> <p><a href="https://aws.amazon.com/ec2/faqs/">https://aws.amazon.com/ec2/faqs/</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['$0.03', '$0.05', '$0.08', '$0.00'], 'question': '<p>You have acquired a new EC2 Spot Instance at a bid price of $0.03/hr. However, the Spot price increases to $0.05/hr after 40 minutes. <br><br>What was the total EC2 compute cost of running your Spot Instance for that hour?</p>'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A cryptocurrency trading platform is using an API built in AWS Lambda and API Gateway. Due to the recent news and rumors about the upcoming price surge of Bitcoin, Ethereum and other cryptocurrencies, it is expected that the trading platform would have a significant increase in site visitors and new users in the coming days ahead. \n\nIn this scenario, how can you protect the backend systems of the platform from traffic spikes?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180498, 'original_assessment_id': 2566934, 'section': 'API Gateway', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>Amazon API Gateway provides throttling at multiple levels including global and by service call. Throttling limits can be set for standard rates and bursts. For example, API owners can set a rate limit of 1,000 requests per second for a specific method in their REST APIs, and also configure Amazon API Gateway to handle a burst of 2,000 requests per second for a few seconds. Amazon API Gateway tracks the number of requests per second. Any request over the limit will receive a 429 HTTP response. The client SDKs generated by Amazon API Gateway retry calls automatically when met with this response.</p> <p>You can add caching to API calls by provisioning an Amazon API Gateway cache and specifying its size in gigabytes. The cache is provisioned for a specific stage of your APIs. This improves performance and reduces the traffic sent to your back end. Cache settings allow you to control the way the cache key is built and the time-to-live (TTL) of the data stored for each method. Amazon API Gateway also exposes management APIs that help you invalidate the cache for each stage.</p> <p>&nbsp;</p> <p><strong>Reference</strong>:</p> <p><a href="https://aws.amazon.com/api-gateway/faqs/">https://aws.amazon.com/api-gateway/faqs/</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p>Switch from using AWS Lambda and API Gateway to a more scalable and highly available architecture using EC2 instances, ELB, and Auto Scaling.</p>', '<p>Enable throttling limits and result caching in API Gateway.</p>', '<p>Use CloudFront in front of the API Gateway to act as a cache.</p>', '<p>Move the Lambda function in a VPC.</p>'], 'question': '<p>A cryptocurrency trading platform is using an API built in AWS Lambda and API Gateway. Due to the recent news and rumors about the upcoming price surge of Bitcoin, Ethereum and other cryptocurrencies, it is expected that the trading platform would have a significant increase in site visitors and new users in the coming days ahead. </p>\n\n<p>In this scenario, how can you protect the backend systems of the platform from traffic spikes?</p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as a Solutions Architect in a top software development company in Silicon Valley. The company has multiple applications hosted in their VPC. While you are monitoring the system, you noticed that multiple port scans are coming in from a specific IP address block which are trying to connect to several AWS resources inside your VPC. The internal security team has requested that all offending IP addresses be denied for the next 24 hours for security purposes. Which of the following is the best method to quickly and temporarily deny access from the specified IP addresses?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180500, 'original_assessment_id': 2566936, 'section': 'VPC', 'prompt': {'explanation': '<p>To control the traffic coming in and out of your VPC network, you can use the&nbsp;<em>network access control list (ACL).</em>&nbsp;It is an optional layer of security for your VPC that acts as a firewall for controlling traffic in and out of one or more subnets. This is the best solution among other options as you can easily add and remove the restriction in a matter of minutes.</p><p>Option 1 is incorrect as an IAM policy does not control the inbound and outbound traffic of your VPC.</p><p>Option 3 is incorrect as although a Security Group acts as a firewall, it will only control both inbound and outbound traffic at the instance level and not on the whole VPC.&nbsp;</p><p>Option 4 is incorrect because adding a firewall in the underlying operating system of the EC2 instance is not enough; the attacker can just connect to other AWS resources since the network access control list still allows them to do so.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_ACLs.html">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_ACLs.html</a></p><p>&nbsp;</p>', 'answers': ['Create a policy in IAM to deny access from the IP Address block.', 'Modify the Network Access Control List associated with all public subnets in the VPC to deny access from the IP Address block.', 'Add a rule in the Security Group of the EC2 instances to deny access from the IP Address block.', 'Configure the firewall in the operating system of the EC2 instances to deny access from the IP address block.'], 'question': 'You are working as a Solutions Architect in a top software development company in Silicon Valley. The company has multiple applications hosted in their VPC. While you are monitoring the system, you noticed that multiple port scans are coming in from a specific IP address block which are trying to connect to several AWS resources inside your VPC. The internal security team has requested that all offending IP addresses be denied for the next 24 hours for security purposes. <br /><br />Which of the following is the best method to quickly and temporarily deny access from the specified IP addresses?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A loan processing application is hosted on a large On-Demand EC2 instance. To ensure high availability, you enabled CloudWatch to monitor the EC2 instance for any spikes on its CPU utilization, read operations, and write operations using the available CPUUtilization, DiskReadOps, and DiskWriteOps metrics. The loan application processes high volumes of financial data which is why you want to add more metrics to the EC2 instance to ensure that the server works well 24 hours a day, 7 days a week.\xa0 \xa0In CloudWatch, which of the following items require a custom metric to monitor?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180502, 'original_assessment_id': 2566938, 'section': 'CloudWatch', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>CloudWatch has available Amazon EC2 Metrics for you to use for monitoring CPU utilization, Network utilization, Disk performance and Disk Reads/Writes. In case that you need to monitor the below items,&nbsp;you need to prepare a custom metric using a Perl or other shell script, as there are no ready to use metrics for these:</p><ul><li>Memory utilization</li><li>disk swap utilization</li><li>disk space utilization</li><li>page file utilization</li><li>log collection</li></ul><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring_ec2.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring_ec2.html</a></p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/mon-scripts.html#using_put_script">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/mon-scripts.html#using_put_script</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Memory utilization', 'disk swap utilization', 'disk space utilization', 'page file utilization', 'All of the above', '<p>None of the above</p>'], 'question': '<p>A loan processing application is hosted on a large On-Demand EC2 instance. To ensure high availability, you enabled CloudWatch to monitor the EC2 instance for any spikes on its CPU utilization, read operations, and write operations using the available <code>CPUUtilization</code>, <code>DiskReadOps</code>, and <code>DiskWriteOps</code> metrics. The loan application processes high volumes of financial data which is why you want to add more metrics to the EC2 instance to ensure that the server works well 24 hours a day, 7 days a week.\xa0 \xa0</p><p>In CloudWatch, which of the following items require a custom metric to monitor?</p>'}, 'related_lectures': [], 'correct_response': ['e'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are working for a software company that has moved a legacy application from an on-premise data center to the cloud. The legacy application requires a static IP address hard-coded into the backend, which blocks you from using an Application Load Balancer. Which steps would you take to apply high availability and fault tolerance to this application without ELB? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180504, 'original_assessment_id': 2566940, 'section': 'Highly Available Network Design', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>For this scenario, it is best to setup a self-monitoring EC2 instance with a virtual IP Address. You can use an Elastic IP and then write a custom script that checks the health of the EC2 instance and if the instance stops responding, the script will switch the Elastic IP address to a standby EC2 instance.</p> <p>A custom script&nbsp;enables one Amazon Elastic Compute Cloud (EC2) instance to monitor another Amazon EC2 instance and take over a private "virtual" IP address on instance failure. When used with two instances, the script enables a High Availability scenario where instances monitor each other and take over a shared virtual IP address if the other instance fails. It could easily be modified to run on a third-party monitoring or witness server to perform the VIP swapping on behalf of the two monitored nodes.</p> <p>Option 3 is incorrect because you don\'t have to postpone your deployment as you have the option to set up a self-monitoring EC2 instance with an EIP address.</p> <p>Option 4 is incorrect as even though the Auto Scaling group provides high availability and scalability, it still depends on ELB which is not available in this scenario.</p> <p>Option 5 is incorrect because although this option is feasible, the goal of the company is to move the application to the cloud and not to continue using its on-premise resources.&nbsp;</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/articles/leveraging-multiple-ip-addresses-for-virtual-ip-address-fail-over-in-6-simple-steps/">https://aws.amazon.com/articles/leveraging-multiple-ip-addresses-for-virtual-ip-address-fail-over-in-6-simple-steps/</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Write a script that checks the health of the EC2 instance. If the instance stops responding, the script will switch the elastic IP address to a standby EC2 instance.', 'Assign an Elastic IP address to the instance.', 'Postpone the deployment until you have fully converted the application to work with the ELB and Auto Scaling.', 'Launch the instance using Auto Scaling which will deploy the instance again if it becomes unhealthy.', 'Use Cloudfront with a custom origin pointed to your on-premise network where the web application is deployed.', '<p>Assign a new IPv6 address to the EC2 instance.</p>'], 'question': '<p>You are working for a software company that has moved a legacy application from an on-premise data center to the cloud. The legacy application requires a static IP address hard-coded into the backend, which blocks you from using an Application Load Balancer. <br><br>Which steps would you take to apply high availability and fault tolerance to this application without ELB? (Choose 2)</p>'}, 'related_lectures': [], 'correct_response': ['a', 'b'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': "For the user session management of your web application, you are tasked to implement a technical solution to consistently route the user's request to the same EC2 instance using sticky sessions. What are the two requirements to configure sticky sessions for your Classic Load Balancer?", '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180506, 'original_assessment_id': 2566942, 'section': 'ELB', 'prompt': {'relatedLectureIds': '', 'explanation': '<div> <p>By default, a Classic Load Balancer routes each request independently to the registered instance with the smallest load. However, you can use the&nbsp;<em>sticky session</em>&nbsp;feature (also known as&nbsp;<em>session affinity</em>), which enables the load balancer to bind a user\'s session to a specific instance. This ensures that all requests from the user during the session are sent to the same instance.</p> <p>&nbsp;To implement the stick session feature, you need to have 2 things:</p> <ul> <li>An HTTP/HTTPS load balancer.</li> <li>At least one healthy instance in each Availability Zone.</li> </ul> <p>The key to managing sticky sessions is to determine how long your load balancer should consistently route the user\'s request to the same instance. If your application has its own session cookie, then you can configure Elastic Load Balancing so that the session cookie follows the duration specified. If your application does not have its own session cookie, then you can configure Elastic Load Balancing to create a session cookie by specifying your own stickiness duration.</p> <p>Take note that these 2 types of EC2 instances are NOT required when you want to implement the sticky session. They are mainly used to improve the performance of the your EC2 instances but not necessarily helpful for the aforementioned feature.</p> <ul> <li>EC2 instance with Enhanced Networking</li> <li>An EC2 instance with a RAID volume</li> </ul> <p>&nbsp;</p> </div> <p><strong>Reference:</strong></p> <p><a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-sticky-sessions.html">https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-sticky-sessions.html</a></p> <p>&nbsp;</p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', '', ''], 'answers': ['<p>An HTTP/HTTPS load balancer and at least one healthy instance in each Availability Zone.</p>', '<p>A Network Load Balancer and at least one healthy instance in each Availability Zone.</p>', '<p>An HTTP/HTTPS load balancer and\xa0EC2 instance with a RAID volume</p>', '<p>A Network Load Balancer and at least two healthy instances in each Availability Zone.</p>', '<p>A Network Load Balancer and an\xa0EC2 instance with a RAID volume</p>'], 'question': "<p>For the user session management of your web application, you are tasked to implement a technical solution to consistently route the user's request to the same EC2 instance using sticky sessions. What are the two requirements to configure sticky sessions for your Classic Load Balancer?</p>"}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have triggered the creation of a snapshot of your EBS volume and is currently on-going. At this point, what are the things that the EBS volume can or cannot do?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180508, 'original_assessment_id': 2566944, 'section': 'EBS', 'prompt': {'explanation': '<p>Snapshots occur asynchronously which means that the point-in-time snapshot is created immediately, but the status of the snapshot is&nbsp;<code>pending</code>&nbsp;until the snapshot is complete (when all of the modified blocks have been transferred to Amazon S3), which can take several hours for large initial snapshots or subsequent snapshots where many blocks have changed. While it is completing, an in-progress snapshot is not affected by ongoing reads and writes to the volume hence, you can still use the volume.</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-snapshot.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-snapshot.html</a></p><p>&nbsp;</p>', 'answers': ['The volume can be used as normal while the snapshot is in progress.', 'The volume can be used in write-only mode while the snapshot is in progress.', 'The volume can be used in read-only mode while the snapshot is in progress.', 'The volume cannot be used until the snapshot completes.'], 'question': 'You have triggered the creation of a snapshot of your EBS volume and is currently on-going. At this point, what are the things that the EBS volume can or cannot do?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A startup based in Australia is deploying a new two-tier web application in AWS. The Australian company wants to store their most frequently used data in an in-memory data store to improve the retrieval and response time of their web application.\xa0 \xa0Which of the following is the most suitable service to be used for this requirement?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180510, 'original_assessment_id': 2566946, 'section': 'ElastiCache', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>Amazon ElastiCache is a web service that makes it easy to deploy, operate, and scale an in-memory data store or cache in the cloud. The service improves the performance of web applications by allowing you to retrieve information from fast, managed, in-memory data stores, instead of relying entirely on slower disk-based databases.</p> <p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://d1.awsstatic.com/elasticache/Databases@2x.2ccaf2321ff1e9c857d9405d62e04de7e087c6ad.png" width="750" height="285" /></p> <p>Option 1 is incorrect because DynamoDB is primarily used as a NoSQL database which supports both document and key-value store models. ElastiCache is a more suitable service to use than DynamoDB, if you need an in-memory data store.</p> <p>Option 2 is incorrect because RDS is mainly used as a relational database and not as a data storage for frequently used data.</p> <p>Option 4 is incorrect&nbsp;because Redshift is a data warehouse service and is not suitable to be used as an in-memory data store.</p> <p><strong>References:</strong></p> <p><a href="https://aws.amazon.com/elasticache/">https://aws.amazon.com/elasticache/</a></p> <p><a href="https://aws.amazon.com/products/databases/">https://aws.amazon.com/products/databases/</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p>DynamoDB</p>', '<p>Amazon RDS</p>', 'Amazon ElastiCache', '<p>Amazon Redshift</p>'], 'question': '<p>A startup based in Australia is deploying a new two-tier web application in AWS. The Australian company wants to store their most frequently used data in an in-memory data store to improve the retrieval and response time of their web application.\xa0 \xa0</p><p>Which of the following is the most suitable service to be used for this requirement?</p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:22:48Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are designing a multi-tier web application architecture that consists of a fleet of EC2 instances and an Oracle relational database server. It is required that the database is highly available and that you have full control over its underlying operating system. Which AWS service will you use for your database tier?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180512, 'original_assessment_id': 2566948, 'section': 'RDS', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>To achieve this requirement, you can deploy your Oracle database to Amazon EC2 instances with data replication between two different Availability Zones. Hence, option 4 is the correct answer. The deployment of this architecture can easily be achieved by using Cloudformation and Quick Start. Please refer to the reference link for information.</p><p>The Quick Start deploys the Oracle primary database (using the preconfigured, general-purpose starter database from Oracle) on an Amazon EC2 instance in the first Availability Zone. It then sets up a second EC2 instance in a second Availability Zone, copies the primary database to the second instance by using the&nbsp;<code class="code">DUPLICATE</code>&nbsp;command, and configures Oracle Data Guard.</p><p>Options 1 and 2 are incorrect because the scenario requires you to have access to the underlying operating system of the database server. Remember that Amazon RDS is a managed database service, which means that Amazon is the one that manages the underlying operating system of the database instance and not you.</p><p>Option 3 is incorrect since deploying to just one Availability Zone (AZ) will not make the database tier highly available. If that AZ went down, your database will be unavailable.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/quickstart/">https://aws.amazon.com/quickstart/</a></p><p><a href="https://docs.aws.amazon.com/quickstart/latest/oracle-database/architecture.html">https://docs.aws.amazon.com/quickstart/latest/oracle-database/architecture.html</a></p><p><a href="http://docs.aws.amazon.com/dms/latest/userguide/CHAP_Introduction.ReplicationInstance.html">http://docs.aws.amazon.com/dms/latest/userguide/CHAP_Introduction.ReplicationInstance.html</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['Amazon RDS', 'Amazon RDS with Multi-AZ deployments', 'Amazon EC2 instances with data replication in one Availability Zone', 'Amazon EC2 instances with data replication between two different Availability Zones'], 'question': '<p>You are designing a multi-tier web application architecture that consists of a fleet of EC2 instances and an Oracle relational database server. It is required that the database is highly available and that you have full control over its underlying operating system. <br><br>Which AWS service will you use for your database tier?</p>'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have a new e-commerce web application written in Angular framework which is deployed to a fleet of EC2 instances behind an Application Load Balancer. You configured the load balancer to perform health checks on these EC2 instances. What will happen if one of these EC2 instances failed the health checks?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180514, 'original_assessment_id': 2566950, 'section': 'ELB', 'prompt': {'explanation': '<p>In case that one of the EC2 instances failed a health check, the Application Load Balancer stops sending traffic to that instance.</p><p>Your Application Load Balancer periodically sends requests to its registered targets to test their status. These tests are called&nbsp;<em>health checks</em>. Each load balancer node routes requests only to the healthy targets in the enabled Availability Zones for the load balancer. Each load balancer node checks the health of each target, using the health check settings for the target group with which the target is registered. After your target is registered, it must pass one health check to be considered healthy. After each health check is completed, the load balancer node closes the connection that was established for the health check.</p><p>References:&nbsp;</p><p><a href="http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-healthchecks.html">http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-healthchecks.html</a>&nbsp;</p>', 'answers': ['The EC2 instance gets terminated automatically by the Application Load Balancer.', 'The EC2 instance gets quarantined by the Application Load Balancer for root cause analysis.', 'The EC2 instance is replaced automatically by the Application Load Balancer.', 'The Application Load Balancer stops sending traffic to the instance that failed its health check.'], 'question': 'You have a new e-commerce web application written in Angular framework which is deployed to a fleet of EC2 instances behind an Application Load Balancer. You configured the load balancer to perform health checks on these EC2 instances. <br /><br />What will happen if one of these EC2 instances failed the health checks?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multi-select', 'question_plain': 'Your team is planning to migrate a web application from your on-premise infrastructure to AWS cloud. Your team lead wants to ensure that even though the application will be in AWS, you can still manage the service and implement ongoing maintenance of packages. Which of the following AWS services can you use, which allows access to its underlying infrastructure? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180516, 'original_assessment_id': 2566952, 'section': 'Elastic Beanstalk', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>You can connect and manage the EC2 instance so Option 2 is correct. You can install new packages and perform changes on the underlying infrastructure of the EC2 instance such as Enhanced Networking, Encryption, and so forth.</p> <p>Elastic Beanstalk is a service that allows you to quickly deploy and manage your application in AWS. What it does is to automatically create EC2 instances for your application, which you can also manage just like a regular instance. Hence, Option 1 is correct.</p> <p><strong>Reference:</strong></p> <p><a href="https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/Welcome.html">https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/Welcome.html</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Elastic Beanstalk', 'EC2', 'DynamoDB', 'RDS', '<p>Lambda</p>', '<p>Amazon Athena</p>'], 'question': 'Your team is planning to migrate a web application from your on-premise infrastructure to AWS cloud. Your team lead wants to ensure that even though the application will be in AWS, you can still manage the service and implement ongoing maintenance of packages. <br><br>Which of the following AWS services can you use, which allows access to its underlying infrastructure? (Choose 2)'}, 'related_lectures': [], 'correct_response': ['a', 'b'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Your IT director assigned you the task of providing a single sign-on feature to all of your existing users who are using on-premise web applications.How will you implement this feature?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180518, 'original_assessment_id': 2566954, 'section': 'STS', 'prompt': {'explanation': '<p>You can authenticate users in your organization\'s network and then provide those users access to AWS without creating new AWS identities for them and requiring them to sign in with a separate user name and password.</p><p>This is known as the single sign-on (SSO) approach to temporary access. AWS STS supports open standards like Security Assertion Markup Language (SAML) 2.0, with which you can use Microsoft AD FS to leverage your Microsoft Active Directory.</p><p>You can also use SAML 2.0 to manage your own solution for federating user identities.<br /><br /></p><p>References:</p><p><a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp.html</a></p>', 'answers': ['Use IAM with SAML.', "Use the company's LDAP directory with IAM.", 'Use the AWS Secure Token service (STS) and SAML', 'Use IAM and OAuth.'], 'question': 'Your IT director assigned you the task of providing a single sign-on feature to all of your existing users who are using on-premise web applications.<br /><br />How will you implement this feature?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': "You've been instructed to create a duplicate environment in another region for your company's disaster recovery plan. Part of your environment relies on EC2 instances with pre-configured software. What step would you take to configure the instances in another region?", '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180520, 'original_assessment_id': 2566956, 'section': 'AMI', 'prompt': {'explanation': '<p>You can copy an Amazon Machine Image (AMI) within or across an AWS region using the AWS Management Console, the AWS command line tools or SDKs, or the Amazon EC2 API, all of which support the&nbsp;<code>CopyImage&nbsp;</code>action. You can copy both Amazon EBS-backed AMIs and instance store-backed AMIs. You can copy encrypted AMIs and AMIs with encrypted snapshots.</p><p>Copying a source AMI results in an identical but distinct target AMI with its own unique identifier. In the case of an Amazon EBS-backed AMI, each of its backing snapshots is, by default, copied to an identical but distinct target snapshot. (The one exception is when you choose to encrypt the snapshot.) You can change or deregister the source AMI with no effect on the target AMI. The reverse is also true.</p><p>There are no charges for copying an AMI. However, standard storage and data transfer rates apply.</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html</a></p>', 'answers': ['Create an AMI of the EC2 instance', 'Create an AMI of the EC2 instance and copy the AMI to the desired region', 'Use IAM permissions to make the EC2 instance shareable among other regions', 'None of the above'], 'question': "You've been instructed to create a duplicate environment in another region for your company's disaster recovery plan. Part of your environment relies on EC2 instances with pre-configured software. <br /><br />What step would you take to configure the instances in another region?"}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You had launched a travel photo sharing website using Amazon S3 to serve high-quality photos to visitors of your website. After a few days, you found out that there are other travel websites linking and using your photos. This resulted to a loss for your business. What is an effective method to mitigate this issue?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180522, 'original_assessment_id': 2566958, 'section': 'CloudFront', 'prompt': {'explanation': '<p>In Amazon S3, all objects by default are private. Only the object owner has permission to access these objects. However, the object owner can optionally share objects with others by creating a pre-signed URL, using their own security credentials, to grant time-limited permission to download the objects.</p><p>When you create a pre-signed URL for your object, you must provide your security credentials, specify a bucket name, an object key, specify the HTTP method (GET to download the object) and expiration date and time. The pre-signed URLs are valid only for the specified duration.</p><p>Anyone who receives the pre-signed URL can then access the object. For example, if you have a video in your bucket and both the bucket and the object are private, you can share the video with others by generating a pre-signed URL.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-signed-urls.html">https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-signed-urls.html</a></p><p>&nbsp;</p>', 'answers': ['Configure your S3 bucket to remove public read access and use pre-signed URLs with expiry dates.', 'Use Cloud Front distributions for your photos.', 'Block the IP addresses of the offending websites using NACL.', 'Store photos on an Amazon EBS volume of the web server.'], 'question': 'You had launched a travel photo sharing website using Amazon S3 to serve high-quality photos to visitors of your website. After a few days, you found out that there are other travel websites linking and using your photos. This resulted to a loss for your business. <br /><br />What is an effective method to mitigate this issue?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A media company has a workflow that sends video files from their on-premise system to AWS for transcoding. They use a fleet of EC2 instances that pull transcoding jobs from SQS. Why is SQS an appropriate service for this scenario?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180524, 'original_assessment_id': 2566960, 'section': 'SQS', 'prompt': {'explanation': '<p>Option 4 is correct. Horizontal scaling means increasing the number of your message producers (making SendMessage requests) and consumers (making ReceiveMessage and DeleteMessage requests) in order to increase your overall queue throughput. You can scale horizontally by increasing the number of threads on a client, adding clients, or both. You should achieve essentially linear gains in queue throughput as you add more clients. For example, if you double the number of clients, you can get twice the throughput.</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-throughput-horizontal-scaling-and-batching.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-throughput-horizontal-scaling-and-batching.html</a></p>', 'answers': ['SQS guarantees the order of the messages.', 'SQS synchronously provides transcoding output.', 'SQS checks the health of the worker instances.', 'SQS helps to facilitate horizontal scaling of encoding tasks.'], 'question': 'A media company has a workflow that sends video files from their on-premise system to AWS for transcoding. They use a fleet of EC2 instances that pull transcoding jobs from SQS. <br /><br />Why is SQS an appropriate service for this scenario?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are using a combination of API\xa0Gateway and Lambda for the\xa0web services of your online web portal that is being accessed by hundreds of thousands of clients each day. Your company will be announcing a new revolutionary product and it is expected that your web portal will receive a massive amount of visitors all around the globe.\xa0How can you\xa0protect your backend systems and applications from traffic spikes?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180526, 'original_assessment_id': 2566962, 'section': 'API Gateway', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>Amazon API Gateway provides throttling at multiple levels including global and by a service call. Throttling limits can be set for standard rates and bursts. For example, API owners can set a rate limit of 1,000 requests per second for a specific method in their REST APIs, and also configure Amazon API Gateway to handle a burst of 2,000 requests per second for a few seconds.</p> <p>Amazon API Gateway tracks the number of requests per second. Any requests over the limit will receive a 429 HTTP response. The client SDKs generated by Amazon API Gateway retry calls automatically when met with this response.</p> <p>Option 2 is incorrect because although it can scale using AWS Edge locations, you still need to configure the throttling to further manage the bursts of your APIs.</p> <p>Option 3 is incorrect because API Gateway is a fully managed service and hence, you do not have access to its underlying resources.</p> <p>Option 4 is incorrect because RDS has Multi-AZ and Read Replica capabilities, and not API Gateway.</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/api-gateway/faqs/#Throttling_and_Caching">https://aws.amazon.com/api-gateway/faqs/#Throttling_and_Caching</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p>Use throttling limits in API Gateway</p>', '<p>API Gateway will automatically scale and handle massive\xa0traffic spikes so you do not have to do anything.</p>', '<p>Manually upgrade the EC2 instances being used by\xa0API Gateway</p>', '<p>Deploy\xa0Multi-AZ in API Gateway with Read Replica</p>'], 'question': '<p>You are using a combination of API\xa0Gateway and Lambda for the\xa0web services of your online web portal that is being accessed by hundreds of thousands of clients each day. Your company will be announcing a new revolutionary product and it is expected that your web portal will receive a massive amount of visitors all around the globe.\xa0How can you\xa0protect your backend systems and applications from traffic spikes?</p>'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A software development company has recently invested 20 million dollars to build their own artificial intelligence APIs and AI-powered chatbots. You are hired as a Solutions Architect to build a low-cost prototype on their AWS cloud infrastructure. Which of the following combination of AWS services will provide user authentication, scalable object storage and will allow you to run your code without the need to host it in an EC2 instance?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180528, 'original_assessment_id': 2566964, 'section': '', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>In this scenario, it is best to use a combination of Cognito, Lambda, and S3. Cognito will handle the user authentication; Lambda provides the serverless architecture that allows you to run your code without deploying it in an EC2 instance and finally, S3 provides a scalable object storage.</p> <p>AWS Lambda lets you run code without provisioning or managing servers. You pay only for the compute time you consume - there is no charge when your code is not running.</p> <p>With Lambda, you can run code for virtually any type of application or backend service - all with zero administration. Just upload your code and Lambda takes care of everything required to run and scale your code with high availability. You can set up your code to automatically trigger from other AWS services or call it directly from any web or mobile app.</p> <p>&nbsp;</p> <p><strong>References:</strong></p> <p><a href="https://aws.amazon.com/lambda/">https://aws.amazon.com/lambda/</a></p> <p><a href="https://aws.amazon.com/cognito/">https://aws.amazon.com/cognito/</a></p> <p><a href="https://aws.amazon.com/blogs/machine-learning/how-to-deploy-deep-learning-models-with-aws-lambda-and-tensorflow/">https://aws.amazon.com/blogs/machine-learning/how-to-deploy-deep-learning-models-with-aws-lambda-and-tensorflow/</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p>Cognito, Lambda, S3</p>', '<p>AWS IoT, Cognito, S3</p>', '<p>IAM, Lambda, EBS Volumes</p>', '<p>IAM, Cognito, EBS Volumes</p>'], 'question': '<p>A software development company has recently invested 20 million dollars to build their own artificial intelligence APIs and AI-powered chatbots. You are hired as a Solutions Architect to build a low-cost prototype on their AWS cloud infrastructure. Which of the following combination of AWS services will provide user authentication, scalable object storage and will allow you to run your code without the need to host it in an EC2 instance?</p>'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are a Solutions Architect in your company working with 3 DevOps Engineers under you. One of the engineers accidentally deleted a file hosted in Amazon S3 which has caused disruption of service. What can you do to prevent this from happening again?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180530, 'original_assessment_id': 2566966, 'section': 'S3', 'prompt': {'explanation': '<p>To avoid accidental deletion in Amazon S3 bucket, you can:</p><ul><li>Enable Versioning</li><li>Enable MFA (Multi-Factor Authentication) Delete</li></ul><p>Versioning is a means of keeping multiple variants of an object in the same bucket. You can use versioning to preserve, retrieve, and restore every version of every object stored in your Amazon S3 bucket. With versioning, you can easily recover from both unintended user actions and application failures.</p><p>If the MFA (Multi-Factor Authentication) Delete is enabled, it requires additional authentication for either of the following operations.</p><ul><li>-Change the versioning state of your bucket</li><li>-Permanently delete an object version</li></ul><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html">http://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html</a></p>', 'answers': ['Use S3 Infrequently Accessed storage to store the data on.', 'Enable S3 Versioning and Multi-Factor Authentication Delete on the bucket.', 'Setup a signed URL to all users.', 'Create an IAM bucket policy that disables delete operation.'], 'question': 'You are a Solutions Architect in your company working with 3 DevOps Engineers under you. One of the engineers accidentally deleted a file hosted in Amazon S3 which has caused disruption of service. <br /><br />What can you do to prevent this from happening again?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'There are a lot of outages in the Availability Zone of your RDS database instance to the point that you have lost access to the database. What could you do to prevent losing access to your database in case that this event happens again?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180532, 'original_assessment_id': 2566968, 'section': 'RDS', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>Amazon RDS Multi-AZ deployments provide enhanced availability and durability for Database (DB) Instances, making them a natural fit for production database workloads. When you provision a Multi-AZ DB Instance, Amazon RDS automatically creates a primary DB Instance and synchronously replicates the data to a standby instance in a different Availability Zone (AZ). Each AZ runs on its own physically distinct, independent infrastructure, and is engineered to be highly reliable.</p> <p>In case of an infrastructure failure, Amazon RDS performs an automatic failover to the standby (or to a read replica in the case of Amazon Aurora), so that you can resume database operations as soon as the failover is complete.&nbsp;</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/rds/details/multi-az/">https://aws.amazon.com/rds/details/multi-az/</a></p> <p>&nbsp;</p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'answers': ['Make a snapshot of the database', 'Enabled Multi-AZ failover ', 'Increase the database instance size', 'Create a read replica'], 'question': 'There are a lot of outages in the Availability Zone of your RDS database instance to the point that you have lost access to the database. What could you do to prevent losing access to your database in case that this event happens again?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are working for a large financial company as an IT consultant. Your role is to help their development team to build a highly available web application using stateless web servers. In this scenario, which AWS services are suitable for storing session state data? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180534, 'original_assessment_id': 2566970, 'section': 'DynamoDB', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>You can store session state data on both DynamoDB and ElastiCache. These AWS services provide high performance storage of key-value pairs which can be used to build a highly available web application.</p><div>&nbsp;</div><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/caching/database-caching/">https://aws.amazon.com/caching/database-caching/</a></p><p><a href="https://aws.amazon.com/caching/session-management/">https://aws.amazon.com/caching/session-management/</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['EC2', 'DynamoDB', 'S3', 'ElastiCache', 'Glacier', 'Redshift'], 'question': 'You are working for a large financial company as an IT consultant. Your role is to help their development team to build a highly available web application using stateless web servers. In this scenario, which AWS services are suitable for storing session state data? (Choose 2)'}, 'related_lectures': [], 'correct_response': ['b', 'd'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multi-select', 'question_plain': 'A startup company is in a hurry in building an API for their mobile app to compete with their rival company. Based on their technical requirements, you recommended to build a serverless architecture instead of typically hosting the API in an EC2 instance.   Which of the following AWS Services can you use to build and run serverless applications? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180536, 'original_assessment_id': 2566972, 'section': 'Serverless', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>AWS provides a set of fully managed services such as Lambda, API Gateway, DynamoDB, and many others that you can use to build and run serverless applications. Serverless applications don\'t require provisioning, maintaining, and administering servers for backend components such as compute, databases, storage, stream processing, message queueing, and more.</p> <p>You also no longer need to worry about ensuring application fault tolerance and availability. Instead, AWS handles all of these capabilities for you. This allows you to focus on product innovation while enjoying faster time-to-market.</p> <p>&nbsp;</p> <p><strong>Reference:</strong>;</p> <p><a href="https://aws.amazon.com/serverless/">https://aws.amazon.com/serverless/</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['<p>AWS API Gateway</p>', '<p>AWS Lambda</p>', '<p>AWS DynamoDB</p>', '<p>Reserved EC2 Instances</p>', '<p>SWF</p>', '<p>IAM</p>'], 'question': '<p>A startup company is in a hurry in building an API for their mobile app to compete with their rival company. Based on their technical requirements, you recommended to build a serverless architecture instead of typically hosting the API in an EC2 instance.   </p><p>Which of the following AWS Services can you use to build and run serverless applications? (Choose 3)</p>'}, 'related_lectures': [], 'correct_response': ['a', 'b', 'c'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have a new joiner in your organization. You had provisioned an IAM user for the new employee in AWS however, the user is not able to perform any actions. What could be the reason for this?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180538, 'original_assessment_id': 2566974, 'section': 'IAM', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>The reason for this issue is that IAM users are created with no permissions&nbsp;by default. That means that when you created the new IAM user, you might not provisioned any permissions to the user. Hence, option 3 is correct and conversely, options 1 and 2 are wrong.</p><p>Option 4 is incorrect because provisions are applied immediately, and not after 24 hours.</p><p>The IAM user might need to make API calls or use the AWS CLI or the Tools for Windows PowerShell. In that case, create an access key (an access key ID and a secret access key) for that user. This is called Programmatic access.</p><p>If the user needs to access AWS resources from the AWS Management Console, create a password and provide it to the user.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/iam/details/manage-users/">https://aws.amazon.com/iam/details/manage-users/</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['IAM users are created by default with partial permissions', 'IAM users are created by default with full permissions', 'IAM users are created by default with no permissions', 'You need to wait for 24 hours for the new IAM user to have access.'], 'question': '<p>You have a new joiner in your organization. You had provisioned an IAM user for the new employee in AWS however, the user is not able to perform any actions. What could be the reason for this?</p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multi-select', 'question_plain': 'Your company announced that there would be a surprise IT audit on all of the AWS resources being used in the production environment. During the audit activities, it was noted that you are using a Reserved EC2 instance on one of your applications. They argued that you should have used Spot EC2 instances instead as it is cheaper than the Reserved Instance.\xa0 \xa0Which of the following are the characteristics and benefits of using a standard Reserved EC2 instance, which you can use as justification? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180540, 'original_assessment_id': 2566976, 'section': 'EC2', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>RIs provide you with a significant discount (up to 75%) compared to On-Demand instance pricing. You have the flexibility to change families, OS types, and tenancies while benefiting from RI pricing when you use Convertible RIs. One important thing to remember here is that Reserved Instances are <span style="text-decoration: underline;">not</span> physical instances, but rather a billing discount applied to the use of On-Demand Instances in your account.&nbsp;</p> <p>When your computing needs change, you can modify your Standard or Convertible Reserved Instances and continue to take advantage of the billing benefit. You can modify the Availability Zone, scope, network platform, or instance size (within the same instance type) of your Reserved Instance. You can also&nbsp;sell your unused instance on the Reserved Instance Marketplace.</p> <p>Option 1 is correct because you can sell your unused instances in the Reserved Instance Marketplace.&nbsp;</p> <p>Option 2 is wrong because you can indeed modify the Availability Zone, scope, network platform, or instance size of your Reserved Instance as long as it is within the same instance type.&nbsp;</p> <p>Option 3 is correct because you can definitely use Auto Scaling on Reserved Instances. Remember that it is basically just a billing concept hence, you can use features like Auto Scaling with your Reserved Instances, same as with your Spot and On-Demand instances. Keep in mind that Reserved Instances are not physical servers/instances, but rather a billing discount applied to the use of On-Demand Instances in your account.&nbsp;</p> <p>Option 4 is wrong because that is the description of a Dedicated instance and not a Reserved Instance. A Dedicated instance runs in a VPC on hardware that\'s dedicated to a single customer.</p> <p>Option 5 is correct, because reserved instances can be used to lower costs. Reserved Instances provide you with a discount on usage of EC2 instances, and a capacity reservation when they are applied to a specific Availability Zone, giving you additional confidence that you will be able to launch the instances you have reserved when you need them.</p> <p>&nbsp;</p> <p><strong>References:</strong></p> <p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ri-modifying.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ri-modifying.html</a></p> <p><a href="https://aws.amazon.com/ec2/pricing/reserved-instances/">https://aws.amazon.com/ec2/pricing/reserved-instances/</a></p> <p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-reserved-instances.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-reserved-instances.html</a></p> <p><a href="https://stackoverflow.com/questions/30873849/use-reserved-instance-and-autoscaling-group">https://stackoverflow.com/questions/30873849/use-reserved-instance-and-autoscaling-group</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', '', ''], 'answers': ['<p>You can sell a standard Reserved instance on the Reserved Instance Marketplace.</p>', 'You cannot modify the Availability Zone, scope, network platform or instance size. ', 'It can be applied to instances launched by Auto Scaling.', "<p>It runs in a VPC on hardware that's dedicated to a single customer.</p>", '<p>It provides you with a significant discount compared to On-Demand instance pricing</p>'], 'question': '<p>Your company announced that there would be a surprise IT audit on all of the AWS resources being used in the production environment. During the audit activities, it was noted that you are using a Reserved EC2 instance on one of your applications. They argued that you should have used Spot EC2 instances instead as it is cheaper than the Reserved Instance.\xa0 \xa0</p><p>Which of the following are the characteristics and benefits of using a standard Reserved EC2 instance, which you can use as justification? (Choose 3)</p>'}, 'related_lectures': [], 'correct_response': ['a', 'c', 'e'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as a Solutions Architect for a government project in which they are building an online portal to allow people to pay their taxes and claim their tax refunds online. Due to the confidentiality of data, the security policy requires that the application hosted in EC2 encrypts the data first before writing it to the disk for storage.\xa0 \xa0In this scenario, which service would you use to meet this requirement?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180542, 'original_assessment_id': 4371674, 'section': 'VPC', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>AWS Key Management Service (AWS KMS) is a managed service that makes it easy for you to create and control the encryption keys used to encrypt your data. The master keys that you create in AWS KMS are protected by FIPS 140-2 validated cryptographic modules. AWS KMS is integrated with most other AWS services that encrypt your data with encryption keys that you manage. AWS KMS is also integrated with AWS CloudTrail to provide encryption key usage logs to help meet your auditing, regulatory and compliance needs.</p> <p>In this scenario, you can configure your application to use the KMS API to encrypt all data before saving it to disk. Hence, Option 4 is the correct answer.</p> <p>Option 1 is incorrect because AWS Security Token Service (STS) is a web service that enables you to request temporary, limited-privilege credentials for AWS Identity and Access Management (IAM) users or for users that you authenticate (federated users). It is not used for encrypting data unlike KMS.</p> <p>Option 2 is incorrect because although EBS encryption provides additional security for the EBS volumes, the application could not use this service to encrypt or decrypt each individual data that it writes on the disk. It is better to use KMS API instead to automatically encrypt the data before saving it to disk.</p> <p>Option 3 is incorrect because EFS is a storage service and does not provide encryption services unlike KMS API.</p> <p>&nbsp;</p> <p><strong>Reference: </strong></p> <p>https://docs.aws.amazon.com/kms/latest/developerguide/programming-top.html</p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p>Security Token Service</p>', '<p>EBS encryption</p>', '<p>Elastic File System (EFS)</p>', '<p>AWS KMS API</p>'], 'question': '<p>You are working as a Solutions Architect for a government project in which they are building an online portal to allow people to pay their taxes and claim their tax refunds online. Due to the confidentiality of data, the security policy requires that the application hosted in EC2 encrypts the data first before writing it to the disk for storage.\xa0 \xa0</p><p>In this scenario, which service would you use to meet this requirement?</p>'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are working as a Solutions Architect in a new startup that provides storage for high-quality photos which are infrequently accessed by the users. To make the architecture cost-effective, you designed the cloud service to use an S3 One Zone-Infrequent Access (S3 One Zone-IA) storage type for free users and an S3 Standard-Infrequent Access (S3 Standard-IA) storage type for premium users. When you manager found out about this, he asked you about the trade-offs of using S3 One Zone-IA instead of the S3 Standard-IA.\xa0 What will you say to your manager? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180544, 'original_assessment_id': 4814324, 'section': 'S3', 'prompt': {'relatedLectureIds': '', 'explanation': '<div> <p>Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) is an Amazon S3 storage class for data that is accessed less frequently but requires rapid access when needed. Unlike other Amazon object storage classes, which store data in a minimum of three Availability Zones (AZs), S3 One Zone-IA stores data in a single AZ. Because of this, storing data in S3 One Zone-IA costs 20% less than storing it in S3 Standard-IA. S3 One Zone-IA is ideal for customers who want a lower cost option for infrequently accessed data but do not require the availability and resilience of S3 Standard or S3 Standard-IA storage. It&rsquo;s a good choice, for example, for storing secondary backup copies of on-premises data or easily re-creatable data, or for storage used as an S3 Cross-Region Replication target from another AWS Region.</p> <p>S3 One Zone-IA offers the same high durability, high throughput, and low latency of Amazon S3 Standard and S3 Standard-IA, with a low per GB storage price and per GB retrieval fee. The S3 One Zone-IA storage class is set at the object level and can exist in the same bucket as S3 Standard and S3 Standard-IA, allowing you to use S3 Lifecycle Policies to automatically transition objects between storage classes without any application changes.</p> <p><strong>Key Features:</strong></p> <ul> <li>Same low latency and high throughput performance of S3 Standard and S3 Standard-IA</li> <li>Designed for durability of 99.999999999% of objects in a single Availability Zone, but data will be lost in the event of Availability Zone destruction</li> <li>Designed for 99.5% availability over a given year</li> <li>Backed with the&nbsp;Amazon S3 Service Level Agreement for availability</li> <li>Supports SSL for data in transit and encryption of data at rest</li> <li>Lifecycle management for automatic migration of objects</li> </ul> </div> <div>&nbsp;</div> <div>Remember that since the S3 One Zone-IA stores data in a single AWS Availability Zone, data stored in this storage class will be lost in the event of Availability Zone destruction.</div> <div>&nbsp;</div> <div>&nbsp;</div> <div><strong>Reference</strong>:&nbsp;</div> <div>&nbsp;</div> <div><a href="https://aws.amazon.com/s3/storage-classes/#Amazon_S3_One_Zone-Infrequent_Access">https://aws.amazon.com/s3/storage-classes/#Amazon_S3_One_Zone-Infrequent_Access</a></div>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['<p>Unlike other Amazon object storage classes, which store data in a minimum of three Availability Zones (AZs), S3 One Zone-IA stores data in a single AZ.</p>', '<p>Storing data in S3 One Zone-IA costs less than storing it in S3 Standard-IA.</p>', '<p>Storing data in S3 One Zone-IA costs more than storing it in S3 Standard-IA but provides more durability.</p>', '<p>Unlike other Amazon object storage classes, which store data in a minimum of three Availability Zones (AZs), S3 One Zone-IA stores data in two AZs only. Hence the name, One Zone-IA since the data replication is skipped in one Availability Zone.</p>', '<p>S3 One Zone-IA offers the same high durability, high throughput, and low latency of Amazon S3 Standard and S3 Standard-IA, with a low per GB storage price and per GB retrieval fee.</p>', '<p>S3 One Zone-IA offers a lower durability and low throughput compared with Amazon S3 Standard and S3 Standard-IA which is why it has a low per GB storage price and per GB retrieval fee.</p>'], 'question': '<p>You are working as a Solutions Architect in a new startup that provides storage for high-quality photos which are infrequently accessed by the users. To make the architecture cost-effective, you designed the cloud service to use an S3 One Zone-Infrequent Access (S3 One Zone-IA) storage type for free users and an S3 Standard-Infrequent Access (S3 Standard-IA) storage type for premium users. When you manager found out about this, he asked you about the trade-offs of using S3 One Zone-IA instead of the S3 Standard-IA.\xa0 </p><p>What will you say to your manager? (Choose 3)</p>'}, 'related_lectures': [], 'correct_response': ['a', 'b', 'e'], 'updated': '2018-11-21T07:22:46Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A Docker application, which is running on an Amazon ECS cluster behind a load balancer, is heavily using DynamoDB. You are instructed to improve the database performance by distributing the workload evenly and using the provisioned throughput efficiently.\xa0 \xa0 Which of the following would you consider to implement for your DynamoDB table?', '_class': 'assessment', 'created': '2018-11-21T07:22:46Z', 'id': 6180546, 'original_assessment_id': 5802010, 'section': 'DynamoDB', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>The partition key portion of a table\'s primary key determines the logical partitions in which a table\'s data is stored. This in turn affects the underlying physical partitions. Provisioned I/O capacity for the table is divided evenly among these physical partitions. Therefore a partition key design that doesn\'t distribute I/O requests evenly can create "hot" partitions that result in throttling and use your provisioned I/O capacity inefficiently.</p> <p>The optimal usage of a table\'s provisioned throughput depends not only on the workload patterns of individual items, but also on the partition-key design. This doesn\'t mean that you must access all partition key values to achieve an efficient throughput level, or even that the percentage of accessed partition key values must be high. It does mean that the more distinct partition key values that your workload accesses, the more those requests will be spread across the partitioned space. In general, you will use your provisioned throughput more efficiently as the ratio of partition key values accessed to the total number of partition key values increases.</p> <p>One example for this is the use of partition keys with high-cardinality attributes, which have a large number of distinct values for each item. Hence, Option 2 is the correct answer.</p> <p>Option 1 is incorrect because instead of reducing the number of partition keys in your DynamoDB table, you should actually add more to improve its performance to distribute the I/O requests evenly and not avoid "hot" partitions.</p> <p>Option 3 is incorrect because this is the exact opposite of the correct answer. Remember that the more distinct partition key values your workload accesses, the more those requests will be spread across the partitioned space. Conversely, the less distinct partition key values, the less evenly spread it would be across the partitioned space, which effectively slows the performance.</p> <p>Option 4 is incorrect because, just like Option 2, a composite primary key will provide more partition for the table and in turn, improves the performance. Hence, it should be used and not avoided.</p> <p><strong>References:</strong></p> <p><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-partition-key-uniform-load.html">https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-partition-key-uniform-load.html</a></p> <p><a href="https://aws.amazon.com/blogs/database/choosing-the-right-dynamodb-partition-key/"> https://aws.amazon.com/blogs/database/choosing-the-right-dynamodb-partition-key/</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p>Reduce the number of partition keys in the DynamoDB table.</p>', '<p>Use partition keys with high-cardinality attributes, which have a large number of distinct values for each item.</p>', '<p>Use partition keys with low-cardinality attributes, which have a few number of distinct values for each item.</p>', '<p>Avoid using a composite primary key, which is composed of a partition key and a sort key.</p>'], 'question': '<p>A Docker application, which is running on an Amazon ECS cluster behind a load balancer, is heavily using DynamoDB. You are instructed to improve the database performance by distributing the workload evenly and using the provisioned throughput efficiently.\xa0 \xa0 </p><p>Which of the following would you consider to implement for your DynamoDB table?</p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:22:46Z'}], 'previous': None, 'next': None}, 'title': 'AWS Certified Solutions Architect Associate Practice Test 1'}, {'type': 'practice-test', 'quiz_data': {'count': 65, 'results': [{'assessment_type': 'multiple-choice', 'question_plain': 'The operations team of your company asked you for a way to monitor the health of your production EC2 instances in AWS. You told them to use the CloudWatch service.Which of the following metrics is not available by default in CloudWatch?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104898, 'original_assessment_id': 2566808, 'section': 'CloudWatch', 'prompt': {'explanation': '<p>Memory Usage is a metric not available by default in CloudWatch. You need to add a custom metric for it to work.</p><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/mon-scripts.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/mon-scripts.html</a></p>', 'answers': ['CPU Usage', 'Memory Usage', 'Disk Read operations', 'Network In and Out'], 'question': 'The operations team of your company asked you for a way to monitor the health of your production EC2 instances in AWS. You told them to use the CloudWatch service.<br /><br />Which of the following metrics is not available by default in CloudWatch?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are a Solutions Architect working with a company that uses Chef Configuration management in their datacenter. Which service is designed to let the customer leverage existing Chef recipes in AWS?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104900, 'original_assessment_id': 2566810, 'section': 'OpsWorks', 'prompt': {'explanation': '<p>AWS OpsWorks is a configuration management service that provides managed instances of Chef and Puppet. Chef and Puppet are automation platforms that allow you to use code to automate the configurations of your servers. OpsWorks lets you use Chef and Puppet to automate how servers are configured, deployed, and managed across your Amazon EC2 instances or on-premises compute environments. OpsWorks has three offerings - AWS Opsworks for Chef Automate, AWS OpsWorks for Puppet Enterprise, and AWS OpsWorks Stacks.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/opsworks/">https://aws.amazon.com/opsworks/</a></p><p>&nbsp;</p>', 'answers': ['Amazon Simple Workflow Service', 'AWS Elastic Beanstalk', 'AWS CloudFormation', 'AWS OpsWorks'], 'question': 'You are a Solutions Architect working with a company that uses Chef Configuration management in their datacenter. Which service is designed to let the customer leverage existing Chef recipes in AWS?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You work for a leading university as an AWS Infrastructure Engineer and also as a professor to aspiring AWS architects. As a way to familiarize your students with AWS, you gave them a project to host their applications to an EC2 instance. One of your students created an instance to host their online enrollment system project but is having a hard time connecting to their newly created EC2 instance. Your students have explored all of the troubleshooting guides by AWS and narrowed it down to login issues.\xa0 \xa0Which of the following can you use to log into an EC2 instance?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104890, 'original_assessment_id': 2566800, 'section': 'EC2', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['Custom EC2 password', 'EC2 Connection Strings', 'Key Pairs', 'Access Keys'], 'question': '<p>You work for a leading university as an AWS Infrastructure Engineer and also as a professor to aspiring AWS architects. As a way to familiarize your students with AWS, you gave them a project to host their applications to an EC2 instance. One of your students created an instance to host their online enrollment system project but is having a hard time connecting to their newly created EC2 instance. Your students have explored all of the troubleshooting guides by AWS and narrowed it down to login issues.\xa0 \xa0</p><p>Which of the following can you use to log into an EC2 instance?</p>', 'explanation': '<p>Amazon EC2 uses public&ndash;key cryptography to encrypt and decrypt login information. Public&ndash;key cryptography uses a public key to encrypt a piece of data, such as a password, then the recipient uses the private key to decrypt the data. The public and private keys are known as a&nbsp;<em>key pair</em>.</p><p>To log in to your instance, you must create a key pair, specify the name of the key pair when you launch the instance, and provide the private key when you connect to the instance.&nbsp;On a Linux instance, the public key content is placed in an entry within&nbsp;<code>~/.ssh/authorized_keys</code>. This is done at boot time and enables you to securely access your instance using the private key instead of a password.</p><ul><li>Options 1 and 2 are incorrect as both&nbsp;Custom EC2 password and EC2 Connection Strings do not exist.</li><li>Option 4 is incorrect as Access Keys are used for API calls and not for logging in to EC2.</li></ul><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html</a></p><p>&nbsp;</p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as an IT consultant for a major telecommunications company. They have an application using an Oracle database deployed in a large EC2 instance which is used for their infrequently accessed data. In this scenario, what is the most cost-effective storage type for the EC2 instance that hosts the database?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104904, 'original_assessment_id': 2566814, 'section': 'EBS', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['<p>EBS General Purpose SSD</p>', '<p>Provisioned IOPS SSD</p>', '<p>Throughput Optimized HDD</p>', '<p>Cold HDD</p>'], 'question': '<p>You are working as an IT consultant for a major telecommunications company. They have an application using an Oracle database deployed in a large EC2 instance which is used for their infrequently accessed data. In this scenario, what is the most cost-effective storage type for the EC2 instance that hosts the database?</p>', 'explanation': '<p>Cold HDD volumes provide low-cost magnetic storage that defines performance in terms of throughput rather than IOPS. With a lower throughput limit than Throughput Optimized HDD, this is a good fit ideal for large, sequential cold-data workloads. If you require infrequent access to your data and are looking to save costs, Cold HDD provides inexpensive block storage. Take note that bootable Cold HDD volumes are not supported.</p> <p>Cold HDD provides the lowest cost HDD volume and is designed for less frequently accessed workloads. Hence, Option 4 is the correct answer.</p> <p>Option 1 is incorrect because a General purpose SSD volume costs more and it is mainly used for a wide variety of workloads.&nbsp;It is recommended to be used as system boot volumes, virtual desktops, low-latency interactive apps, and many more.</p> <p>Option 2 is incorrect because Provisioned IOPS HDD costs more than the Cold HDD and thus, not cost-effective for this scenario. It provides the highest performance SSD volume for mission-critical low-latency or high-throughput workloads, which is not needed in the scenario.</p> <p>Option 3 is incorrect because although Throughput Optimized HDD is cheaper than HDD, it is primarily designed and used for frequently accessed, throughput-intensive workloads. Cold HDD perfectly fits the description as it is used for their infrequently accessed data and provides the lowest cost, unlike Throughput Optimized HDD.</p> <p>&nbsp;</p> <p><strong>References: </strong></p> <p><a href="https://aws.amazon.com/ebs/details/">https://aws.amazon.com/ebs/details/</a></p> <p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html"> https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html</a></p>'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are building a transcription service for a startup company in which a fleet of EC2 worker instances process an uploaded  audio file and generate a text file as an output. You must store both of these files in the same durable storage until the text file is retrieved by the uploader. Due to an expected demand, you have to ensure that the storage is scalable.Which storage option in AWS can you use in this situation, which is both cost-efficient and scalable?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104906, 'original_assessment_id': 2566816, 'section': 'S3', 'prompt': {'explanation': '<p>In this scenario, the best option is to use Amazon S3. It&rsquo;s a simple storage service that offers a highly-scalable, reliable, and low-latency data storage infrastructure at very low costs.</p><p>Options 1 and 4 are incorrect because these services do not provide durable storage.</p><p>Option 2 is incorrect because Amazon Glacier is mainly used for data archives with data retrieval times that can take some few hours. Hence, it is not suitable for the transcription service where the data are stored and frequently accessed.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/s3/faqs/">https://aws.amazon.com/s3/faqs/</a></p><p>&nbsp;</p>', 'answers': ['Multiple Amazon EBS volume with snapshots', 'A single Amazon Glacier vault', 'A single Amazon S3 bucket', 'Multiple instance stores'], 'question': 'You are building a transcription service for a startup company in which a fleet of EC2 worker instances process an uploaded  audio file and generate a text file as an output. You must store both of these files in the same durable storage until the text file is retrieved by the uploader. Due to an expected demand, you have to ensure that the storage is scalable.<br /><br />Which storage option in AWS can you use in this situation, which is both cost-efficient and scalable?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'As an AWS Cloud Consultant working for a record company, you are building an application that will store both key-value store and document models like band ID, album ID, song ID and composer ID.\xa0 \xa0Which AWS service will suit your needs for your application?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104902, 'original_assessment_id': 2566812, 'section': 'DynamoDB', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['AWS RDS', 'DynamoDB', 'Oracle RDS', 'Elastic Map Reduce'], 'question': '<p>As an AWS Cloud Consultant working for a record company, you are building an application that will store both key-value store and document models like band ID, album ID, song ID and composer ID.\xa0 \xa0</p><p>Which AWS service will suit your needs for your application?</p>', 'explanation': '<p>Amazon DynamoDB is a fast and flexible NoSQL database service for all applications that need consistent, single-digit millisecond latency at any scale. It is a fully managed cloud database and supports both document and key-value store models. Its flexible data model, reliable performance, and automatic scaling of throughput capacity makes it a great fit for mobile, web, gaming, ad tech, IoT, and many other applications.</p> <p>Option 1 is incorrect because RDS is a relational database while DynamoDB is non-relational.</p> <p>Option 3 is incorrect because Oracle RDS itself is a relational database.</p> <p>Option 4 is incorrect because it is used for large scale data warehouse service for use with business intelligence tools.</p> <p>The following diagram shows an example of data stored as key-value pairs in DynamoDB:</p> <p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://udemy-images.s3.amazonaws.com/redactor/raw/2018-10-23_05-24-29-74b3e6dadc8ce683ccd2a5bd00f99889.png" /></p> <p><strong>References:</strong></p> <p><a href="https://aws.amazon.com/dynamodb/">https://aws.amazon.com/dynamodb/</a></p> <p><a href="https://aws.amazon.com/nosql/key-value/">https://aws.amazon.com/nosql/key-value/</a></p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as a new Solutions Architect for a large financial company. You are instructed by your CTO to share the best practices for using Auto Scaling, SQS, and EC2 to the DevOps team. Which of the following items is not a best practice in AWS?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104908, 'original_assessment_id': 2566818, 'section': 'AMI', 'prompt': {'explanation': '<p>All of the options are best practices except for the first one. Remember that an AMI is a regional resource and if you need to use this to another region, you have to make a copy of it.&nbsp;</p><p>Correct answers are:</p><ul><li>-Use Auto Scaling to automatically deploy new EC2 instances if there is a sudden spike in application requests.</li><li>-Set up CloudWatch alarms to automatically send notifications if there is an issue in one of the EC2 instances.</li><li>-Set up an IAM role to grant Amazon EC2 instances permission to access an S3 bucket.</li></ul><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html</a></p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/sharingamis-intro.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/sharingamis-intro.html</a></p>', 'answers': ['Use the exact same Amazon Machine Image of your EC2 instances across all regions.', 'Use Auto Scaling to automatically deploy new EC2 instances if there is a sudden spike in application requests.', 'Set up CloudWatch alarms to automatically send notifications if there is an issue in one of the EC2 instances.', 'Set up an IAM role to grant Amazon EC2 instances permission to access an S3 bucket.'], 'question': 'You are working as a new Solutions Architect for a large financial company. You are instructed by your CTO to share the best practices for using Auto Scaling, SQS, and EC2 to the DevOps team. <br /><br />Which of the following items is not a best practice in AWS?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for an investment firm as an AWS Consultant where you are deploying their international money transfer application to AWS Cloud. In order to achieve a scalable and highly available system as required by the client, you need to utilize the power of the Elastic Load Balancer.\xa0 \xa0Which of the following options best describes the main purpose of an Elastic Load Balancer?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104894, 'original_assessment_id': 2566804, 'section': 'ELB', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['It distributes incoming application traffic across multiple EC2 instances deployed in a single or multiple Availability Zones, which increases the fault tolerance of your applications.', 'A fast and flexible NoSQL database service for all applications that need consistent, single-digit millisecond latency at any scale.', 'A managed service that makes it easy to set up, operate, and scale a relational database in the cloud.', 'Provides a highly durable, scalable, and secure destination for backing up and archiving your critical data.'], 'question': '<p>You are working for an investment firm as an AWS Consultant where you are deploying their international money transfer application to AWS Cloud. In order to achieve a scalable and highly available system as required by the client, you need to utilize the power of the Elastic Load Balancer.\xa0 \xa0</p><p>Which of the following options best describes the main purpose of an Elastic Load Balancer?</p>', 'explanation': '<p>An Elastic Load Balancer distributes incoming application traffic across multiple EC2 instances, in multiple Availability Zones which increases the fault tolerance of your applications. Hence, option 1 is correct.</p> <p>Option 2 is incorrect because that describes the purpose of Amazon DynamoDB.</p> <p>Option 3 is incorrect because&nbsp;that describes&nbsp;the purpose of Amazon RDS.</p> <p>Option 4 is incorrect because&nbsp;that describes&nbsp;the purpose of Amazon S3.</p> <p><span style="font-weight: 400;">The figure below demonstrates the routing of traffic to different availability zones for increased fault tolerance:</span></p> <p><span style="font-weight: 400;"><img style="display: block; margin-left: auto; margin-right: auto;" src="https://udemy-images.s3.amazonaws.com/redactor/raw/2018-10-23_05-18-48-c372f2699e88d29065cdd4908daa9ffb.png" /></span></p> <p><strong>Reference:</strong></p> <p><a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/userguide/what-is-load-balancing.html">https://docs.aws.amazon.com/elasticloadbalancing/latest/userguide/what-is-load-balancing.html</a></p> <p>&nbsp;</p>'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multi-select', 'question_plain': 'A media company has two VPCs: VPC-1 and VPC-2 with peering connection between each other. VPC-1 only contains private subnets while VPC-2 only contains public subnets. The company uses a single AWS Direct Connect connection and a virtual interface to connect their on-premise network with VPC-1. Which of the following options increase the fault tolerance of the connection to VPC-1? (Select all that applies.)', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104910, 'original_assessment_id': 2566820, 'section': 'VPC', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', ''], 'answers': ['Use the AWS VPN CloudHub to create a new AWS Direct Connect connection and private virtual interface in a same region as VPC-2.', 'Establish a hardware VPN over the Internet between VPC-1 and the on-premises network.', 'Establish a hardware VPN over the Internet between VPC-2 and the on-premises network.', 'Establish a new AWS Direct Connect connection and private virtual interface in the same region as VPC-2.', 'Establish another AWS Direct Connect connection and private virtual interface in the same AWS region as VPC-1.'], 'question': 'A media company has two VPCs: VPC-1 and VPC-2 with peering connection between each other. VPC-1 only contains private subnets while VPC-2 only contains public subnets. The company uses a single AWS Direct Connect connection and a virtual interface to connect their on-premise network with VPC-1. <br><br>Which of the following options increase the fault tolerance of the connection to VPC-1? (Select all that applies.)', 'explanation': '<p>In this scenario, you have two VPCs which have peering connections with each other. Note that a VPC peering connection does not support edge to edge routing. This means that if either VPC in a peering relationship has one of the following connections, you cannot extend the peering relationship to that connection:</p> <div class="itemizedlist"> <ul> <li>A VPN connection or an AWS Direct Connect connection to a corporate network</li> <li>An internet connection through an internet gateway</li> <li>An internet connection in a private subnet through a NAT device</li> <li>A VPC endpoint to an AWS service; for example, an endpoint to Amazon S3.</li> <li>(IPv6) A ClassicLink connection. You can enable IPv4 communication between a linked EC2-Classic instance and instances in a VPC on the other side of a VPC peering connection. However, IPv6 is not supported in EC2-Classic, so you cannot extend this connection for IPv6 communication.</li> </ul> </div> <p>For example, if VPC A and VPC B are peered, and VPC A has any of these connections, then instances in VPC B cannot use the connection to access resources on the other side of the connection. Similarly, resources on the other side of a connection cannot use the connection to access VPC B.</p> <p>Hence, this means that you cannot use VPC-2 to extend the peering relationship that exists between VPC-1 and the on-premise network. For example, traffic from the corporate network can\'t directly access VPC-1 by using the VPN connection or the AWS Direct Connect connection to VPC-2, which is why Options 1, 3, and 4 are incorrect.</p> <p>The correct answers are options 2 and 5. You can do the following to provide a highly available, fault-tolerant network connection:</p> <ul> <li>Establish a hardware VPN over the Internet between the VPC and the on-premises network.</li> <li>Establish another AWS Direct Connect connection and private virtual interface in the same AWS region.&nbsp;</li> </ul> <p>&nbsp;</p> <p>References:</p> <p><a href="https://docs.aws.amazon.com/vpc/latest/peering/invalid-peering-configurations.html#edge-to-edge-vgw">https://docs.aws.amazon.com/vpc/latest/peering/invalid-peering-configurations.html#edge-to-edge-vgw</a></p> <p><a href="https://aws.amazon.com/premiumsupport/knowledge-center/configure-vpn-backup-dx/" target="_blank" rel="noopener">https://aws.amazon.com/premiumsupport/knowledge-center/configure-vpn-backup-dx/</a></p> <p><a href="https://aws.amazon.com/answers/networking/aws-multiple-data-center-ha-network-connectivity/" target="_blank" rel="noopener">https://aws.amazon.com/answers/networking/aws-multiple-data-center-ha-network-connectivity/</a></p>'}, 'related_lectures': [], 'correct_response': ['b', 'e'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multi-select', 'question_plain': 'An online events registration system is hosted in AWS and uses ECS to host its front-end tier and a Multi-AZ RDS for its database tier, which also has a standby replica. What are the events that will make Amazon RDS automatically perform a failover to the standby replica? (Choose 3)', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104912, 'original_assessment_id': 2566822, 'section': 'RDS', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Loss of availability in primary Availability Zone', 'Loss of network connectivity to primary', 'Storage failure on secondary', 'Storage failure on primary', '<p>In the event of Read Replica failure</p>', '<p>Compute unit failure on secondary DB instance</p>'], 'question': '<p>An online events registration system is hosted in AWS and uses ECS to host its front-end tier and a Multi-AZ RDS for its database tier, which also has a standby replica. What are the events that will make Amazon RDS automatically perform a failover to the standby replica? (Choose 3)</p>', 'explanation': '<p>Amazon RDS detects and automatically recovers from the most common failure scenarios for Multi-AZ deployments so that you can resume database operations as quickly as possible without administrative intervention.</p><p>Amazon RDS automatically performs a failover in the event of any of the following:</p><ul><li>-Loss of availability in primary Availability Zone</li><li>-Loss of network connectivity to primary</li><li>-Compute unit failure on primary</li><li>-Storage failure on primary</li></ul><p>&nbsp;</p><p>Resources:</p><p><a href="https://aws.amazon.com/rds/details/multi-az/">https://aws.amazon.com/rds/details/multi-az/</a></p><p>&nbsp;</p>'}, 'related_lectures': [], 'correct_response': ['a', 'b', 'd'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'One of your EC2 instances is reporting an unhealthy system status check. The operations team is looking for an easier way to monitor and repair these instances instead of fixing them manually. How will you automate the monitoring and repair of the system status check failure in an AWS environment?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104916, 'original_assessment_id': 2566826, 'section': 'CloudWatch', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['Create CloudWatch alarms that stop and start the instance based out of status check alarms.', 'Write a python script that queries the EC2 API for each instance status check', 'Write a shell script that periodically shuts down and starts instances based on certain stats.', 'Buy and implement a third party monitoring tool.'], 'question': '<p>One of your EC2 instances is reporting an unhealthy system status check. The operations team is looking for an easier way to monitor and repair these instances instead of fixing them manually. <br><br>How will you automate the monitoring and repair of the system status check failure in an AWS environment?</p>', 'explanation': '<p>Using Amazon CloudWatch alarm actions, you can create alarms that automatically stop, terminate, reboot, or recover your EC2 instances. You can use the stop or terminate actions to help you save money when you no longer need an instance to be running. You can use the reboot and recover actions to automatically reboot those instances or recover them onto new hardware if a system impairment occurs.</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/UsingAlarmActions.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/UsingAlarmActions.html</a></p><p>&nbsp;</p><p>&nbsp;</p>'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Your manager asks you to create a highly available web application which serves static content from a fleet of Spot EC2 instances. Which of the following is not needed to accomplish this requirement?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104918, 'original_assessment_id': 2566828, 'section': 'Highly Available Network Design', 'prompt': {'explanation': '<p>For a highly available system in AWS, you need to have a fleet of EC2 instances configured with an Auto Scaling group, deployed to multiple Availability Zones and are connected by an Elastic Load Balancer. You don\'t need&nbsp;ElastiCache for this case as this service is mainly used for caching to improve the performance of your application but not its availability.</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-benefits.html">https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-benefits.html</a></p><p><a href="https://media.amazonwebservices.com/architecturecenter/AWS_ac_ra_ftha_04.pdf">https://media.amazonwebservices.com/architecturecenter/AWS_ac_ra_ftha_04.pdf</a></p>', 'answers': ['Multiple Availability Zones', 'Application Load Balancer', 'ElastiCache', 'An Auto Scaling group to recover from EC2 instance failures'], 'question': 'Your manager asks you to create a highly available web application which serves static content from a fleet of Spot EC2 instances. Which of the following is not needed to accomplish this requirement?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'As a Network Architect developing a food ordering application, you need to retrieve the instance ID, public keys, and public IP address of the EC2 server you made for tagging and grouping the attributes into your internal application running on-premises. Which EC2 feature will help you achieve your requirements?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104914, 'original_assessment_id': 2566824, 'section': 'EC2', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', ''], 'answers': ['Instance user data', 'Resource tags', 'Instance metadata', 'Amazon Machine Image', 'Placement Groups'], 'question': '<p>As a Network Architect developing a food ordering application, you need to retrieve the instance ID, public keys, and public IP address of the EC2 server you made for tagging and grouping the attributes into your internal application running on-premises. </p><p>Which EC2 feature will help you achieve your requirements?</p>', 'explanation': '<p>Instance metadata is the data about your instance that you can use to configure or manage the running instance. You can get the instance ID, public keys, public IP address and many other information from the instance metadata by firing a URL command in your instance to this URL: <a href="http://169.254.169.254/latest/meta-data/">http://169.254.169.254/latest/meta-data/</a></p> <p>Option 1 is incorrect because it is mainly used to perform common automated configuration tasks and run scripts after the instance starts.</p> <p>Option 2 is incorrect because resource tags are labels that you assign to an AWS resource. Each tag consists of a key and an optional value, both of which you define.</p> <p>Option 4 is incorrect because Amazon Machine Image (AMI) mainly provides the information required to launch an instance, which is a virtual server in the cloud. An AMI includes the following:</p> <ul> <li>A template for the root volume for the instance </li> <li>Launch permissions that control which AWS accounts can use the AMI to launch instances</li> <li>A block device mapping that specifies the volumes to attach to the instance when it\'s launched</li> </ul> <p>Option 5 is incorrect because placement groups are used for applications that benefit from low network latency, high network throughput, or both, and if the majority of the network traffic is between the instances in the group.</p> <p><strong>Reference:</strong></p> <p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.htm">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.htm</a></p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are working for a central bank as the Principal AWS Solutions Architect. Due to compliance requirements and security concerns, you are tasked to implement strict access to the central bank AWS resources. Which of the following can you manage in the IAM dashboard? (Choose 3)', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104920, 'original_assessment_id': 2566830, 'section': 'IAM', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['<p>Groups</p>', 'Identity providers', 'Cost Allocation Reports', 'Policies', '<p>Network Access Control List</p>', '<p>Security Groups</p>'], 'question': '<p>You are working for a central bank as the Principal AWS Solutions Architect. Due to compliance requirements and security concerns, you are tasked to implement strict access to the central bank AWS resources. </p><p>Which of the following can you manage in the IAM dashboard? (Choose 3)</p>', 'explanation': '<p>Option 1 is correct because an IAM group is a collection of IAM users. Groups let you specify permissions for multiple users, which can make it easier to manage the permissions for those users.</p> <p>Option 2 is correct as you can manage identity providers using IAM Dashboard instead of creating IAM users in your AWS account. With an identity provider (IdP), you can manage your user identities outside of AWS and give these external user identities permission to use AWS resources in your account.</p> <p>Option 3 is incorrect because cost allocation reports are under AWS Billing and Cost Management.</p> <p>Option 4 is correct because you can manage IAM policies in the IAM Dashboard. An IAM policy is an object in AWS that, when associated with an entity or resource, defines their permissions.</p> <p>Options 5 and 6 are both incorrect. NACL is an optional layer of security for your VPC that acts as a firewall for controlling traffic in and out of one or more subnets while security groups act as virtual firewall for your instance to control inbound and outbound traffic, both of which cannot be managed in the IAM dashboard.</p> <p><strong>Reference:</strong></p> <p><a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction.html">https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction.html</a></p>'}, 'related_lectures': [], 'correct_response': ['a', 'b', 'd'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multi-select', 'question_plain': 'Your fellow AWS Engineer has created a new Standard-class S3 bucket to store financial reports that are not frequently accessed but should be immediately available when an auditor requests for it. To save costs, you changed the storage class of the S3 bucket from Standard to Infrequent Access storage class.\xa0 \xa0In Amazon S3 Standard - Infrequent Access storage class, which of the following statements are true? (Choose 3)', '_class': 'assessment', 'created': '2018-11-17T02:28:13Z', 'id': 6104808, 'original_assessment_id': 2566714, 'section': 'S3', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['<p>It is designed for data that is accessed less frequently.</p>', '<p>It is the best storage option to store noncritical and reproducible data</p>', '<p>It is designed for data that requires rapid access when needed.</p>', '<p>It provides high latency and low throughput performance</p>', '<p>Ideal to use for long-term storage, backups, and as a data store for disaster recovery.</p>', '<p>Ideal to use for data archiving.</p>'], 'question': '<p>Your fellow AWS Engineer has created a new Standard-class S3 bucket to store financial reports that are not frequently accessed but should be immediately available when an auditor requests for it. To save costs, you changed the storage class of the S3 bucket from Standard to Infrequent Access storage class.\xa0 \xa0</p><p>In Amazon S3 Standard - Infrequent Access storage class, which of the following statements are true? (Choose 3)</p>', 'explanation': '<p>Amazon S3 Standard - Infrequent Access (Standard - IA) is an Amazon S3 storage class for data that is accessed less frequently, but requires rapid access when needed. Standard - IA offers the high durability, throughput, and low latency of Amazon S3 Standard, with a low per GB storage price and per GB retrieval fee.</p> <p>This combination of low cost and high performance make Standard - IA ideal for long-term storage, backups, and as a data store for disaster recovery. The Standard - IA storage class is set at the object level and can exist in the same bucket as Standard, allowing you to use lifecycle policies to automatically transition objects between storage classes without any application changes.</p> <p><strong>Key Features:</strong></p> <ul> <li>Same low latency and high throughput performance of Standard</li> <li>Designed for durability of 99.999999999% of objects</li> <li>Designed for 99.9% availability over a given year</li> <li>Backed with the Amazon S3 Service Level Agreement for availability</li> <li>Supports SSL encryption of data in transit and at rest</li> <li>Lifecycle management for automatic migration of objects</li> </ul> <p>The option: "<em>It provides high latency and low throughput performance</em>" is wrong as it should be "low latency" and "high throughput" instead.</p> <p>The option: "<em>It is the best storage option to store noncritical and reproducible data</em>" is wrong as it actually refers to Amazon S3 - Reduced Redundancy Storage (RRS).&nbsp;</p> <p>The option: "<em>Ideal to use for data archiving.</em>" is wrong because this statement refers to Amazon Glacier.</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/s3/storage-classes/">https://aws.amazon.com/s3/storage-classes/</a></p>'}, 'related_lectures': [], 'correct_response': ['a', 'c', 'e'], 'updated': '2018-11-17T02:28:13Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are instructed by your manager to set up a bastion host to your Amazon VPC and that you should be the only person that can access it via SSH. What is the best way for you to achieve this?', '_class': 'assessment', 'created': '2018-11-17T02:28:13Z', 'id': 6104810, 'original_assessment_id': 2566716, 'section': 'VPC', 'prompt': {'explanation': '<p>The best way to implement a bastion host is to create a small EC2 instance which should only have a security group from a particular IP address for maximum security. We use a small instance rather than a large one because this host will only act as a jump server to connect to other instances in your VPC and nothing else. Hence, there is no point of allocating a large instance simply because it doesn\'t need that much computing power to process SSH (port 22) or RDP (port 3389) connections. Hence, option 4 is the right answer for this scenario.&nbsp;</p><p>Options 1 and 3 are incorrect because even though&nbsp;you have your own pre-configured password, the SSH connection can still be accessed by anyone over the Internet, which poses as a security vulnerability.</p><p>Option 2 is incorrect because you don\'t need a large instance for a bastion host as it does not require much CPU resources.</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/quickstart/latest/linux-bastion/architecture.html">https://docs.aws.amazon.com/quickstart/latest/linux-bastion/architecture.html</a></p><p><a href="https://aws.amazon.com/blogs/security/how-to-record-ssh-sessions-established-through-a-bastion-host/">https://aws.amazon.com/blogs/security/how-to-record-ssh-sessions-established-through-a-bastion-host/</a></p><p>&nbsp;</p>', 'answers': ['Create a large EC2 instance with a security group which only allows access on port 22 using your own pre-configured password.', 'Create a large EC2 instance with a security group which only allows access on port 22 via your IP address.', 'Create a small EC2 instance with a security group which only allows access on port 22 using your own pre-configured password.', 'Create a small EC2 instance and a security group which only allows access on port 22 via your IP address.'], 'question': 'You are instructed by your manager to set up a bastion host to your Amazon VPC and that you should be the only person that can access it via SSH. What is the best way for you to achieve this?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-17T02:28:13Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are building a cloud infrastructure where you have EC2 instances that require access to various AWS services such as S3 and Redshift. You will also need to provision access to system administrators so they can deploy and test their changes.Which configuration should be used to ensure that AWS Credentials like Access Keys and Secret Access Keys are secured and not compromised? (Choose 2)', '_class': 'assessment', 'created': '2018-11-17T02:28:13Z', 'id': 6104812, 'original_assessment_id': 2566718, 'section': 'IAM', 'prompt': {'explanation': '<p>In this scenario, the correct answers are:&nbsp;&nbsp;</p><ul><li>-Enable Multi-Factor Authentication</li><li>-Assign an IAM role to the Amazon EC2 instance</li></ul><br /><p>Always remember that you should associate IAM roles to EC2 instances and not an IAM user, for the purpose of accessing other AWS services. IAM roles are designed so that your applications can securely make API requests from your instances, without requiring you to manage the security credentials that the applications use. Instead of creating and distributing your AWS credentials, you can delegate permission to make API requests using IAM roles.</p><p>AWS Multi-Factor Authentication (MFA) is a simple best practice that adds an extra layer of protection on top of your user name and password. With MFA enabled, when a user signs in to an AWS website, they will be prompted for their user name and password (the first factor&mdash;what they know), as well as for an authentication code from their AWS MFA device (the second factor&mdash;what they have). Taken together, these multiple factors provide increased security for your AWS account settings and resources. You can enable MFA for your AWS account and for individual IAM users you have created under your account. MFA can also be used to control access to AWS service APIs.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/iam/details/mfa/">https://aws.amazon.com/iam/details/mfa/</a></p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html</a></p><p>&nbsp;</p><p>&nbsp;</p>', 'answers': ['Enable Multi-Factor Authentication.', 'Assign an IAM role to the Amazon EC2 instance.', 'Store the AWS Access Keys in the EC2 instance.', 'Assign an IAM user for each Amazon EC2 Instance.'], 'question': 'You are building a cloud infrastructure where you have EC2 instances that require access to various AWS services such as S3 and Redshift. You will also need to provision access to system administrators so they can deploy and test their changes.<br /><br />Which configuration should be used to ensure that AWS Credentials like Access Keys and Secret Access Keys are secured and not compromised? (Choose 2)'}, 'related_lectures': [], 'correct_response': ['a', 'b'], 'updated': '2018-11-17T02:28:13Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You want to establish an SSH connection to a Linux instance hosted in your VPC via the Internet. Which of the following is not required in order for this to work?', '_class': 'assessment', 'created': '2018-11-17T02:28:13Z', 'id': 6104814, 'original_assessment_id': 2566720, 'section': 'EC2', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['<p>Secondary Private IP Address</p>', '<p>Public IP Address or Elastic IP</p>', 'Internet Gateway', '<p>Network access control and security group rules which allow the relevant traffic to flow to and from your EC2 instance.</p>'], 'question': 'You want to establish an SSH connection to a Linux instance hosted in your VPC via the Internet. Which of the following is not required in order for this to work?', 'explanation': '<p>Since you need to connect to your EC2 instance via the Internet, you basically need to ensure that your VPC has an attached Internet Gateway so it can communicate with the outside world. Your instance should also have either public IP or Elastic IP address.&nbsp;In this scenario, you don\'t need a Secondary Private IP Address since it is only used inside your VPC.</p> <p>To enable access to or from the internet for instances in a VPC subnet, you must do the following:</p> <div> <ul> <li>Attach an internet gateway to your VPC.</li> <li>Ensure that your subnet\'s route table points to the internet gateway.</li> <li>Ensure that instances in your subnet have a globally unique IP address (public IPv4 address, Elastic IP address, or IPv6 address).</li> <li>Ensure that your network access control and security group rules allow the relevant traffic to flow to and from your instance.</li> </ul> </div> <p>&nbsp;</p> <p>References:</p> <p><a href="https://aws.amazon.com/premiumsupport/knowledge-center/secondary-private-ip-address/">https://aws.amazon.com/premiumsupport/knowledge-center/secondary-private-ip-address/</a></p> <p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-instance-addressing.html/">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-instance-addressing.html/</a></p> <p>&nbsp;</p>'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-17T02:28:13Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as a Cloud Consultant for a government agency with a mandate of improving traffic planning, maintenance of roadways and preventing accidents. There is a need to manage traffic infrastructure in real time, alert traffic engineers and emergency response teams when problems are detected, and automatically change traffic signals to get emergency personnel to accident scenes faster by using sensors and smart devices.\xa0 \xa0Which AWS service will allow the developers of the agency to connect the said devices to your cloud-based applications?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104882, 'original_assessment_id': 2566790, 'section': 'IoT Core', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', ''], 'answers': ['CloudFormation', 'Elastic Beanstalk', 'AWS IoT Core', 'Container service', '<p>Lambda\xa0 </p>'], 'question': '<p>You are working as a Cloud Consultant for a government agency with a mandate of improving traffic planning, maintenance of roadways and preventing accidents. There is a need to manage traffic infrastructure in real time, alert traffic engineers and emergency response teams when problems are detected, and automatically change traffic signals to get emergency personnel to accident scenes faster by using sensors and smart devices.\xa0 \xa0</p><p>Which AWS service will allow the developers of the agency to connect the said devices to your cloud-based applications?</p>', 'explanation': '<p>AWS IoT Core is a managed cloud service that lets connected devices easily and securely interact with cloud applications and other devices. AWS IoT Core provides secure communication and data processing across different kinds of connected devices and locations so you can easily build IoT applications.</p> <p>Option 1 is incorrect because CloudFormation is mainly used for creating and managing the architecture and not for handling connected devices. You have to use AWS IoT Core instead.</p> <p>Option 2 is incorrect because AWS Elastic Beanstalk is mainly used as a substitute to Infrastructure-as-a-Service with Platform-as-a-Service, which reduces management complexity without restricting choice or control and not for handling connected devices. </p> <p>Option 4 is incorrect because Amazon Elastic Container Services is mainly used for creating and managing docker instances and not for handling devices. </p> <p>Option 5 is incorrect because AWS Lambda is a serverless computing platform in AWS and not mainly used for connecting to smart devices.</p> <p><strong>References: </strong></p> <p><a href="https://aws.amazon.com/iot-core/">https://aws.amazon.com/iot-core/</a></p> <p><a href="https://aws.amazon.com/iot/">https://aws.amazon.com/iot/</a></p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You need to back up your mySQL database hosted on a Reserved EC2 instance. It is using EBS volumes that are configured in a RAID array.\xa0 What steps will you take to minimize the time during which the database cannot be written to and to ensure a consistent backup?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104816, 'original_assessment_id': 2566722, 'section': 'EBS', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['<p>1. Detach EBS volumes from the EC2 instance.</p><p><br></p><p>2. Start EBS snapshot of volumes.</p><p><br></p><p>3. Re-attach the EBS volumes.</p>', '<p>1. Stop all applications from writing to the RAID array.</p><p><br></p><p>2. Flush all caches to the disk.</p><p><br></p><p>3. Confirm that the associated EC2 instance is no longer writing to the RAID array by taking actions such as freezing the file system, unmounting the RAID array, or even shutting down the EC2 instance.</p><p><br></p><p>4. After taking steps to halt all disk-related activity to the RAID array, take a snapshot of each EBS volume in the array.</p>', '<p>1. Stop all I/O activity in the volumes.</p><p><br></p><p>2. Create an image of the EC2 Instance.</p><p><br></p><p>3. Resume all I/O activity in the volume.</p>', '<p>1. Stop all I/O activity in the volumes.</p><p><br></p><p>2. Start EBS snapshot of volumes.</p><p><br></p><p>3. While the snapshot is in progress, resume all I/O activity.</p>'], 'question': '<p>You need to back up your mySQL database hosted on a Reserved EC2 instance. It is using EBS volumes that are configured in a RAID array.\xa0 </p><p>What steps will you take to minimize the time during which the database cannot be written to and to ensure a consistent backup?</p>', 'explanation': '<div> <p>Remember that since the instance is using a RAID configuration, the snapshot process is different. You should stop all I/O activity of the volumes before creating a snapshot. Hence, option 2 is correct:</p> <ol> <li>Stop all applications from writing to the RAID array.</li> <li>Flush all caches to the disk.</li> <li>Confirm that the associated EC2 instance is no longer writing to the RAID array by taking actions such as freezing the file system, unmounting the RAID array, or even shutting down the EC2 instance.</li> <li>After taking steps to halt all disk-related activity to the RAID array, take a snapshot of each EBS volume in the array.</li> </ol> <p>&nbsp;</p> <div> <div> <p>When you take a snapshot of an attached Amazon EBS volume that is in use, the snapshot excludes data cached by applications or the operating system. For a single EBS volume, this is often not a problem. However, when cached data is excluded from snapshots of multiple EBS volumes in a RAID array, restoring the volumes from the snapshots can degrade the integrity of the array.</p> <p>When creating snapshots of EBS volumes that are configured in a RAID array, it is critical that there is no data I/O to or from the volumes when the snapshots are created. RAID arrays introduce data interdependencies and a level of complexity not present in a single EBS volume configuration.</p> </div> </div> <p>Option 1 is incorrect as you don\'t need to detach the volumes in the first place.</p> <p>Option 3 is incorrect as you don\'t need to create a new image of the instance.</p> <p>Option 4&nbsp;is incorrect because there are missing steps in the process. You have to flush all caches to the disk first and you have to ensure that the EC2 instance is no longer writing to the RAID Array.</p> <div> <p>&nbsp;</p> </div> </div> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/premiumsupport/knowledge-center/snapshot-ebs-raid-array/">https://aws.amazon.com/premiumsupport/knowledge-center/snapshot-ebs-raid-array/</a></p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are developing a meal planning application that provides meal recommendations for the week as well as the food consumption of your users. Your application resides on an EC2 instance which requires access to various AWS services for its day-to-day operations. You found out that access keys are a good option but unsure if it is a recommended way. What is the best practice for managing API credentials in AWS?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104928, 'original_assessment_id': 2566838, 'section': 'IAM', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['Create a role in IAM and assign it to the EC2 instance.', 'Store the API credentials in the EC2 instance.', 'Add the API Credentials in the Security Group and assign it to the EC2 instance.', 'Store the API credentials in a bastion host.'], 'question': '<p>You are developing a meal planning application that provides meal recommendations for the week as well as the food consumption of your users. Your application resides on an EC2 instance which requires access to various AWS services for its day-to-day operations. You found out that access keys are a good option but unsure if it is a recommended way. </p><p>What is the best practice for managing API credentials in AWS?</p>', 'explanation': '<p>The best practice in handling API Credentials is to create a new role in the Identity Access Management (IAM) service and then assign it to a specific EC2 instance. In this way, you have a secure and centralized way of storing and managing your credentials.</p><p>Options 2, 3, and 4 are incorrect because it is not secure to store nor use the API credentials from any EC2 instance. You should use IAM service instead.</p><p>&nbsp;</p><p>Resources:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html</a></p>'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Your company just recently adopted a hybrid architecture that integrates their on-premise data center to their AWS cloud. You are assigned to configure the VPC as well as to implement the required IAM users, IAM roles, IAM groups and IAM policies. \n\nIn this scenario, what is a best practice when creating IAM policies?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104818, 'original_assessment_id': 2566724, 'section': 'IAM', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['Use the principle of least privilege which means granting only the permissions required to perform a task.', 'Grant all permissions to any EC2 user.', 'Use the principle of least privilege which means granting only the least number of people with full root access.', 'Determine what users need to do and then craft policies for them that let the users perform those tasks including additional administrative operations.'], 'question': '<p>Your company just recently adopted a hybrid architecture that integrates their on-premise data center to their AWS cloud. You are assigned to configure the VPC as well as to implement the required IAM users, IAM roles, IAM groups and IAM policies. </p>\n\n<p>In this scenario, what is a best practice when creating IAM policies?</p>', 'explanation': '<p>One of the best practices in Amazon IAM is to <em>grant least privilege</em>.</p> <p>When you create IAM policies, follow the standard security advice of granting&nbsp;<em>least privilege</em>&mdash;that is, granting only the permissions required to perform a task. Determine what users need to do and then craft policies for them that let the users perform&nbsp;<em>only</em>&nbsp;those tasks.</p> <p>Start with a minimum set of permissions and grant additional permissions as necessary. Doing so is more secure than starting with permissions that are too lenient and then trying to tighten them later.</p> <p>Defining the right set of permissions requires some research. Determine what is required for the specific task, what actions a particular service supports, and what permissions are required in order to perform those actions.</p> <p>&nbsp;</p> <p><strong>Reference:</strong></p> <p><a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#use-groups-for-permissions">https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#use-groups-for-permissions</a></p>'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are working as a Solutions Architect for a start-up company that has a not-for-profit crowdfunding platform hosted in AWS. Their platform allows people around the globe to raise money for social enterprise projects including challenging circumstances like accidents and illnesses. Since the system handles financial transactions, you have to ensure that your cloud architecture is secure. Which of the following AWS services encrypts data at rest by default? (Choose 2)', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104820, 'original_assessment_id': 2566726, 'section': 'Storage Gateway', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['AWS Storage Gateway', 'Amazon RDS', 'Amazon DynamoDB', 'Amazon Glacier', '<p>AWS Lambda</p>', '<p>S3</p>'], 'question': '<p>You are working as a Solutions Architect for a start-up company that has a not-for-profit crowdfunding platform hosted in AWS. Their platform allows people around the globe to raise money for social enterprise projects including challenging circumstances like accidents and illnesses. Since the system handles financial transactions, you have to ensure that your cloud architecture is secure. </p><p>Which of the following AWS services encrypts data at rest by default? (Choose 2)</p>', 'explanation': '<p>All data transferred between any type of gateway appliance and AWS storage is encrypted using SSL. By default, all data stored by AWS Storage Gateway in S3 is encrypted server-side with Amazon S3-Managed Encryption Keys (SSE-S3). Also, when using the file gateway, you can optionally configure each file share to have your objects encrypted with AWS KMS-Managed Keys using SSE-KMS.</p> <p>Data stored in Amazon Glacier is protected by default; only vault owners have access to the Amazon Glacier resources they create. Amazon Glacier encrypts your data at rest by default and supports secure data transit with SSL.</p> <p>&nbsp;</p> <p><strong>References:</strong></p> <p><a href="https://aws.amazon.com/storagegateway/faqs/" target="_blank" rel="noopener">https://aws.amazon.com/storagegateway/faqs/</a>&nbsp;</p> <p><a href="https://aws.amazon.com/glacier/features">https://aws.amazon.com/glacier/features</a></p>'}, 'related_lectures': [], 'correct_response': ['a', 'd'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You run a website which accepts high-quality photos and turn it into a downloadable video montage. The website offers a free account and a premium account that guarantees faster processing. All requests by both free and premium members goes through a single SQS queue and then, processed by a group of EC2 instances which generate the videos. You need to ensure that the premium users who paid for the service have a higher priority than your free members. How do you re-design your architecture to address this requirement?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104826, 'original_assessment_id': 2566732, 'section': 'SQS', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', ''], 'answers': ['For the requests made by premium members, set a higher priority in the SQS queue so it will be processed first compared to the requests made by free members.', "Create an SQS queue for free members and another one for premium members. Configure your EC2 instances to consume messages from the premium queue first and if it is empty, poll from the free members' SQS queue.", 'Use Amazon Kinesis to process the photos and generate the video montage in real time.', '<p>For the requests made by premium members, set a lower priority in the SQS queue so it will be processed first compared to the requests made by free members.</p>', 'Use Amazon S3 to store and process the photos and then generate the video montage afterwards.'], 'question': 'You run a website which accepts high-quality photos and turn it into a downloadable video montage. The website offers a free account and a premium account that guarantees faster processing. All requests by both free and premium members goes through a single SQS queue and then, processed by a group of EC2 instances which generate the videos. You need to ensure that the premium users who paid for the service have a higher priority than your free members. <br><br>How do you re-design your architecture to address this requirement?', 'explanation': '<p>In this scenario, it is best to create 2 separate SQS queues for each type of members. The SQS queues for the premium members can be polled first by the EC2 Instances and once completed, the messages from the free members can be processed next.</p><ul><li>Option 1 is incorrect as you cannot set a priority to individual items in the SQS queue.</li><li>Option 3 is incorrect as Amazon Kinesis is used to process streaming data and it is not applicable in this scenario.</li><li>Option 4 is incorrect as Amazon S3 is used for durable storage and not for processing&nbsp;data.</li></ul><br /><p>References:</p><p><a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-best-practices.html">https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-best-practices.html</a></p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'In Elastic Load Balancing, there are various security features that you can use such as Server Order Preference, Predefined Security Policy, Perfect Forward Secrecy and many others. Perfect Forward Secrecy is a feature that provides additional safeguards against the eavesdropping of encrypted data, through the use of a unique random session key. This prevents the decoding of captured data, even if the secret long-term key is compromised. Perfect Forward Secrecy is used to offer SSL/TLS cipher suites for which two AWS services?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104828, 'original_assessment_id': 2566734, 'section': 'ELB', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['EC2 and S3', 'CloudTrail and CloudWatch', '<p>CloudFront and Elastic Load Balancing</p>', '<p>Trusted Advisor and GovCloud</p>'], 'question': '<p>In Elastic Load Balancing, there are various security features that you can use such as Server Order Preference, Predefined Security Policy, Perfect Forward Secrecy and many others. Perfect Forward Secrecy is a feature that provides additional safeguards against the eavesdropping of encrypted data, through the use of a unique random session key. This prevents the decoding of captured data, even if the secret long-term key is compromised. </p><p>Perfect Forward Secrecy is used to offer SSL/TLS cipher suites for which two AWS services?</p>', 'explanation': '<p>Perfect Forward Secrecy is a feature that provides additional safeguards against the eavesdropping of encrypted data, through the use of a unique random session key. This prevents the decoding of captured data, even if the secret long-term key is compromised.</p> <p>Cloudfront and Elastic Load Balancing are the two AWS services that supports&nbsp;Perfect Forward Secrecy.</p> <p>&nbsp;</p> <p><strong>References:</strong></p> <p><a href="https://aws.amazon.com/about-aws/whats-new/2014/02/19/elastic-load-balancing-perfect-forward-secrecy-and-more-new-security-features/">https://aws.amazon.com/about-aws/whats-new/2014/02/19/elastic-load-balancing-perfect-forward-secrecy-and-more-new-security-features/</a></p> <p><a href="https://d1.awsstatic.com/whitepapers/Security/Secure_content_delivery_with_CloudFront_whitepaper.pdf">https://d1.awsstatic.com/whitepapers/Security/Secure_content_delivery_with_CloudFront_whitepaper.pdf</a></p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'One member of your DevOps team consulted you about a problem in connecting to one of the EC2 instances of your VPC over the Internet. Your environment is set up with four EC2 instances that all belong to a subnet with an attached Internet gateway. The EC2 instances also belong to the same security group. Everything works well as expected except for one of the EC2 instances which is not able to send nor  receive traffic over the Internet like the other three instances. What could be the possible reason for this issue?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104832, 'original_assessment_id': 2566738, 'section': 'VPC', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', ''], 'answers': ['The route table is not properly configured to allow traffic to and from the Internet through the Internet gateway.', 'The EC2 instance is running in an Availability Zone that is not connected to an Internet gateway.', 'The EC2 instance does not have a private IP address associated with it.', 'The EC2 instance does not have a public IP address associated with it.', 'There is a problem in the Security Group.'], 'question': 'One member of your DevOps team consulted you about a problem in connecting to one of the EC2 instances of your VPC over the Internet. Your environment is set up with four EC2 instances that all belong to a subnet with an attached Internet gateway. The EC2 instances also belong to the same security group. Everything works well as expected except for one of the EC2 instances which is not able to send nor  receive traffic over the Internet like the other three instances. <br><br>What could be the possible reason for this issue?', 'explanation': '<div> <p>In this scenario, there are 4 EC2 instances that belong to the same security group that should be able to connect to the Internet. The main route table is properly configured but there is a problem connecting to one instance. Since the other three instances are working fine, we can assume that the security group and the route table are correctly configured. One possible reason for this issue is that the problematic instance does not have a public or an EIP address, hence, the correct answer is Option 4.</p> <p>Options 1 and 5 are incorrect as the other three instances, which are associated with the same route table and security group, do not have any issues.&nbsp;</p> <p>Option 2 is incorrect because there is no relationship between the Availability Zone and the Internet Gateway (IGW) that may have caused the issue.</p> <p><strong>Reference:</strong></p> </div> <p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario1.html">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario1.html</a></p>'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-17T02:28:55Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You recently launched a Docker instance using ECS in your VPC. For security purposes, you have to configure its security group to control all the traffic that is coming in or out. What are the 2 types of rules that you can define in AWS Security Groups? (Choose 2)', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104852, 'original_assessment_id': 2566758, 'section': 'VPC', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Inbound', 'Transitional', 'Bi-Directional', 'Outbound', '<p>Incoming</p>', '<p>Outgoing</p>'], 'question': '<p>You recently launched a Docker instance using ECS in your VPC. For security purposes, you have to configure its security group to control all the traffic that is coming in or out. What are the 2 types of rules that you can define in AWS Security Groups? (Choose 2)</p>', 'explanation': '<p>We have two types of rules in Security Group: Inbound and Outbound rules.</p><p>The rules of a security group control the inbound traffic that\'s allowed to reach the instances that are associated with the security group and the outbound traffic that\'s allowed to leave them.&nbsp;</p><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-network-security.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-network-security.html</a></p><p>&nbsp;</p>'}, 'related_lectures': [], 'correct_response': ['a', 'd'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You started an artificial intelligence and machine learning startup that builds enterprise AI solutions, which can quickly turn raw data in various forms stored across siloed hardware into fully operationalized solutions, without time-consuming coding. Your cloud infrastructure is composed of auto-scaled On-Demand EC2 instances deployed to multiple Availability Zones with an ELB in front that load balances the incoming traffic. To ensure high availability of your APIs and other services, you need to set up monitoring that checks the health of your On-Demand EC2 instances.\xa0 Which of the following are best practices for monitoring your EC2 Instances?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104834, 'original_assessment_id': 2566740, 'section': 'EC2', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['Automate monitoring tasks as much as possible.', 'Check the log files on your EC2 instances.', 'Make monitoring a priority to head off small problems before they become big ones.', 'All of the above'], 'question': '<p>You started an artificial intelligence and machine learning startup that builds enterprise AI solutions, which can quickly turn raw data in various forms stored across siloed hardware into fully operationalized solutions, without time-consuming coding. Your cloud infrastructure is composed of auto-scaled On-Demand EC2 instances deployed to multiple Availability Zones with an ELB in front that load balances the incoming traffic. To ensure high availability of your APIs and other services, you need to set up monitoring that checks the health of your On-Demand EC2 instances.\xa0 </p><p>Which of the following are best practices for monitoring your EC2 Instances?</p>', 'explanation': '<p>Use the following best practices for monitoring to help you with your Amazon EC2 monitoring tasks.</p> <div> <ul> <li> <p>Make monitoring a priority to head off small problems before they become big ones.</p> </li> <li> <p>Create and implement a monitoring plan that collects monitoring data from all of the parts in your AWS solution so that you can more easily debug a multi-point failure if one occurs. Your monitoring plan should address, at a minimum, the following questions:</p> <ul> <li>What are your goals for monitoring?</li> <li>What resources will you monitor?</li> <li>How often will you monitor these resources?</li> <li>What monitoring tools will you use?</li> <li>Who will perform the monitoring tasks?</li> <li>Who should be notified when something goes wrong?</li> </ul> </li> <li> <p>Automate monitoring tasks as much as possible.</p> </li> <li> <p>Check the log files on your EC2 instances.</p> </li> </ul> </div> <p>&nbsp;</p> <p><strong>Reference:</strong></p> <p><a target="" rel="">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring_best_practices.html</a></p>'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You have two On-Demand EC2 instances inside your Virtual Private Cloud in the same Availability Zone but are deployed to different subnets. One EC2 instance is running a database and the other EC2 instance a web application that connects with the database. You want to ensure that these two instances can communicate with each other for your system to work properly.What are the things you have to check so that these EC2 instances can communicate inside the VPC? (Choose 2)', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104836, 'original_assessment_id': 2566742, 'section': 'VPC', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Check the Network ACL if it allows communication between the two subnets.', 'Check if both instances are the same instance class.', 'Check if the default route is set to a NAT instance or Internet Gateway (IGW) for them to communicate.', 'Check if all security groups are set to allow the application host to communicate to the database on the right port and protocol.', '<p>Ensure that the EC2 instances are in the same Placement Group.</p>', '<p>Ensure that EC2 Enhanced Networking is enabled.</p>'], 'question': 'You have two On-Demand EC2 instances inside your Virtual Private Cloud in the same Availability Zone but are deployed to different subnets. One EC2 instance is running a database and the other EC2 instance a web application that connects with the database. You want to ensure that these two instances can communicate with each other for your system to work properly.<br><br>What are the things you have to check so that these EC2 instances can communicate inside the VPC? (Choose 2)', 'explanation': '<p>First, the Network ACL should be properly set to allow communication between the two subnets. The security group should also be properly configured so that your web server can communicate with the database server. Hence, options 1 and 4 are the correct answers:</p> <ul> <li>Check if all security groups are set to allow the application host to communicate to the database on the right port and protocol.</li> <li>Check the Network ACL if it allows communication between the two subnets.</li> </ul> <p>&nbsp;</p> <p>Option 2 is incorrect because the EC2 instances do not need to be of the same class in order to communicate with each other.</p> <p>Option 3 is incorrect because an Internet gateway is primarily used to communicate to the Internet.</p> <p>Option 5 is incorrect because Placement Group is mainly used to provide low-latency network performance necessary for tightly-coupled node-to-node communication.</p> <p>Option 6 is incorrect because Enhanced Networking is only used to provide high-performance networking capabilities on supported EC2 instance types, and hence, not applicable for this scenario.</p> <p>&nbsp;</p> <p><strong>Reference:&nbsp;</strong></p> <p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html</a></p>'}, 'related_lectures': [], 'correct_response': ['a', 'd'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You developed a web application and deployed it on a fleet of EC2 instances and is using Amazon SQS. The requests are saved as messages in the SQS queue which is configured with the maximum message retention period. However, after thirteen days of operation, the web application suddenly crashed and there are 10,000 unprocessed messages that are still waiting in the queue. Since you developed the application, you can easily resolve the issue but you need to send a communication to the users on the issue.What information will you provide and what will happen to the unprocessed messages?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104838, 'original_assessment_id': 2566744, 'section': 'SQS', 'prompt': {'explanation': '<p>In this scenario, it is stated that the SQS queue is configured with the maximum message retention period. The maximum message retention in SQS is 14 days that is why option 3 is the correct answer i.e. there will be no missing messages.&nbsp;</p><p>Options 1 and 2 are incorrect as there are no missing messages in the queue thus, there is no need to resubmit any previous requests.</p><p>Option 4 is incorrect as the queue can contain an unlimited number of messages, not just 10,000 messages.</p><p>In Amazon SQS, you can configure the message retention period to a value from 1 minute to 14 days. The default is 4 days. Once the message retention limit is reached, your messages are automatically deleted.</p><p>A single Amazon SQS message queue can contain an unlimited number of messages. However, there is a 120,000 limit for the number of inflight messages for a standard queue and 20,000 for a FIFO queue. Messages are inflight after they have been received from the queue by a consuming component, but have not yet been deleted from the queue.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/sqs/">https://aws.amazon.com/sqs/</a></p>', 'answers': ['Tell the users that unfortunately, they have to resubmit all the requests again.', 'Tell the users that the application will be operational shortly however, requests sent over three days ago will need to be resubmitted.', 'Tell the users that the application will be operational shortly and all received requests will be processed after the web application is restarted.', 'Tell the users that unfortunately, they have to resubmit all of the requests since the queue would not be able to process the 10,000 messages together.'], 'question': 'You developed a web application and deployed it on a fleet of EC2 instances and is using Amazon SQS. The requests are saved as messages in the SQS queue which is configured with the maximum message retention period. However, after thirteen days of operation, the web application suddenly crashed and there are 10,000 unprocessed messages that are still waiting in the queue. Since you developed the application, you can easily resolve the issue but you need to send a communication to the users on the issue.<br /><br />What information will you provide and what will happen to the unprocessed messages?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have started your new role as a Solutions Architect for a media company. They host large volumes of data for their operations which are about 250 TB in size on their internal servers. They have decided to store this data on S3 because of its durability and redundancy. The company currently has a 100 Mbps dedicated line connecting their head office to the Internet. What is the fastest way to import all this data to Amazon S3?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104840, 'original_assessment_id': 2566746, 'section': 'Snowball', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', ''], 'answers': ['Upload it directly to S3', 'Use AWS Direct connect and transfer the data over to S3.', 'Upload the files using AWS Data pipeline.', 'Use AWS Snowball to upload the files.', 'Upload to AWS Glacier then move it to S3.'], 'question': 'You have started your new role as a Solutions Architect for a media company. They host large volumes of data for their operations which are about 250 TB in size on their internal servers. They have decided to store this data on S3 because of its durability and redundancy. The company currently has a 100 Mbps dedicated line connecting their head office to the Internet. <br><br>What is the fastest way to import all this data to Amazon S3?', 'explanation': '<p>Amazon Snowball is a petabyte-scale data transport solution that uses secure appliances to transfer large amounts of data into and out of the AWS cloud. Using Snowball addresses common challenges with large-scale data transfers including high network costs, long transfer times, and security concerns. Transferring data with Snowball is simple, fast, secure, and can be as little as one-fifth the cost of high-speed Internet.</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/snowball/">https://aws.amazon.com/snowball/</a></p> <p>&nbsp;</p>'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-17T02:37:40Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are working as a Solutions Architect for a leading commercial bank which has recently adopted a hybrid cloud architecture. You have to ensure that the required data security is in place on all of their AWS resources to meet the strict financial regulatory requirements. In the AWS Shared Responsibility Model, which security aspects are the responsibilities of the customer? (Choose 4)', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104824, 'original_assessment_id': 2566730, 'section': 'AWS Shared Responsibility Model', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Configuration of Security Group and Network Access Control List', 'Physical security of hardware', 'OS Patching of an EC2 instance', 'IAM Policies and Credentials Management', 'Virtualization infrastructure', 'Encryption of your data at rest or in transit'], 'question': '<p>You are working as a Solutions Architect for a leading commercial bank which has recently adopted a hybrid cloud architecture. You have to ensure that the required data security is in place on all of their AWS resources to meet the strict financial regulatory requirements. In the AWS Shared Responsibility Model, which security aspects are the responsibilities of the customer? (Choose 4)</p>', 'explanation': '<p>Security and Compliance is a shared responsibility between AWS and the customer. This shared model can help relieve customer&rsquo;s operational burden as AWS operates, manages and controls the components from the host operating system and virtualization layer down to the physical security of the facilities in which the service operates. The customer assumes responsibility and management of the guest operating system (including updates and security patches), other associated application software as well as the configuration of the AWS provided security group firewall.</p> <p>Customers should carefully consider the services they choose as their responsibilities vary depending on the services used, the integration of those services into their IT environment, and applicable laws and regulations. The nature of this shared responsibility also provides the flexibility and customer control that permits the deployment. This differentiation of responsibility is commonly referred to as Security &ldquo;<strong>of</strong>&rdquo; the Cloud versus Security &ldquo;<strong>in</strong>&rdquo; the Cloud.</p> <p>The shared responsibility model for infrastructure services, such as Amazon Elastic Compute Cloud (Amazon EC2) for example, specifies that AWS manages the security of the following assets:</p> <ul> <li>Facilities</li> <li>Physical security of hardware</li> <li>Network infrastructure</li> <li>Virtualization infrastructure&nbsp;</li> </ul> <p>You as the customer are responsible for the security of the following assets:</p> <ul> <li>Amazon Machine Images (AMIs)</li> <li>Operating systems</li> <li>Applications</li> <li>Data in transit</li> <li>Data at rest</li> <li>Data stores</li> <li>Credentials</li> <li>Policies and configuration</li> </ul> <p>For a better understanding about this topic, refer to the&nbsp;AWS Security Best Practices whitepaper on the reference link below and also the Shared Responsibility Model diagram.</p> <p><strong>References:&nbsp;</strong></p> <p><a href="https://d0.awsstatic.com/whitepapers/aws-security-best-practices.pdf">https://d0.awsstatic.com/whitepapers/aws-security-best-practices.pdf</a></p> <p><a href="https://aws.amazon.com/compliance/shared-responsibility-model/">https://aws.amazon.com/compliance/shared-responsibility-model/</a></p>'}, 'related_lectures': [], 'correct_response': ['a', 'c', 'd', 'f'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A corporate and investment bank has recently decided to adopt a hybrid cloud architecture for their Trade Finance web application which uses an Oracle database with Oracle Real Application Clusters (RAC) configuration. Since Oracle RAC is not supported in RDS, they decided to launch their database in a large On-Demand EC2 instance instead, with multiple EBS Volumes attached. As a Solutions Architect, you are responsible to ensure the security, availability, scalability, and disaster recovery of the whole architecture.  In this scenario, which of the following will enable you to take backups of your EBS volumes that are being used by the Oracle database?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104842, 'original_assessment_id': 2566748, 'section': 'EBS', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['<p>EBS-backed EC2 instances.</p>', '<p>Use Disk Mirroring, which is also known as RAID 1, that replicates data to two or more disks/EBS Volumes.</p>', '<p>Launch the EBS Volumes to a Placement Group which automatically backup your data.</p>', '<p>Create snapshots of the EBS Volumes.</p>', '<p>Use an Internet Small Computer Systems Interface (ISCSI) to backup the EBS Volumes to AWS Storage Gateway.</p>', '<p>Use Striping, which is also known as RAID 0, that replicates data to two or more disks/EBS Volumes.</p>'], 'question': '<p>A corporate and investment bank has recently decided to adopt a hybrid cloud architecture for their Trade Finance web application which uses an Oracle database with Oracle Real Application Clusters (RAC) configuration. Since Oracle RAC is not supported in RDS, they decided to launch their database in a large On-Demand EC2 instance instead, with multiple EBS Volumes attached. As a Solutions Architect, you are responsible to ensure the security, availability, scalability, and disaster recovery of the whole architecture.  </p><p>In this scenario, which of the following will enable you to take backups of your EBS volumes that are being used by the Oracle database?</p>', 'explanation': '<p>You can back up the data on your Amazon EBS volumes to Amazon S3 by taking point-in-time snapshots. Snapshots are&nbsp;<em>incremental</em>&nbsp;backups, which means that only the blocks on the device that have changed after your most recent snapshot are saved. This minimizes the time required to create the snapshot and saves on storage costs by not duplicating data. When you delete a snapshot, only the data unique to that snapshot is removed. Each snapshot contains all of the information needed to restore your data (from the moment the snapshot was taken) to a new EBS volume.</p> <p>&nbsp;</p> <p><strong>Reference:</strong></p> <p><a target="" rel="">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html</a></p>'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are working as a Solutions Architect for an investment bank and your Chief Technical Officer intends to migrate all of your applications to AWS. You are looking for block storage to store all of your data and have decided to go with EBS volumes. Your boss is worried that EBS volumes are not appropriate for your workloads due to compliance requirements, downtime scenarios, and IOPS performance.\xa0 \xa0Which of the following are valid points in proving that EBS is the best service to use for your migration? (Select all that applies)', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104876, 'original_assessment_id': 2566784, 'section': 'EBS', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['<p>When you create an EBS volume in an Availability Zone, it is automatically replicated within that zone to prevent data loss due to a failure of any single hardware component.</p>', 'EBS volumes can be attached to any EC2 Instance in any Availability Zone.', 'An EBS volume is off-instance storage that can persist independently from the life of an instance.', 'EBS volumes support live configuration changes while in production which means that you can modify the volume type, volume size, and IOPS capacity without service interruptions.', '<p>Amazon EBS provides the ability to create snapshots (backups) of any EBS volume and write a copy of the data in the volume to Amazon RDS, where it is stored redundantly in multiple Availability Zones </p>', '<p>You can use encrypted EBS volumes to meet a wide range of data-at-rest encryption requirements for regulated/audited data and applications. </p>'], 'question': '<p>You are working as a Solutions Architect for an investment bank and your Chief Technical Officer intends to migrate all of your applications to AWS. You are looking for block storage to store all of your data and have decided to go with EBS volumes. Your boss is worried that EBS volumes are not appropriate for your workloads due to compliance requirements, downtime scenarios, and IOPS performance.\xa0 \xa0</p><p>Which of the following are valid points in proving that EBS is the best service to use for your migration? (Select all that applies) </p>', 'explanation': '<p>Options 1, 3, 4, and 6 are correct.</p> <ul> <li>When you create an EBS volume in an Availability Zone, it is automatically replicated within that zone to prevent data loss due to a failure of any single hardware component.</li> <li>An EBS volume can only be attached to one EC2 instance at a time.</li> <li>After you create a volume, you can attach it to any EC2 instance in the same Availability Zone</li> <li>An EBS volume is off-instance storage that can persist independently from the life of an instance. You can specify not to terminate the EBS volume when you terminate the EC2 instance during instance creation.</li> <li>EBS volumes support live configuration changes while in production which means that you can modify the volume type, volume size, and IOPS capacity without service interruptions.</li> <li>Amazon EBS encryption uses 256-bit Advanced Encryption Standard algorithms (AES-256)</li> <li>EBS Volumes offer 99.999% SLA.</li> </ul> <p>Option 2 is incorrect as EBS volumes can only be attached to an EC2 instance in the same Availability Zone.</p> <p>Option 5 is almost correct. But instead of storing the volume to Amazon RDS, the EBS Volume snapshots are actually sent to Amazon S3.</p> <p><strong>References:</strong></p> <p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumes.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumes.html</a></p> <p><a href="https://aws.amazon.com/ebs/features/">https://aws.amazon.com/ebs/features/</a></p>'}, 'related_lectures': [], 'correct_response': ['a', 'c', 'd', 'f'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multi-select', 'question_plain': 'Your company has a top priority requirement to monitor a few database metrics and then afterwards, send email notifications to the Operations team in case there is an issue. Which AWS services can accomplish this requirement? (Choose 2)', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104844, 'original_assessment_id': 2566750, 'section': 'CloudWatch', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Amazon Simple Email Service', 'Amazon CloudWatch', 'Amazon Simple Queue Service (SQS)', 'Amazon Route 53', 'Amazon Simple Notification Service (SNS)', '<p>Amazon CloudMonitor</p>'], 'question': '<p>Your company has a top priority requirement to monitor a few database metrics and then afterwards, send email notifications to the Operations team in case there is an issue. Which AWS services can accomplish this requirement? (Choose 2)</p>', 'explanation': '<p>In this requirement, you can use Amazon CloudWatch to monitor the database and then Amazon SNS to send the emails to the Operations team. Take note that you should use SNS instead of SES (Simple Email Service) when you want to monitor your EC2 instances.</p> <p>&nbsp;</p> <p><strong>References:&nbsp;</strong></p> <p><a href="https://aws.amazon.com/cloudwatch/">https://aws.amazon.com/cloudwatch/</a></p> <p><a href="https://aws.amazon.com/sns/">https://aws.amazon.com/sns/</a></p> <p>&nbsp;</p>'}, 'related_lectures': [], 'correct_response': ['b', 'e'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are a solutions architect of a multi-national gaming company which\xa0develops\xa0video games for\xa0PS4, Xbox One and\xa0Nintendo Switch consoles, plus a number of mobile games for Android and iOS. Due to the wide range of their products and services, you proposed\xa0that they use\xa0API\xa0Gateway. What are the key features of API\xa0Gateway that you can tell to your client?\xa0(Choose 3)', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104846, 'original_assessment_id': 2566752, 'section': 'API Gateway', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['<p>Amazon API Gateway lets you simultaneously run multiple versions of the same API, allowing you to quickly iterate, test, and release new versions.</p>', '<p>You can run your APIs with quantum computer servers.</p>', '<p>You can run your APIs without any servers.</p>', '<p>Provides durable data\xa0storage</p>', '<p>You pay only for the API calls you receive and the amount of data transferred out.</p>', '<p>It automatically provides a query language for your APIs similar to GraphQL.</p>'], 'question': '<p>You are a solutions architect of a multi-national gaming company which\xa0develops\xa0video games for\xa0PS4, Xbox One and\xa0Nintendo Switch consoles, plus a number of mobile games for Android and iOS. Due to the wide range of their products and services, you proposed\xa0that they use\xa0API\xa0Gateway. What are the key features of API\xa0Gateway that you can tell to your client?\xa0(Choose 3)\xa0</p>', 'explanation': '<p>Amazon API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. With a few clicks in the AWS Management Console, you can create an API that acts as a &ldquo;front door&rdquo; for applications to access data, business logic, or functionality from your back-end services, such as workloads running on Amazon Elastic Compute Cloud (Amazon EC2), code running on AWS Lambda, or any web application. Since it can use AWS Lambda, you can run your APIs without servers</p> <p>Amazon API Gateway handles all the tasks involved in accepting and processing up to hundreds of thousands of concurrent API calls, including traffic management, authorization and access control, monitoring, and API version management. Amazon API Gateway has no minimum fees or startup costs. You pay only for the API calls you receive and the amount of data transferred out.</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/api-gateway/">https://aws.amazon.com/api-gateway/</a></p> <p>&nbsp;</p>'}, 'related_lectures': [], 'correct_response': ['a', 'c', 'e'], 'updated': '2018-11-17T02:43:10Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'In a new VPC that you created, you assigned two EC2 Instances that both belong to the same Auto Scaling group, behind an Elastic Load Balancer. However, the EC2 instances and the ELB are not reachable via URL to the ELB that serves the web application data from the EC2 instances. How do you resolve this issue?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104848, 'original_assessment_id': 2566754, 'section': 'ELB', 'prompt': {'explanation': '<p>If connectivity to the load balancer from an EC2 instance in the same region fails, verify that the VPC has an Internet gateway and that the route table has a route to the Internet gateway</p><br /><p>References:</p><p><a href="https://aws.amazon.com/premiumsupport/knowledge-center/elb-connectivity-troubleshooting/" target="_blank" rel="noopener">https://aws.amazon.com/premiumsupport/knowledge-center/elb-connectivity-troubleshooting/</a></p>', 'answers': ['Attach an Internet gateway to the VPC and route it to the subnet', 'Add an Elastic IP address to the instance', 'Create a new Amazon Elastic Load Balancer to serve requests to your instances located in the internal subnet', 'Reboot the EC2 instances again and then re-try.'], 'question': 'In a new VPC that you created, you assigned two EC2 Instances that both belong to the same Auto Scaling group, behind an Elastic Load Balancer. However, the EC2 instances and the ELB are not reachable via URL to the ELB that serves the web application data from the EC2 instances. <br /><br />How do you resolve this issue?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You have a static corporate website hosted in a standard S3 bucket and a new web domain name which was registered using Route53. You are instructed by your manager to integrate these two services in order to successfully launch their corporate website. What are the prerequisites when routing traffic using Amazon Route53 to a website that is hosted in an Amazon S3 Bucket? (Choose 2)', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104850, 'original_assessment_id': 2566756, 'section': 'Route53', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['The S3 bucket name must be the same as the domain name', 'A registered domain name', 'The record set must be of type "MX"', 'The S3 bucket must be in the same region as the hosted zone', '<p>The Cross-Origin Resource Sharing (CORS) option should be enabled in the S3 bucket</p>', '<p>The access control lists (ACL) of each web file such as .html, *.css and *.js should be set to public</p>'], 'question': '<p>You have a static corporate website hosted in a standard S3 bucket and a new web domain name which was registered using Route53. You are instructed by your manager to integrate these two services in order to successfully launch their corporate website. </p><p>What are the prerequisites when routing traffic using Amazon Route53 to a website that is hosted in an Amazon S3 Bucket? (Choose 2)</p>', 'explanation': '<p>Here are the prerequisites for routing traffic to a website that is hosted in an Amazon S3 Bucket:</p><ul><li>-An S3 bucket that is configured to host a static website. The bucket must have the same name as your domain or subdomain. For example, if you want to use the subdomain acme.example.com, the name of the bucket must be acme.example.com.</li><li>-A registered domain name. You can use Route53 as your domain registrar, or you can use a different registrar.</li><li>-Route53 as the DNS service for the domain. If you register your domain name by using Route53, we automatically configure Route53 as the DNS service for the domain.</li></ul><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/RoutingToS3Bucket.html">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/RoutingToS3Bucket.html</a></p>'}, 'related_lectures': [], 'correct_response': ['a', 'b'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multi-select', 'question_plain': 'A software company has resources hosted in AWS and on-premise servers. You have been requested to create a decoupled architecture for applications which make use of both resources. Which of the following options are valid? (Choose 2)', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104854, 'original_assessment_id': 2566760, 'section': 'SQS', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Use SWF to utilize both on-premises servers and EC2 instances for your decoupled application', 'Use RDS to utilize both on-premises servers and EC2 instances for your decoupled application', 'Use SQS to utilize both on-premises servers and EC2 instances for your decoupled application', 'Use Amazon Simple Decoupling Service to utilize both on-premises servers and EC2 instances for your decoupled application', 'Use DynamoDB to utilize both on-premises servers and EC2 instances for your decoupled application', '<p>Use AWS Lambda to utilize both on-premises servers and EC2 instances for your decoupled application.</p>'], 'question': 'A software company has resources hosted in AWS and on-premise servers. You have been requested to create a decoupled architecture for applications which make use of both resources. <br><br>Which of the following options are valid? (Choose 2)', 'explanation': '<p>Amazon Simple Queue Service (SQS) and&nbsp;Amazon Simple Workflow Service (SWF) are the services that you can use for creating a decoupled architecture in AWS.&nbsp;Decoupled architecture is a type of computing architecture that enables computing components or layers to execute independently while still interfacing with each other.</p><p>Amazon SQS offers reliable, highly-scalable hosted queues for storing messages while they travel between applications or microservices. Amazon SQS lets you move data between distributed application components and helps you decouple these components. Amazon SWF is a web service that makes it easy to coordinate work across distributed application components.</p><p>Options 2 and 5 are incorrect as RDS and DynamoDB are database services.</p><p>Option 4 is wrong because there is no such thing as Amazon Simple Decoupling Service.</p><p>&nbsp;</p><p>Resources:</p><p><a href="https://aws.amazon.com/sqs/">https://aws.amazon.com/sqs/</a></p><p><a href="http://docs.aws.amazon.com/amazonswf/latest/developerguide/swf-welcome.html">http://docs.aws.amazon.com/amazonswf/latest/developerguide/swf-welcome.html</a></p><p>&nbsp;</p><p>&nbsp;</p>'}, 'related_lectures': [], 'correct_response': ['a', 'c'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': "You are an AWS Network Engineer working for a utilities provider where you are managing a monolithic application with EC2 instance using a Windows AMI. You want to implement a cost-effective and highly available architecture for your application where you have an exact replica of the Windows server that is in a running state. If the primary instance terminates, you can attach the ENI to the standby secondary instance which allows the traffic flow to resume within a few seconds. When it comes to the ENI attachment to an EC2 instance, what does 'warm attach' refer to?", '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104930, 'original_assessment_id': 2566840, 'section': 'EC2', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['Attaching an ENI to an instance when it is stopped.', 'Attaching an ENI to an instance during the launch process.', 'Attaching an ENI to an instance when it is running.', 'Attaching an ENI to an instance when it is idle.'], 'question': "<p>You are an AWS Network Engineer working for a utilities provider where you are managing a monolithic application with EC2 instance using a Windows AMI. You want to implement a cost-effective and highly available architecture for your application where you have an exact replica of the Windows server that is in a running state. If the primary instance terminates, you can attach the ENI to the standby secondary instance which allows the traffic flow to resume within a few seconds. </p><p>When it comes to the ENI attachment to an EC2 instance, what does 'warm attach' refer to?</p>", 'explanation': '<p>An elastic network interface (ENI) is a logical networking component in a VPC that represents a virtual network card. You can attach a network interface to an EC2 instance in the following ways:</p><ol><li>When it\'s running (hot attach)</li><li>When it\'s stopped (warm attach)</li><li>When the instance is being launched (cold attach).</li></ol><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html#attach_eni_launch">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html#attach_eni_launch</a></p><p>&nbsp;</p>'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have built a web application that checks for new items in an S3 bucket once every hour. If new items exist, a message is added to an SQS queue. You have a fleet of EC2 instances which retrieve messages from the SQS queue, process the file, and finally, send you and the user an email confirmation that the item has been successfully processed. Your officemate uploaded one test file to the S3 bucket and after a couple of hours,  you noticed that you and your officemate have 50 emails from your application with the same message. Which of the following is most likely the root cause why the application has sent you and the user multiple emails?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104856, 'original_assessment_id': 2566762, 'section': 'SQS', 'prompt': {'explanation': '<p>In this scenario, the main culprit is that your application does not issue a delete command to the SQS queue after processing the message, which is why this message went back to the queue and was processed multiple times.</p><p>Option 1 is incorrect as&nbsp;there is no sqsSendEmailMessage attribute in SQS.</p><p>Option 2 is a valid answer but since the scenario did not mention that the EC2 instances delete the processed messages, option 4 is a better answer than this option.</p><p>Option 3 is incorrect as SQS does not automatically delete the messages.&nbsp;</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/sqs/faqs/">https://aws.amazon.com/sqs/faqs/</a></p><p>&nbsp;</p>', 'answers': ['The sqsSendEmailMessage attribute of the SQS queue is configured to 50.', 'There is a bug in the application.', 'By default, SQS automatically deletes the messages that were processed by the consumers. It might be possible that your officemate has submitted the request 50 times which is why you received a lot of emails.', 'Your application does not issue a delete command to the SQS queue after processing the message, which is why this message went back to the queue and was processed multiple times.'], 'question': 'You have built a web application that checks for new items in an S3 bucket once every hour. If new items exist, a message is added to an SQS queue. You have a fleet of EC2 instances which retrieve messages from the SQS queue, process the file, and finally, send you and the user an email confirmation that the item has been successfully processed. Your officemate uploaded one test file to the S3 bucket and after a couple of hours,  you noticed that you and your officemate have 50 emails from your application with the same message. <br /><br />Which of the following is most likely the root cause why the application has sent you and the user multiple emails?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multi-select', 'question_plain': "You are working for a litigation firm as the Data Engineer for their case history application. You need to keep track of all the cases your firm has handled. The static assets like .jpg, .png, and .pdf files are stored in S3 for cost efficiency and high durability. As these files are critical to your business, you want to keep track of what's happening in your S3 bucket. You found out that S3 has an event notification whenever a delete or write operation happens within the S3 bucket.\xa0 \xa0What are the possible Event Notifications available for S3 buckets? (Choose 3)", '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104926, 'original_assessment_id': 2566836, 'section': 'S3', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['SNS', 'SES', 'SQS', 'Lambda function', '<p>SWF</p>', '<p>Kinesis</p>'], 'question': "<p>You are working for a litigation firm as the Data Engineer for their case history application. You need to keep track of all the cases your firm has handled. The static assets like .jpg, .png, and .pdf files are stored in S3 for cost efficiency and high durability. As these files are critical to your business, you want to keep track of what's happening in your S3 bucket. You found out that S3 has an event notification whenever a delete or write operation happens within the S3 bucket.\xa0 \xa0</p><p>What are the possible Event Notifications available for S3 buckets? (Choose 3)</p>", 'explanation': '<p>The Amazon S3 notification feature enables you to receive notifications when certain events happen in your bucket. To enable notifications, you must first add a notification configuration identifying the events you want Amazon S3 to publish, and the destinations where you want Amazon S3 to send the event notifications.</p> <p>Amazon S3 supports the following destinations where it can publish events:<br /><br /><strong>Amazon Simple Notification Service (Amazon SNS) topic</strong></p> <ul> <li>A web service that coordinates and manages the delivery or sending of messages to subscribing endpoints or clients.</li> </ul> <p><strong>Amazon Simple Queue Service (Amazon SQS) queue</strong></p> <ul> <li>Offers reliable and scalable hosted queues for storing messages as they travel between computer.</li> </ul> <p><strong>AWS Lambda</strong></p> <ul> <li>AWS Lambda is a compute service where you can upload your code and the service can run the code on your behalf using the AWS infrastructure. You package up and upload your custom code to AWS Lambda when you create a Lambda function</li> </ul> <p>Option 2 is incorrect because SES is mainly used for sending email designed to help digital marketers and application developers send marketing, notification, and transactional emails and not for sending event notifications from S3. You have to use SNS, SQS or Lambda.</p> <p>Option 5 is incorrect because SWF is mainly used to build applications that use Amazon\'s cloud to coordinate work across distributed components and not used as a way to trigger event notifications from S3. You have to use SNS, SQS or Lambda.</p> <p>Option 6 is incorrect because Amazon Kinesis is used to collect, process, and analyze real-time, streaming data so you can get timely insights and react quickly to new information and not used for event notifications. You have to use SNS, SQS or Lambda.</p> <p>Here&rsquo;s what you need to do in order to start using this new feature with your application:</p> <ol> <li>Create the queue, topic, or Lambda function (which I&rsquo;ll call the target for brevity) if necessary.</li> <li>Grant S3 permission to publish to the target or invoke the Lambda function. For SNS or SQS, you do this by applying an appropriate policy to the topic or the queue. For Lambda, you must create and supply an IAM role, then associate it with the Lambda function.</li> <li>Arrange for your application to be invoked in response to activity on the target. As you will see in a moment, you have several options here.</li> <li>Set the bucket&rsquo;s Notification Configuration to point to the target.</li> </ol> <p><img src="https://udemy-images.s3.amazonaws.com/redactor/raw/2018-10-23_07-00-07-8b41add7c02e86428c5743b6790ac876.png" /></p> <p><strong>Reference:&nbsp;</strong></p> <p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html">https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html</a></p>'}, 'related_lectures': [], 'correct_response': ['a', 'c', 'd'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have a new, dynamic web app written in MEAN stack that is going to be launched in the next month. There is a probability that the traffic will be quite high in the first couple of weeks. In the event of a load failure, how can you set up DNS failover to a static website?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104858, 'original_assessment_id': 2566764, 'section': 'Route53', 'prompt': {'explanation': '<p>For this scenario, you can create a new Route53 with the failover option to a static S3 website bucket or CloudFront distribution as an alternative.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/premiumsupport/knowledge-center/fail-over-s3-r53/" target="_blank" rel="noopener">https://aws.amazon.com/premiumsupport/knowledge-center/fail-over-s3-r53/</a></p><p><a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover.html</a></p>', 'answers': ['Duplicate the exact application architecture in another region and configure DNS weight-based routing.', 'Enable failover to an application hosted in an on-premise data center.', 'Use Route53 with the failover option to a static S3 website bucket or CloudFront distribution.', 'Add more servers in case the application fails.'], 'question': 'You have a new, dynamic web app written in MEAN stack that is going to be launched in the next month. There is a probability that the traffic will be quite high in the first couple of weeks. In the event of a load failure, how can you set up DNS failover to a static website?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multi-select', 'question_plain': 'As a Junior Software Engineer, you are developing a hotel reservations application for the startup company that you work for and are given the task of improving the database aspect of the application. You found out that RDS does not satisfy the needs of your application because it does not scale as easily compared with DynamoDB. You need to prove to your Senior Software Engineer the advantages of using DynamoDB over RDS.\xa0 \xa0What are the valid use cases for Amazon DynamoDB? (Choose 3)', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104860, 'original_assessment_id': 2566766, 'section': 'DynamoDB', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Running relational SQL joins and complex data updates.', 'Managing web sessions.', 'Storing JSON documents.', 'Storing metadata for Amazon S3 objects.', 'Storing BLOB data.', 'Storing large amounts of infrequently accessed data.'], 'question': '<p>As a Junior Software Engineer, you are developing a hotel reservations application for the startup company that you work for and are given the task of improving the database aspect of the application. You found out that RDS does not satisfy the needs of your application because it does not scale as easily compared with DynamoDB. You need to prove to your Senior Software Engineer the advantages of using DynamoDB over RDS.\xa0 \xa0</p><p>What are the valid use cases for Amazon DynamoDB? (Choose 3)</p>', 'explanation': '<p>DynamoDB supports key-value and document data structures.&nbsp;A key-value store is a database service that provides support for storing, querying, and updating collections of objects that are identified using a key and values that contain the actual content being stored.  Meanwhile, a&nbsp;document data store provides support for storing, querying, and updating items in a document format such as JSON, XML, and HTML.</p> <p>The DynamoDB Time-to-Live (TTL) mechanism enables you to manage web sessions of your application easily. It lets you set a specific timestamp to delete expired items from your tables. Once the timestamp expires, the corresponding item is marked as expired and is subsequently deleted from the table. By using this functionality, you do not have to track expired data and delete it manually. TTL can help you reduce storage usage and reduce the cost of storing data that is no longer relevant.&nbsp;</p> <p>Amazon DynamoDB stores structured data indexed by primary key, and allows low latency read and write access to items ranging from 1 byte up to 400KB. Amazon S3 stores unstructured blobs and is suited for storing large objects up to 5 TB. In order to optimize your costs across AWS services, large objects or infrequently accessed data sets should be stored in Amazon S3, while smaller data elements or file pointers (possibly to Amazon S3 objects) are best saved in Amazon DynamoDB.</p> <p>&nbsp;</p> <p>References:</p> <p><a href="https://aws.amazon.com/dynamodb/faqs/">https://aws.amazon.com/dynamodb/faqs/</a></p> <p>&nbsp;</p>'}, 'related_lectures': [], 'correct_response': ['b', 'c', 'd'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a large telecommunications company. They have a requirement to move 20 TB data warehouse to the cloud.  It would take 2 months to transfer the data given their current bandwidth allocation. Which service would allow you to quickly upload their data into AWS?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104862, 'original_assessment_id': 2566768, 'section': 'Snowball', 'prompt': {'explanation': '<div><p>AWS Snowball is a service that accelerates the transfer of large amounts of data into and out of AWS using physical storage appliances, bypassing the Internet. Each AWS Snowball appliance type can transport data at faster-than Internet speeds. This transport is done by shipping the data in the appliances through a regional carrier. The appliances are rugged shipping containers, complete with E Ink shipping labels.</p><p>With a Snowball, you can transfer hundreds of terabytes or petabytes of data between your on-premises data centers and Amazon Simple Storage Service (Amazon S3). AWS Snowball uses Snowball appliances and provides powerful interfaces that you can use to create jobs, transfer data, and track the status of your jobs through to completion. By shipping your data in Snowballs, you can transfer large amounts of data at a significantly faster rate than if you were transferring that data over the Internet, saving you time and money.</p><p>&nbsp;</p></div><p>Resources:</p><p><a href="https://docs.aws.amazon.com/snowball/latest/ug/whatissnowball.html">https://docs.aws.amazon.com/snowball/latest/ug/whatissnowball.html</a>&nbsp;</p>', 'answers': ['Amazon Snowball', 'Amazon Direct Connect', 'Amazon S3 MultiPart Upload', 'Amazon S3 Connector'], 'question': 'You are working for a large telecommunications company. They have a requirement to move 20 TB data warehouse to the cloud.  It would take 2 months to transfer the data given their current bandwidth allocation. <br /><br />Which service would allow you to quickly upload their data into AWS?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You work for an Intelligence Agency as its Principal Consultant developing a missile tracking application, which is hosted on both development and production AWS accounts. Alice, the Intelligence agency’s Junior Developer, only has access to the development account. She has received security clearance to access the agency’s production account but the access is only temporary and only write access to EC2 and S3 services of AWS is allowed.\xa0 \xa0Which of the following allows you to issue temporary security credentials to allow access to other AWS resources of the production account?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104924, 'original_assessment_id': 2566834, 'section': 'IAM', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', ''], 'answers': ['AWS SQS', 'AWS STS', 'AWS SES', 'None of the above.', 'All of the above.'], 'question': '<p>You work for an Intelligence Agency as its Principal Consultant developing a missile tracking application, which is hosted on both development and production AWS accounts. Alice, the Intelligence agency’s Junior Developer, only has access to the development account. She has received security clearance to access the agency’s production account but the access is only temporary and only write access to EC2 and S3 services of AWS is allowed.\xa0 \xa0</p><p>Which of the following allows you to issue temporary security credentials to allow access to other AWS resources of the production account?</p>', 'explanation': '<p>AWS Security Token Service (AWS STS) is the service that you can use to create and provide trusted users with temporary security credentials that can control access to your AWS resources. Temporary security credentials work almost identically to the long-term access key credentials that your IAM users can use.</p> <p>Option 1 is incorrect as Amazon SQS is the queuing service.</p> <p>Option 3 is incorrect as Amazon SES is the email service provided by AWS.</p> <p>Option 4 is incorrect because you can STS to provide&nbsp;temporary security credentials.</p> <p>Option 5 is incorrect as only STS has the ability to provide&nbsp;temporary security credentials.&nbsp;</p> <p>In this diagram, IAM user Alice in the Dev account (the role-assuming account) needs to access the Prod account (the role-owning account). Here&rsquo;s how it works:</p> <ol> <li>Alice in the Dev account assumes an IAM role (WriteAccess) in the Prod account by calling AssumeRole.</li> <li>STS returns a set of temporary security credentials.</li> <li>Alice uses the temporary security credentials to access services and resources in the Prod account. Alice could, for example, make calls to Amazon S3 and Amazon EC2, which are granted by the WriteAccess role.</li> </ol> <p><img src="https://udemy-images.s3.amazonaws.com/redactor/raw/2018-10-23_06-52-31-201df4af92968773479c7a09268baf1e.png" /></p> <p><strong>Reference:&nbsp;</strong></p> <p><a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp.html">https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp.html</a></p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'As part of the Business Continuity Plan of your company, your IT Director instructed you to set up an automated backup all of the EBS Volumes for your EC2 instances as soon as possible.\xa0 What is the fastest and most cost-effective solution to automatically back up all of your EBS Volumes?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104864, 'original_assessment_id': 2566770, 'section': 'EBS', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', ''], 'answers': ['<p>For an automated solution, create a scheduled job that calls the "create-snapshot" command via the AWS CLI to take a snapshot of production EBS volumes periodically.\xa0 </p>', 'Set your Amazon Storage Gateway with EBS volumes as the data source and store the backups in your on-premise servers through the storage gateway.', '<p>Use an EBS-cycle policy in Amazon S3 to automatically back up the EBS volumes.</p>', 'Create a scheduled job on your EC2 instance that compresses all of the data into a zip file and automatically transfer it to your on-premise server via FTP. ', '<p>Use Amazon Data Lifecycle Manager (Amazon DLM) to automate the creation of EBS snapshots.</p>'], 'question': '<p>As part of the Business Continuity Plan of your company, your IT Director instructed you to set up an automated backup all of the EBS Volumes for your EC2 instances as soon as possible.\xa0 </p><p>What is the fastest and most cost-effective solution to automatically back up all of your EBS Volumes?</p>', 'explanation': '<p>You can use Amazon Data Lifecycle Manager (Amazon DLM) to automate the creation, retention, and deletion of snapshots taken to back up your Amazon EBS volumes. Automating snapshot management helps you to:</p> <ul> <li>Protect valuable data by enforcing a regular backup schedule.</li> <li>Retain backups as required by auditors or internal compliance.</li> <li>Reduce storage costs by deleting outdated backups.</li> </ul> <p>Combined with the monitoring features of Amazon CloudWatch Events and AWS CloudTrail, Amazon DLM provides a complete backup solution for EBS volumes at no additional cost. Hence, Option 5 is the correct answer as it is the fastest and cost-effective solution in providing an automated way of backing up your EBS volumes.</p> <p>Option 1 is incorrect because even though this is a valid solution, you would still need additional time to create a scheduled job that calls the "create-snapshot" command. It would be better to use Amazon Data Lifecycle Manager (Amazon DLM) instead as this provides you the fastest solution which enables you&nbsp;to automate the creation, retention, and deletion of the EBS snapshots without having to write custom shell scripts or creating scheduled jobs.</p> <p>Option 2 is incorrect as the Amazon Storage Gateway is used only for creating a backup of data from your on-premise server and not from the Amazon Virtual Private Cloud.</p> <p>Option 3 is incorrect as there is no such thing as EBS-cycle policy in Amazon S3.</p> <p>Option 4 is incorrect. You simply need to create a snapshot of the EBS Volume instead of doing a complicated task of compressing all of its data and sending it to your on-premise server.</p> <p><strong>References:</strong></p> <p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html</a></p> <p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-snapshot.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-snapshot.html</a></p>'}, 'related_lectures': [], 'correct_response': ['e'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are working for a commercial bank as an AWS Infrastructure Engineer handling the forex trading application of the bank. You have an Auto Scaling group of EC2 instances that allow your company to cope up with the current demand of traffic and achieve cost-efficiency. You want the Auto Scaling group to behave in such a way that it will follow a predefined set of parameters before it scales down the number of EC2 instances, which protects your system from unintended slowdown or unavailability.\xa0 \xa0Which of the following statements are true regarding the cooldown period? (Select all that applies)', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104892, 'original_assessment_id': 2566802, 'section': 'Auto Scaling', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['It ensures that before the Auto Scaling group scales out, the EC2 instances have an ample time to cooldown.', 'It ensures that the Auto Scaling group launches or terminates additional EC2 instances without any downtime.', 'It ensures that the Auto Scaling group does not launch or terminate additional EC2 instances before the previous scaling activity takes effect.', 'Its default value is 300 seconds.', 'Its default value is 600 seconds.', 'It is a configurable setting for your Auto Scaling group.'], 'question': '<p>You are working for a commercial bank as an AWS Infrastructure Engineer handling the forex trading application of the bank. You have an Auto Scaling group of EC2 instances that allow your company to cope up with the current demand of traffic and achieve cost-efficiency. You want the Auto Scaling group to behave in such a way that it will follow a predefined set of parameters before it scales down the number of EC2 instances, which protects your system from unintended slowdown or unavailability.\xa0 \xa0</p><p>Which of the following statements are true regarding the cooldown period? (Select all that applies)</p>', 'explanation': '<p>In Auto Scaling, the following statements are correct regarding the cooldown period:</p> <ul> <li>It ensures that the Auto Scaling group does not launch or terminate additional EC2 instances before the previous scaling activity takes effect.</li> <li>Its default value is 300 seconds.</li> <li>It is a configurable setting for your Auto Scaling group.</li> </ul> <p>Options 1, 2, and 5 are incorrect as these statements are false in depicting what the word "cooldown" actually means for Auto Scaling. The cooldown period is a configurable setting for your Auto Scaling group that helps to ensure that it doesn\'t launch or terminate additional instances before the previous scaling activity takes effect. After the Auto Scaling group dynamically scales using a simple scaling policy, it waits for the cooldown period to complete before resuming scaling activities.</p> <p><span style="font-weight: 400;">The figure below demonstrates the scaling cooldown:</span></p> <p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://udemy-images.s3.amazonaws.com/redactor/raw/2018-10-23_05-13-47-8ff2ec72179862c346ba76ede3994182.png" /></p> <p><strong>Reference:&nbsp;</strong></p> <p><a href="http://docs.aws.amazon.com/autoscaling/latest/userguide/as-instance-termination.html">http://docs.aws.amazon.com/autoscaling/latest/userguide/as-instance-termination.html</a></p>'}, 'related_lectures': [], 'correct_response': ['c', 'd', 'f'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are a Solutions Architect of a media company and you are instructed to migrate an on-premise web application architecture to AWS. During your design process, you have to give consideration to current on-premise security and determine which security attributes you are responsible for on AWS. Which of the following does AWS provide for you as part of the shared responsibility model?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104866, 'original_assessment_id': 2566772, 'section': 'AWS Shared Responsibility Model', 'prompt': {'explanation': '<p>Security and Compliance is a shared responsibility between AWS and the customer. This shared model can help relieve customer&rsquo;s operational burden as AWS operates, manages and controls the components from the host operating system and virtualization layer down to the physical security of the facilities in which the service operates. The customer assumes responsibility and management of the guest operating system (including updates and security patches), other associated application software as well as the configuration of the AWS provided security group firewall.</p><p>Customers should carefully consider the services they choose as their responsibilities vary depending on the services used, the integration of those services into their IT environment, and applicable laws and regulations. The nature of this shared responsibility also provides the flexibility and customer control that permits the deployment. As shown in the chart below, this differentiation of responsibility is commonly referred to as Security &ldquo;of&rdquo; the Cloud versus Security &ldquo;in&rdquo; the Cloud.</p><p>Refer to this diagram for a better understanding of the shared responsibility model.</p><p><img src="https://d1.awsstatic.com/security-center/NewSharedResponsibilityModel.749924fb27d7c6de5cd59376dbaab323f86ce5dd.png" width="570" height="291" /></p><p>&nbsp;</p><p>Resources:</p><p><a href="https://aws.amazon.com/compliance/shared-responsibility-model/">https://aws.amazon.com/compliance/shared-responsibility-model/</a></p><p>&nbsp;</p>', 'answers': ['Customer Data', 'Physical network infrastructure', 'Instance security', 'User access to the AWS environment'], 'question': 'You are a Solutions Architect of a media company and you are instructed to migrate an on-premise web application architecture to AWS. During your design process, you have to give consideration to current on-premise security and determine which security attributes you are responsible for on AWS. <br /><br />Which of the following does AWS provide for you as part of the shared responsibility model?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'In the Network ACL of your Amazon Virtual Private Cloud, how are the access rules evaluated?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104868, 'original_assessment_id': 2566774, 'section': 'VPC', 'prompt': {'explanation': '<p>Network ACL Rules are evaluated by rule number, from lowest to highest, and executed immediately when a matching allow/deny rule is found.</p><p>References:</p><p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_ACLs.html">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_ACLs.html</a></p>', 'answers': ['Network ACL Rules are evaluated by rule number, from highest to lowest and are executed immediately when a matching allow/deny rule is found.', 'By default, all Network ACL Rules are evaluated before any traffic is allowed or denied.', 'Network ACL Rules are evaluated by rule number, from lowest to highest, and executed immediately when a matching allow/deny rule is found.', 'Network ACL Rules are evaluated by rule number, from lowest to highest, and executed after all rules are checked for conflicting allow/deny rules.'], 'question': 'In the Network ACL of your Amazon Virtual Private Cloud, how are the access rules evaluated?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Using the EC2 API, you requested 40 m5.large On-Demand EC2 instances in a single Availability Zone. Twenty instances were successfully created but the other 20 requests failed.\xa0 \xa0What is the solution for this issue and what is the root cause?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104870, 'original_assessment_id': 2566776, 'section': 'EC2', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['For new accounts, there is a soft limit of 20 EC2 instances per region. Submit an Amazon EC2 instance Request Form in order to lift this limit.', 'You can only create 20 instances per Availability Zone.  Select a different Availability Zone and retry creating the instances again.', 'A certain Inbound Rule in your Network Access List is preventing you to create more than 20 instances. Remove this rule and the issue will be resolved.', 'The API credentials that you are using has a limit of only 20 requests per hour. Try submitting the request again after one hour.'], 'question': '<p>Using the EC2 API, you requested 40 m5.large On-Demand EC2 instances in a single Availability Zone. Twenty instances were successfully created but the other 20 requests failed.\xa0 \xa0</p><p>What is the solution for this issue and what is the root cause?</p>', 'explanation': '<p>Amazon EC2 has a soft limit of 20 instances per region, which can be easily resolved by completing the Amazon EC2 instance request form where your use case and your instance increase will be considered. Limit increases are tied to the region they were requested for.</p><ul><li>Option 2 is incorrect as there is no such limit in the Availability Zone.&nbsp;</li><br /><li>Option 3 is incorrect. Network Access List is an optional layer of security for your VPC that acts as a firewall for controlling traffic in and out of one or more subnets. It does not affect the creation of new EC2 instances.</li><br /><li>Option 4 is incorrect as there is no problem with your API credentials.&nbsp;</li></ul><br /><p>References:</p><p><a href="https://aws.amazon.com/ec2/faqs/#How_many_instances_can_I_run_in_Amazon_EC2 " target="_blank" rel="noopener">https://aws.amazon.com/ec2/faqs/#How_many_instances_can_I_run_in_Amazon_EC2</a></p><p><a href="http://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html</a></p>'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You work for a brokerage firm as an AWS Infrastructure Engineer who handle the stocks trading application. You host your database in an EC2 server with two EBS volumes for OS and data storage in ap-southeast-1a. Due to the fault tolerance requirements, there is a need to assess if the EBS volumes will be affected in the event of ap-southeast-1a availability zone outage. Can EBS tolerate an Availability Zone failure each and every time?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104922, 'original_assessment_id': 2566832, 'section': 'EBS', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['No, all EBS volume is stored and replicated in a single AZ only.', '<p>Yes, EBS volume is fault-tolerant and has multiple copies across multiple AZ.</p>', 'Depends on how the EBS volume is set up.', 'Depends on the AWS region where EBS volume is created.'], 'question': '<p>You work for a brokerage firm as an AWS Infrastructure Engineer who handle the stocks trading application. You host your database in an EC2 server with two EBS volumes for OS and data storage in ap-southeast-1a. Due to the fault tolerance requirements, there is a need to assess if the EBS volumes will be affected in the event of ap-southeast-1a availability zone outage. </p><p>Can EBS tolerate an Availability Zone failure each and every time?</p>', 'explanation': '<p>Option 1 is correct because when you create an EBS volume in an Availability Zone, it is automatically replicated within that zone only to prevent data loss due to a failure of any single hardware component. After you create a volume, you can attach it to any EC2 instance in the same Availability Zone.</p> <p>Option 2 is incorrect because it is the EBS snapshots, not the EBS volume, that has a copy of the data which is stored redundantly in multiple Availability Zones.</p> <p>Option 3 is incorrect because there is no option to span an EBS volume in different availability zones.</p> <p>Option 4 is incorrect because it doesn&rsquo;t matter which AWS region the EBS volume is created. EBS volumes only exist in a single availability zone while EBS snapshots are available in one AWS region.</p> <p><strong>Reference:</strong></p> <p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumes.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumes.html</a></p>'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Your client is an insurance company that utilizes SAP HANA for their day-to-day ERP operations. Since you can’t migrate this database due to customer preferences, you need to integrate it with your current AWS workload in your VPC in which you are required to establish a site-to-site VPN connection.\xa0 \xa0What needs to be configured outside of the VPC for you to have a successful site-to-site VPN connection?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104872, 'original_assessment_id': 2566778, 'section': 'AMI', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['A dedicated NAT instance in a public subnet', "An Internet-routable IP address (static) of the customer gateway's external interface for the on-premise network", 'The main route table in your VPC to route traffic through a NAT instance', 'An EIP to the Virtual Private Gateway'], 'question': '<p>Your client is an insurance company that utilizes SAP HANA for their day-to-day ERP operations. Since you can’t migrate this database due to customer preferences, you need to integrate it with your current AWS workload in your VPC in which you are required to establish a site-to-site VPN connection.\xa0 \xa0</p><p>What needs to be configured outside of the VPC for you to have a successful site-to-site VPN connection? </p>', 'explanation': '<p>By default, instances that you launch into a virtual private cloud (VPC) can\'t communicate with your own network. You can enable access to your network from your VPC by attaching a virtual private gateway to the VPC, creating a custom route table, updating your security group rules, and creating an AWS managed VPN connection.</p> <p>Although the term&nbsp;<em>VPN connection</em>&nbsp;is a general term, in the Amazon VPC documentation, a VPN connection refers to the connection between your VPC and your own network. AWS supports Internet Protocol security (IPsec) VPN connections.</p> <p>A&nbsp;<em>customer gateway</em>&nbsp;is a physical device or software application on your side of the VPN connection.</p> <p>To create a VPN connection, you must create a customer gateway resource in AWS, which provides information to AWS about your customer gateway device. Next, you have to setup an Internet-routable IP address (static) of the customer gateway\'s external interface.</p> <p><span style="font-weight: 400;">The following diagram illustrates single VPN connections. The VPC has an attached virtual private gateway, and your remote network includes a customer gateway, which you must configure to enable the VPN connection. You set up the routing so that any traffic from the VPC bound for your network is routed to the virtual private gateway.</span></p> <p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://udemy-images.s3.amazonaws.com/redactor/raw/2018-10-27_22-45-01-dbcb3de60063eaba73e8d2d12c61d6dc.png" /></p> <p><strong>References:</strong></p> <p><a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_VPN.html"><span style="font-weight: 400;">https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_VPN.html</span></a></p> <p><a href="https://docs.aws.amazon.com/vpc/latest/userguide/SetUpVPNConnections.html"><span style="font-weight: 400;">https://docs.aws.amazon.com/vpc/latest/userguide/SetUpVPNConnections.html</span></a></p> <p>&nbsp;</p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Your company is running a multi-tier web application farm in a virtual private cloud (VPC) that is not connected to their corporate network. They are connecting to the VPC over the Internet to manage the fleet of Amazon EC2 instances running in both the public and private subnets. You have added a bastion host with Microsoft Remote Desktop Protocol (RDP) access to the application instance security groups, but the company wants to further limit administrative access to all of the instances in the VPC. Which of the following bastion host deployment options will meet this requirement?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104874, 'original_assessment_id': 2566780, 'section': 'VPC', 'prompt': {'explanation': '<p>The correct answer is to deploy a Windows Bastion host with an Elastic IP address in the public subnet and allow RDP access to bastion only from the corporate IP addresses.</p><p>A bastion host is a special purpose computer on a network specifically designed and configured to withstand attacks. If you have a bastion host in AWS, it&nbsp;is basically just an EC2 instance. It should be in a public subnet with either a public or Elastic IP address with sufficient RDP or SSH access defined in the security group. Users log on to the bastion host via SSH or RDP and then use that session to manage other hosts in the private subnets.&nbsp;</p><p>Resources:</p><p><a href="https://docs.aws.amazon.com/quickstart/latest/linux-bastion/architecture.html">https://docs.aws.amazon.com/quickstart/latest/linux-bastion/architecture.html</a></p>', 'answers': ['Deploy a Windows Bastion host on the corporate network that has RDP access to all EC2 instances in the VPC.', 'Deploy a Windows Bastion host with an Elastic IP address in the private subnet, and restrict RDP access to the bastion from only the corporate public IP addresses.', 'Deploy a Windows Bastion host with an Elastic IP address in the public subnet and allow SSH access to the bastion from anywhere.', 'Deploy a Windows Bastion host with an Elastic IP address in the public subnet and allow RDP access to bastion only from the corporate IP addresses.'], 'question': 'Your company is running a multi-tier web application farm in a virtual private cloud (VPC) that is not connected to their corporate network. They are connecting to the VPC over the Internet to manage the fleet of Amazon EC2 instances running in both the public and private subnets. You have added a bastion host with Microsoft Remote Desktop Protocol (RDP) access to the application instance security groups, but the company wants to further limit administrative access to all of the instances in the VPC. <br /><br />Which of the following bastion host deployment options will meet this requirement?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multi-select', 'question_plain': 'For data privacy, a healthcare company has been asked to comply with the Health Insurance Portability and Accountability Act (HIPAA). They have been told that all of the data being backed up or stored on Amazon S3 must be encrypted. What is the best option to do this? (Choose 2)', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104878, 'original_assessment_id': 2566786, 'section': 'S3', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Before sending the data to Amazon S3 over HTTPS, encrypt the data locally first using your own encryption keys.', 'Store the data on EBS volumes with encryption enabled instead of using Amazon S3.', 'Store the data in encrypted EBS snapshots.', 'Enable Server-Side Encryption on an S3 bucket to make use of AES-256 encryption.', 'Enable Server-Side Encryption on an S3 bucket to make use of AES-128 encryption.', '<p>Compress the data first before storing to S3.</p>'], 'question': 'For data privacy, a healthcare company has been asked to comply with the Health Insurance Portability and Accountability Act (HIPAA). They have been told that all of the data being backed up or stored on Amazon S3 must be encrypted. <br><br>What is the best option to do this? (Choose 2)', 'explanation': '<div><p>Server-side encryption is about data encryption at rest&mdash;that is, Amazon S3 encrypts your data at the object level as it writes it to disks in its data centers and decrypts it for you when you access it. As long as you authenticate your request and you have access permissions, there is no difference in the way you access encrypted or unencrypted objects. For example, if you share your objects using a presigned URL, that URL works the same way for both encrypted and unencrypted objects.</p><p>You have three mutually exclusive options depending on how you choose to manage the encryption keys:</p><ul><li>-Use Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3)</li><li>-Use Server-Side Encryption with AWS KMS-Managed Keys (SSE-KMS)</li><li>-Use Server-Side Encryption with Customer-Provided Keys (SSE-C)</li></ul><br /><p>Options 1 and 4 are correct because they are using&nbsp;Amazon S3-Managed Keys (SSE-S3) and&nbsp;Customer-Provided Keys (SSE-C).&nbsp;SSE-S3 uses&nbsp;AES-256 encryption and&nbsp;SSE-C allows you to use your own encryption key.</p><p>Options 2 and 3 are incorrect because both options use EBS encryption and not S3.</p><p>Option 5 is incorrect as S3 doesn\'t provide AES-128 encryption, only&nbsp;AES-256.</p><p>&nbsp;</p></div><p>Resources:</p><p><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingEncryption.html">http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingEncryption.html</a></p>'}, 'related_lectures': [], 'correct_response': ['a', 'd'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for an online hotel booking firm with terabytes of customer data coming from your websites and applications. There is an annual corporate meeting where you need to present the booking behavior and acquire new insights from your customers’ data. You are looking for a service to perform super-fast analytics on massive data sets in near real-time.\xa0 \xa0Which of the following services gives you the ability to store huge amounts of data and perform quick and flexible queries on it?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104880, 'original_assessment_id': 2566788, 'section': 'Redshift', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['DynamoDB', 'ElastiCache', 'RDS', 'Redshift'], 'question': '<p>You are working for an online hotel booking firm with terabytes of customer data coming from your websites and applications. There is an annual corporate meeting where you need to present the booking behavior and acquire new insights from your customers’ data. You are looking for a service to perform super-fast analytics on massive data sets in near real-time.\xa0 \xa0</p><p>Which of the following services gives you the ability to store huge amounts of data and perform quick and flexible queries on it?\xa0 </p>', 'explanation': '<p>Amazon Redshift is a fast, scalable data warehouse that makes it simple and cost-effective to analyze all your data across your data warehouse and data lake. Redshift delivers ten times faster performance than other data warehouses by using machine learning, massively parallel query execution, and columnar storage on high-performance disk.</p> <p>Option 1 is incorrect. DynamoDB is a NoSQL database which is based on key-value pairs used for fast processing of small data that dynamically grows and changes. But if you need to scan large amounts of data (ie a lot of keys all in one query), the performance will not be optimal.</p> <p>Option 2 is incorrect because Elasticache is used to increase the performance, speed and redundancy with which applications can retrieve data by providing an in-memory database caching system, and not for database analytical processes.</p> <p>Option 3 is incorrect because RDS is mainly used for On-Line Transaction Processing (OLTP) applications and not for Online Analytics Processing (OLAP).</p> <p><strong>References: </strong></p> <p><a href="https://docs.aws.amazon.com/redshift/latest/mgmt/welcome.html">https://docs.aws.amazon.com/redshift/latest/mgmt/welcome.html</a></p> <p><a href="https://docs.aws.amazon.com/redshift/latest/gsg/getting-started.htm">https://docs.aws.amazon.com/redshift/latest/gsg/getting-started.htm</a>l</p>'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have set up a VPC with public subnet and an Internet gateway. You set up an EC2 instance with a public IP as well. However, you are still not able to connect to the instance via the Internet. You checked its associated security group and it seems okay.What should you do to ensure you can connect to the EC2 instance from the Internet?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104884, 'original_assessment_id': 2566792, 'section': 'VPC', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['Set an Elastic IP Address to the EC2 instance.', 'Set a Secondary Private IP Address to the EC2 instance.', 'Check the main route table and ensure that the right route entry to the Internet Gateway (IGW) is configured.', 'Check the CloudWatch logs as there must be some issue in the EC2 instance.'], 'question': '<p>You have set up a VPC with public subnet and an Internet gateway. You set up an EC2 instance with a public IP as well. However, you are still not able to connect to the instance via the Internet. You checked its associated security group and it seems okay.<br><br>What should you do to ensure you can connect to the EC2 instance from the Internet?</p>', 'explanation': '<p>The route table entries enable EC2 instances in the subnet to use IPv4 to communicate with other instances in the VPC, and to communicate directly over the Internet. A subnet that\'s associated with a route table that has a route to an Internet gateway is known as a public subnet.</p><p>If you could not connect to your EC2 instance even if there is already an Internet Gateway in your VPC and there is no issue in the security group, then you must check if the entries in the route table are properly configured.</p><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario1.html">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario1.html</a></p><p>&nbsp;</p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are working for an advertising company as their Senior Solutions Architect handling the S3 storage data. Your company has terabytes of data sitting on AWS S3 standard storage class, which accumulates significant operational costs. The management wants to cut down on the cost of their cloud infrastructure so you were instructed to switch to Glacier to lessen the cost per GB storage.\xa0 \xa0The Amazon Glacier storage service is primarily used for which use case? (Choose 2)', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104932, 'original_assessment_id': 2566842, 'section': 'Glacier', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Storing cached session data', 'Storing infrequently accessed data', 'Storing Data archives', 'Used for active database storage', 'Used as a data warehouse', '<p>Storing frequently accessed data</p>'], 'question': '<p>You are working for an advertising company as their Senior Solutions Architect handling the S3 storage data. Your company has terabytes of data sitting on AWS S3 standard storage class, which accumulates significant operational costs. The management wants to cut down on the cost of their cloud infrastructure so you were instructed to switch to Glacier to lessen the cost per GB storage.\xa0 \xa0</p><p>The Amazon Glacier storage service is primarily used for which use case? (Choose 2)\xa0 </p>', 'explanation': '<p>Amazon Glacier is an extremely low-cost storage service that provides secure, durable, and flexible storage for data backup and archival. Amazon Glacier is designed to store data that is infrequently accessed. Amazon Glacier enables customers to offload the administrative burdens of operating and scaling storage to AWS so that they don&rsquo;t have to worry about capacity planning, hardware provisioning, data replication, hardware failure detection and repair, or time-consuming hardware migrations.</p> <p>Option 1 is incorrect because storing cached session data is the main use case for ElastiCache and not Amazon Glacier.</p> <p>Option 4 is incorrect because you should use RDS or DynamoDB for your active database storage as S3 in general is used for storing your data or files.</p> <p>Option 5 is incorrect because storing it for data warehousing is the main use case of Amazon Redshift. It does not meet the requirement of being able to archive your infrequently accessed data. You can use S3 standard instead for frequently accessed data or Glacier for infrequently accessed data and archiving.</p> <p>Option 6 is incorrect because since you are looking for an archiving service, there is no need to access your files frequently. If you want to access your files frequently then look into AWS S3 Standard instead of S3 Glacier for frequently accessed files.</p> <p>It is advisable to transition the standard data to infrequent access first then transition it to Amazon Glacier. You can specify in the lifecycle rule the time it will sit in standard tier and infrequent access. You can also delete the objects after a certain amount of time.</p> <p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://udemy-images.s3.amazonaws.com/redactor/raw/2018-11-12_21-01-50-8e238b3286aa6c7c72f18b468ce19ead.png" /></p> <p>In transitioning S3 standard to Glacier you need to tell S3 which objects are to be archived to the new Glacier storage option, and under what conditions. You do this by setting up a lifecycle rule using the following elements:</p> <ul> <li>A prefix to specify which objects in the bucket are subject to the policy.</li> <li>A relative or absolute time specifier and a time period for transitioning objects to Glacier. The time periods are interpreted with respect to the object&rsquo;s creation date. They can be relative (migrate items that are older than a certain number of days) or absolute (migrate items on a specific date)</li> <li>An object age at which the object will be deleted from S3. This is measured from the original PUT of the object into the service, and the clock is not reset by a transition to Glacier.</li> </ul> <p>You can create a lifecycle rule in the AWS Management Console</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/glacier/faqs/">https://aws.amazon.com/glacier/faqs/</a></p>'}, 'related_lectures': [], 'correct_response': ['b', 'c'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': "You are working for a University as their AWS Consultant. They want to have a disaster recovery strategy in AWS for mission-critical applications after suffering a disastrous outage wherein they lost student and employee records. They don't want this to happen again but at the same time want to minimize the monthly costs. You are instructed to set up a minimum version of the application that is always available in case of any outages.\xa0 \xa0Which of the following disaster recovery architectures is the most suitable one to use in this scenario?", '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104886, 'original_assessment_id': 2566796, 'section': 'Disaster Recovery', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['<p>Backup &amp; Restore</p>', 'Pilot Light', '<p>Warm Standby</p>', '<p>Multi Site</p>'], 'question': "<p>You are working for a University as their AWS Consultant. They want to have a disaster recovery strategy in AWS for mission-critical applications after suffering a disastrous outage wherein they lost student and employee records. They don't want this to happen again but at the same time want to minimize the monthly costs. You are instructed to set up a minimum version of the application that is always available in case of any outages.\xa0 \xa0</p><p>Which of the following disaster recovery architectures is the most suitable one to use in this scenario?</p>", 'explanation': '<p>The correct answer is&nbsp;pilot light.</p><p>The term pilot light is often used to describe a DR scenario in which a minimal version of an environment is always running in the cloud. The idea of the pilot light is an analogy that comes from the gas heater. In a gas heater, a small flame that&rsquo;s always on can quickly ignite the entire furnace to heat up a house. This scenario is similar to a backup-and-restore scenario.</p><p>For example, with AWS you can maintain a pilot light by configuring and running the most critical core elements of your system in AWS. When the time comes for recovery, you can rapidly provision a full-scale production environment around the critical core.</p><p>&nbsp;</p><p>References:</p><p><a href="https://media.amazonwebservices.com/AWS_Disaster_Recovery.pdf">https://media.amazonwebservices.com/AWS_Disaster_Recovery.pdf</a></p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multi-select', 'question_plain': 'A start-up company has an EC2 instance that is hosting a web application. The volume of users is expected to grow in the coming months and hence, you need to add more elasticity and scalability in your AWS architecture to cope with the demand. Which of the following options can satisfy the above requirement for the given scenario? (Choose 3)', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104888, 'original_assessment_id': 2566798, 'section': 'Highly Available Network Design', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Setup two EC2 instances and then put them behind an Elastic Load balancer (ELB).', 'Setup an S3 Cache in front of the EC2 instance.', 'Setup two EC2 instances and use Route53 to route traffic based on a Weighted Routing Policy.', '<p>Setup an AWS WAF behind your EC2 Instance.</p>', '<p>Setup a CloudFront web distribution.</p>', '<p>Setup a CloudFront RTMP distribution.</p>'], 'question': '<p>A start-up company has an EC2 instance that is hosting a web application. The volume of users is expected to grow in the coming months and hence, you need to add more elasticity and scalability in your AWS architecture to cope with the demand. </p><p>Which of the following options can satisfy the above requirement for the given scenario? (Choose 3)</p>', 'explanation': '<p>Using an Elastic Load balancer is an ideal solution for adding elasticity to your application. Alternatively, you can also create a policy in Route53, such as a Weighted routing policy, to evenly distribute the traffic to 2 or more EC2 instances.</p><br /><p>Resources:</p><p><a href="https://aws.amazon.com/elasticloadbalancing">https://aws.amazon.com/elasticloadbalancing</a></p><p><a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/Welcome.html"  target="_blank">http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/Welcome.html</a></p><p>&nbsp;</p>'}, 'related_lectures': [], 'correct_response': ['a', 'c', 'e'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'If the primary database instance fails, what would happen to an RDS database configured with Multi-AZ deployment?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104830, 'original_assessment_id': 2566736, 'section': 'RDS', 'prompt': {'explanation': '<p>In Amazon RDS, failover is automatically handled so that you can resume database operations as quickly as possible without administrative intervention in the event that your primary database instance went down. When failing over, Amazon RDS simply flips the canonical name record (CNAME) for your DB instance to point at the standby, which is in turn promoted to become the new primary.&nbsp;</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/rds/details/multi-az/">https://aws.amazon.com/rds/details/multi-az/</a></p>', 'answers': ['The IP address of the primary DB instance is switched to the standby DB instance.', 'The primary database instance will reboot.', 'A new database instance is created in the standby Availability Zone.', 'The canonical name record (CNAME) is switched from the primary to standby instance.'], 'question': 'If the primary database instance fails, what would happen to an RDS database configured with Multi-AZ deployment?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are a Solutions Architect working for a large insurance company that deployed their production environment on a custom Virtual Private Cloud in AWS. The VPC consists of two private subnets and one public subnet. Inside the public subnet is a group of EC2 instances which are created by an Auto Scaling group and all of the instances are in the same Security Group. Your development team has created a new web application which connects to mobile devices using a custom port. This application has been deployed to the production environment and you need to open this port globally to the Internet.\xa0 \xa0Which of the following is the correct procedure?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104896, 'original_assessment_id': 2566806, 'section': 'VPC', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['Open the custom port on the Security Group. Your EC2 instances will be able to use this port after 60 minutes.', 'Open the custom port on the Network Access Control List of your VPC. Your EC2 instances will be able to use this port immediately.', 'Open the custom port on the Security Group. Your EC2 instances will be able to use this port immediately.', 'Open the custom port on the Network Access Control List of your VPC. Your EC2 instances will be able to use this port after a reboot.'], 'question': '<p>You are a Solutions Architect working for a large insurance company that deployed their production environment on a custom Virtual Private Cloud in AWS. The VPC consists of two private subnets and one public subnet. Inside the public subnet is a group of EC2 instances which are created by an Auto Scaling group and all of the instances are in the same Security Group. Your development team has created a new web application which connects to mobile devices using a custom port. This application has been deployed to the production environment and you need to open this port globally to the Internet.\xa0 \xa0</p><p>Which of the following is the correct procedure?</p>', 'explanation': '<p>To allow the custom port, you have to change the Inbound Rules in your Security Group to allow traffic coming from the mobile devices.&nbsp;</p> <p>Security Groups usually control the list of ports that are allowed to be used by your EC2 instances and the NACLs control which network or list of IP addresses can connect to your whole VPC.</p> <p>Any changes to the Security Groups or Network Access Control Lists&nbsp;are applied immediately.</p> <p>&nbsp;</p> <p><strong>Reference:</strong></p> <p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html</a></p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are helping out a new DevOps engineer to design her first architecture in AWS. She is planning to develop a highly available and fault-tolerant architecture which is composed of an Elastic Load Balancer and an Auto Scaling group of EC2 instances deployed across multiple Availability Zones. This will be used by an online accounting application which requires TLS termination capabilities, path-based routing, host-based routing, and support for containerized applications.\xa0 \xa0Which is the most suitable type of Elastic Load Balancer that you should recommend for her to use?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104934, 'original_assessment_id': 4949130, 'section': 'ELB', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['<p>Application Load Balancer</p>', '<p>Network Load Balancer</p>', '<p>Classic Load Balancer</p>', '<p>Either a Classic Load Balancer or a Network Load Balancer</p>', '<p>Either a Network Load Balancer or a Classic Load Balancer</p>', '<p>None of the above.</p>'], 'question': '<p>You are helping out a new DevOps engineer to design her first architecture in AWS. She is planning to develop a highly available and fault-tolerant architecture which is composed of an Elastic Load Balancer and an Auto Scaling group of EC2 instances deployed across multiple Availability Zones. This will be used by an online accounting application which requires TLS termination capabilities, path-based routing, host-based routing, and support for containerized applications.\xa0 \xa0</p><p>Which is the most suitable type of Elastic Load Balancer that you should recommend for her to use?</p>', 'explanation': '<p>Elastic Load Balancing supports three types of load balancers. You can select the appropriate load balancer based on your application needs.</p> <p>If you need flexible application management and TLS termination then we recommend that you use Application Load Balancer. If extreme performance and static IP is needed for your application then we recommend that you use Network Load Balancer. If your application is built within the EC2 Classic network then you should use Classic Load Balancer.</p> <p>An Application Load Balancer functions at the application layer, the seventh layer of the Open Systems Interconnection (OSI) model. After the load balancer receives a request, it evaluates the listener rules in priority order to determine which rule to apply, and then selects a target from the target group for the rule action. You can configure listener rules to route requests to different target groups based on the content of the application traffic. Routing is performed independently for each target group, even when a target is registered with multiple target groups.</p> <p>Application Load Balancers support TLS termination capabilities, path-based routing, host-based routing and support for containerized applications hence, Option 1 is correct.</p> <p>Options 2, 3, 4 and 5 are incorrect as none of these support&nbsp;path-based routing and host-based routing, unlike an Application Load Balancer.</p> <p>Option 6 is incorrect because you can use an Application Load Balancer to fulfill these requirements.</p> <p>&nbsp;</p> <p><strong>References:</strong></p> <p><a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html#application-load-balancer-benefits">https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html#application-load-balancer-benefits</a></p> <p><a href="https://aws.amazon.com/elasticloadbalancing/faqs/">https://aws.amazon.com/elasticloadbalancing/faqs/</a></p>'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are an IT Consultant for an advertising company that is currently working on a proof of concept project that automatically provides SEO analytics for their clients. Your company has a VPC in AWS that operates in dual-stack mode in which IPv4 and IPv6 communication is allowed. You deployed the application to an Auto Scaling group of EC2 instances with an Application Load Balancer in front that evenly distributes the incoming traffic. You are ready to go live but you need to point your domain name (tutorialsdojo.com) to the Application Load Balancer.\xa0 \xa0In Route 53, which record type will you use to point the DNS name of the Application Load Balancer?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104936, 'original_assessment_id': 5711302, 'section': 'Route53', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', ''], 'answers': ['<p>Non-Alias with a type "A" record set</p>', '<p>Alias with a type "AAAA" record set</p>', '<p>Alias with a type "CNAME" record set</p>', '<p>Alias with a type "A" record set</p>', '<p>Alias with a type of “MX” record set</p>'], 'question': '<p>You are an IT Consultant for an advertising company that is currently working on a proof of concept project that automatically provides SEO analytics for their clients. Your company has a VPC in AWS that operates in dual-stack mode in which IPv4 and IPv6 communication is allowed. You deployed the application to an Auto Scaling group of EC2 instances with an Application Load Balancer in front that evenly distributes the incoming traffic. You are ready to go live but you need to point your domain name (tutorialsdojo.com) to the Application Load Balancer.\xa0 \xa0</p><p>In Route 53, which record type will you use to point the DNS name of the Application Load Balancer?</p>', 'explanation': '<p>Options 2 and 4 are correct.&nbsp;To route domain traffic to an ELB load balancer, use Amazon Route 53 to create an alias record that points to your load balancer. An alias record is a Route 53 extension to DNS. It\'s similar to a CNAME record, but you can create an alias record both for the root domain, such as tutorialsdojo.com, and for subdomains, such as portal.tutorialsdojo.com. (You can create CNAME records only for subdomains.) To enable IPv6 resolution, you would need to create a second resource record, tutorialsdojo.com ALIAS AAAA -&gt; myelb.us-west-2.elb.amazonnaws.com, this is assuming your Elastic Load Balancer has IPv6 support.</p> <p>Option 1 is incorrect because you only use Non-Alias with a type &ldquo;A&rdquo; record set for IP addresses.</p> <p>Option 3 is incorrect because you can\'t create a CNAME record at the zone apex. For example, if you register the DNS name tutorialsdojo.com, the zone apex is tutorialsdojo.com.</p> <p>Option 5 is incorrect because an MX record is primarily used for mail servers. It includes a priority number and a domain name, for example, 10 mailserver.tutorialsdojo.com.</p> <p><strong>Reference:</strong></p> <p><a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-to-elb-load-balancer.html">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-to-elb-load-balancer.html</a></p>'}, 'related_lectures': [], 'correct_response': ['b', 'd'], 'updated': '2018-11-17T02:28:14Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A\xa0start-up company that offers an intuitive financial data analytics service has consulted you about their AWS architecture. They have a fleet of Amazon EC2 worker instances that process financial data and then outputs reports which are used by their clients. You must store the generated report files in a durable storage. The number of files to be stored can grow over time as the start-up company is expanding rapidly overseas and hence, they also need a way to distribute the reports faster to clients located across the globe.\xa0 Which of the following is a cost-efficient and scalable storage option that you should use for this scenario?', '_class': 'assessment', 'created': '2018-11-17T02:28:14Z', 'id': 6104822, 'original_assessment_id': 2566728, 'section': 'S3', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['<p>Use Amazon Redshift as the data storage and CloudFront as the CDN.</p>', '<p>Use Amazon Glacier as the data storage and ElastiCache as the CDN.</p>', '<p>Use Amazon S3 as the data storage and CloudFront as the CDN.</p>', '<p>Use multiple EC2 instance stores for data storage and ElastiCache as the CDN.</p>'], 'question': '<p>A\xa0start-up company that offers an intuitive financial data analytics service has consulted you about their AWS architecture. They have a fleet of Amazon EC2 worker instances that process financial data and then outputs reports which are used by their clients. You must store the generated report files in a durable storage. The number of files to be stored can grow over time as the start-up company is expanding rapidly overseas and hence, they also need a way to distribute the reports faster to clients located across the globe.\xa0 </p><p>Which of the following is a cost-efficient and scalable storage option that you should use for this scenario?</p>', 'explanation': '<p>Amazon S3 offers a highly durable, scalable, and secure destination for backing up and archiving your critical data. This is the correct option as the start-up company is looking for a durable storage to store the audio and text files. In addition, ElastiCache is only used for caching and not specifically as a Global Content Delivery Network (CDN).</p> <ul> <li>Option 1 is incorrect as Amazon Redshift is usually used as a Data Warehouse.</li> <li>Option 2 is incorrect as Amazon Glacier is usually used for data archives.</li> <li>Option 4 is&nbsp;incorrect as data stored in an instance store is not durable.</li> </ul> <p>&nbsp;</p> <p><strong>References:</strong></p> <p><a href="https://aws.amazon.com/s3/" target="_blank" rel="noopener">https://aws.amazon.com/s3/</a></p> <p><a href="https://aws.amazon.com/caching/cdn/">https://aws.amazon.com/caching/cdn/</a></p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-17T02:28:14Z'}], 'previous': None, 'next': None}, 'title': 'AWS Certified Solutions Architect Associate Practice Test 2'}, {'type': 'practice-test', 'quiz_data': {'count': 65, 'results': [{'assessment_type': 'multiple-choice', 'question_plain': 'You recently joined a commercial bank as an IT consultant. The business development manager of the bank is quite frustrated at the current limitations of their on-premise data center which hinders the growth of their online banking services. \n\nAs an IT consultant, which Amazon service will you recommend to use which can provide a virtual network that closely resembles a traditional data center?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180568, 'original_assessment_id': 2566980, 'section': 'VPC', 'prompt': {'explanation': '<p>Amazon Virtual Private Cloud (Amazon VPC) lets you provision a logically isolated section of the AWS Cloud where you can launch AWS resources in a virtual network that you define. You have complete control over your virtual networking environment, including selection of your own IP address range, creation of subnets, and configuration of route tables and network gateways. You can use both IPv4 and IPv6 in your VPC for secure and easy access to resources and applications.</p> <p>You can easily customize the network configuration for your Amazon VPC. For example, you can create a public-facing subnet for your web servers that has access to the Internet, and place your backend systems such as databases or application servers in a private-facing subnet with no Internet access. You can leverage multiple layers of security, including security groups and network access control lists, to help control access to Amazon EC2 instances in each subnet.</p> <p>&nbsp;</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/vpc/">https://aws.amazon.com/vpc/</a></p> <p>&nbsp;</p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You recently joined a commercial bank as an IT consultant. The business development manager of the bank is quite frustrated at the current limitations of their on-premise data center which hinders the growth of their online banking services. </p>\n\n<p>As an IT consultant, which Amazon service will you recommend to use which can provide a virtual network that closely resembles a traditional data center?</p>', 'answers': ['Amazon VPC', 'Amazon ServiceBus', 'Amazon EMR', 'Amazon RDS']}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Your manager has asked you to deploy a web application that can collect votes for a very popular television show. Millions of users will submit votes using mobile phones. These votes must be collected and stored into a durable, scalable, and highly available data store for real-time public tabulation. Which service should you use for this scenario?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180570, 'original_assessment_id': 2566982, 'section': 'DynamoDB', 'prompt': {'explanation': '<p>When the word durability pops out, the first service that should come to your mind is Amazon S3. Since this service is not available in the answer options, we can look at the other data stores available which is Amazon DynamoDB.</p> <p>DynamoDB is a durable, scalable, and highly available data store which can be used for real-time tabulation.&nbsp;You can also use AppSync with DynamoDB to make it easy for you to build collaborative apps that keep shared data updated in real time. You just specify the data for your app with simple code statements and AWS AppSync manages everything needed to keep the app data updated in real time. This will allow your app to access data in Amazon DynamoDB, trigger AWS Lambda functions, or run Amazon Elasticsearch queries and combine data from these services to provide the exact data you need for your app.</p> <p>Option 2 is incorrect as Amazon Redshift is mainly used as a data warehouse and for&nbsp;online analytic processing (<em>OLAP</em>). Although this service can be used for this scenario, DynamoDB is still the top choice given its better durability and scalability.&nbsp;</p> <p>Option 3 is incorrect because Amazon Simple Notification Service is a notification service and not a data storage service.</p> <p>Option 4 is incorrect as&nbsp;Amazon Simple Queue Service is a decoupling solution.</p> <p>Options 5 and 6 are incorrect as both ECS and EKS are container services.</p> <p>&nbsp;</p> <p><strong>References:&nbsp;</strong></p> <p><a href="https://aws.amazon.com/dynamodb/faqs/">https://aws.amazon.com/dynamodb/faqs/</a></p> <p><a href="https://aws.amazon.com/appsync/">https://aws.amazon.com/appsync/</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'relatedLectureIds': '', 'question': 'Your manager has asked you to deploy a web application that can collect votes for a very popular television show. Millions of users will submit votes using mobile phones. These votes must be collected and stored into a durable, scalable, and highly available data store for real-time public tabulation. <br><br>Which service should you use for this scenario?', 'answers': ['Amazon DynamoDB', 'Amazon Redshift', 'Amazon Simple Notification Service', 'Amazon Simple Queue Service', '<p>Amazon ECS</p>', '<p>Amazon EKS</p>']}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': "You were recently promoted to a technical lead role in your DevOps team. Your company has an existing VPC which is quite unutilized for the past few months. The business manager instructed you to integrate your on-premise data center and your VPC. You explained the list of tasks that you'll be doing and mentioned about a Virtual Private Network (VPN) connection. The business manager is not tech-savvy but he is interested to know what a VPN is and its benefits. \n\nWhat is one of the major advantages of having a VPN in AWS?", '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180572, 'original_assessment_id': 2566984, 'section': 'VPC', 'prompt': {'explanation': '<p>One main advantage of a VPN connection is that you will be able to connect your Amazon VPC to other remote networks.&nbsp;</p> <p>You can create an IPsec VPN connection between your VPC and your remote network. On the AWS side of the VPN connection, a&nbsp;<em>virtual private gateway</em>&nbsp;provides two VPN endpoints (tunnels) for automatic failover. You configure your&nbsp;<em>customer gateway</em>&nbsp;on the remote side of the VPN connection.&nbsp;If you have more than one remote network (for example, multiple branch offices), you can create multiple AWS managed VPN connections via your virtual private gateway to enable communication between these networks.</p> <p>You can create a VPN connection to your remote network by using an Amazon EC2 instance in your VPC that\'s running a third party software VPN appliance. AWS does not provide nor maintain third party software VPN appliances; however, you can choose from a range of products provided by partners and open source communities.</p> <p>&nbsp;</p> <p><strong>Reference:</strong></p> <p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpn-connections.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpn-connections.html</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': "<p>You were recently promoted to a technical lead role in your DevOps team. Your company has an existing VPC which is quite unutilized for the past few months. The business manager instructed you to integrate your on-premise data center and your VPC. You explained the list of tasks that you'll be doing and mentioned about a Virtual Private Network (VPN) connection. The business manager is not tech-savvy but he is interested to know what a VPN is and its benefits. </p>\n\n<p>What is one of the major advantages of having a VPN in AWS?</p>", 'answers': ['Security is automatically managed by AWS.', 'You can connect your AWS cloud resources to on-premise data centers using VPN connections.', 'You can provision unlimited number of Amazon S3 and Glacier resources.', 'None of the above']}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'An online remittance website utilizes a fleet of Spot EC2 instances and a DynamoDB table in hosting the exchange rates of different countries. You are currently using the default 5-minute datapoint by CloudWatch for monitoring your instances. Due to the growing volume of users, you are planning to use high-resolution metrics which monitors your system per minute.\xa0 What is the retention period for a one-minute datapoint in Amazon CloudWatch?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180586, 'original_assessment_id': 2566998, 'section': 'CloudWatch', 'prompt': {'explanation': '<p>CloudWatch retains metric data as follows:</p> <ul> <li>Data points with a period of less than 60 seconds are available for 3 hours. These data points are high-resolution custom metrics.</li> <li>Data points with a period of 60 seconds (1 minute) are available for 15 days.</li> <li>Data points with a period of 300 seconds (5 minute) are available for 63 days.</li> <li>Data points with a period of 3600 seconds (1 hour) are available for 455 days (15 months).</li> </ul> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/cloudwatch/faqs/">https://aws.amazon.com/cloudwatch/faqs/</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>An online remittance website utilizes a fleet of Spot EC2 instances and a DynamoDB table in hosting the exchange rates of different countries. You are currently using the default 5-minute datapoint by CloudWatch for monitoring your instances. Due to the growing volume of users, you are planning to use high-resolution metrics which monitors your system per minute.\xa0 </p><p>What is the retention period for a one-minute datapoint in Amazon CloudWatch?\xa0 </p>', 'answers': ['14 days', '15 days', '1 month', '1 year']}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': "You are the Solutions Architect for your company's AWS account of approximately 300 IAM users. They have a new company policy that will change the access of 100 of the IAM users to have a particular sort of access to Amazon S3 buckets. What will you do to avoid the time-consuming task of applying the policy at the individual user?", '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180574, 'original_assessment_id': 2566986, 'section': 'IAM', 'prompt': {'explanation': '<p>In this scenario, the best option is to group the set of users in an IAM Group and then apply a policy with the required access to the Amazon S3 bucket. This will enable you to easily add, remove, and manage the users instead of manually adding a policy to each and every 100 IAM users.&nbsp;</p> <p>Option 2 is incorrect because you need a new IAM Group for this scenario and not assign a policy to each user via a shell script. This method can save you time but afterwards, it will be difficult to manage all 100 users that are not contained in an IAM Group.</p> <p>Option 3 is incorrect because you need a new IAM Group and the method is also time-consuming.</p> <p>Option 4 is incorrect because you need to use an IAM Group and not an IAM role.</p> <p>&nbsp;</p> <p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://docs.aws.amazon.com/IAM/latest/UserGuide/images/Relationship_Between_Entities_Example.diagram.png" /></p> <p>&nbsp;</p> <p><strong>Reference:&nbsp;</strong></p> <p><a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_groups.html">http://docs.aws.amazon.com/IAM/latest/UserGuide/id_groups.html</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': "You are the Solutions Architect for your company's AWS account of approximately 300 IAM users. They have a new company policy that will change the access of 100 of the IAM users to have a particular sort of access to Amazon S3 buckets. <br><br>What will you do to avoid the time-consuming task of applying the policy at the individual user?", 'answers': ['Create a new IAM group and then add the users that require access to the S3 bucket. Afterwards, apply the policy to IAM group.', 'Create a new policy and apply it to multiple IAM users using a shell script.', 'Create a new S3 bucket access policy with unlimited access for each IAM user.', 'Create a new IAM role and add each user to the IAM role.']}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are a Solutions Architect for a global news company. You are configuring a fleet of EC2 instances in a subnet which currently is in a VPC with an Internet gateway attached. All of these EC2 instances can be accessed from the Internet. You then launch another subnet and launch an EC2 instance in it, however you are not able to access the EC2 instance from the Internet.\xa0 \xa0What could be the possible reasons for this issue? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180576, 'original_assessment_id': 2566988, 'section': 'VPC', 'prompt': {'explanation': '<p>In cases where your EC2 instance cannot access the Internet, you usually have to check two things:</p> <ul> <li>Does it have an EIP or public IP address?</li> <li>Is the route table properly configured?</li> </ul> <p>&nbsp;</p> <p>Below are the correct answers:&nbsp;</p> <ul> <li>Amazon EC2 instance does not have a public IP address associated with it.</li> <li>The route table is not configured properly to send traffic from the EC2 instance to the Internet through the Internet gateway.</li> </ul> <p>&nbsp;</p> <p><strong>Reference:&nbsp;</strong></p> <p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario2.html">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario2.html</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are a Solutions Architect for a global news company. You are configuring a fleet of EC2 instances in a subnet which currently is in a VPC with an Internet gateway attached. All of these EC2 instances can be accessed from the Internet. You then launch another subnet and launch an EC2 instance in it, however you are not able to access the EC2 instance from the Internet.\xa0 \xa0</p><p>What could be the possible reasons for this issue? (Choose 2)</p>', 'answers': ['The Amazon EC2 instance does not have a public IP address associated with it.', 'The Amazon EC2 instance is not a member of the same Auto Scaling group.', 'The Amazon EC2 instance is running in an Availability Zone that does not support Internet access.', 'The route table is not configured properly to send traffic from the EC2 instance to the Internet through the Internet gateway.', '<p>The route table is not configured properly to send traffic from the EC2 instance to the Internet through the customer gateway (CGW).</p>', '<p>Enhanced Network in EC2 is not enabled.</p>']}, 'related_lectures': [], 'correct_response': ['a', 'd'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a data analytics company as a Software Engineer, which has a client that is setting up an innovative checkout-free grocery store. You developed a monitoring application that uses smart sensors to collect the items that your customers are getting from the grocery’s refrigerators and shelves then automatically maps it to their accounts. To know more about the buying behavior of your customers, you want to analyze the items that are constantly being bought and store the results in S3 for durable storage.\xa0 \xa0What service can you use to easily capture, transform, and load streaming data into Amazon S3, Amazon Elasticsearch Service, and Splunk?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180588, 'original_assessment_id': 2567000, 'section': 'EIP', 'prompt': {'explanation': '<p>Amazon Kinesis Data Firehose is the easiest way to load streaming data into data stores and analytics tools. It can capture, transform, and load streaming data into Amazon S3, Amazon Redshift, Amazon Elasticsearch Service, and Splunk, enabling near real-time analytics with existing business intelligence tools and dashboards you are already using today.</p> <p>It is a fully managed service that automatically scales to match the throughput of your data and requires no ongoing administration. It can also batch, compress, and encrypt the data before loading it, minimizing the amount of storage used at the destination and increasing security.</p> <p>In the diagram below, you gather the data from your smart refrigerators and use Kinesis Data firehouse to prepare and load the data. S3 will be used as a method of durably store the data for analytics and the eventual ingestion of data for output using analytical tools.</p> <p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://udemy-images.s3.amazonaws.com/redactor/raw/2018-11-12_21-25-45-a0789b019c82e01bc6cbc2830a24f90f.png" /></p> <p>Option 2 is incorrect because Amazon Kinesis is the streaming data platform of AWS and has four distinct services under it: Kinesis Data Firehose, Kinesis Data Streams, Kinesis Video Streams, and Amazon Kinesis Data Analytics. For a specific use case of the requirement by the question, use Kinesis Data Firehose.</p> <p>Option 3 is incorrect because Amazon Redshift is mainly used for data warehousing making it simple and cost-effective to analyze your data across your data warehouse and data lake. It does not meet the requirement of being able to load and stream data into data stores for analytics. You have to use Kinesis Data Firehose instead.</p> <p>Option 4 is incorrect because Amazon Macie is mainly used as a security service that uses machine learning to automatically discover, classify, and protect sensitive data in AWS. As a security feature of AWS, it does not meet the requirements of being able to load and stream data into data stores for analytics. You have to use Kinesis Data Firehose instead.</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/kinesis/data-firehose/">https://aws.amazon.com/kinesis/data-firehose/</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are working for a data analytics company as a Software Engineer, which has a client that is setting up an innovative checkout-free grocery store. You developed a monitoring application that uses smart sensors to collect the items that your customers are getting from the grocery’s refrigerators and shelves then automatically maps it to their accounts. To know more about the buying behavior of your customers, you want to analyze the items that are constantly being bought and store the results in S3 for durable storage.\xa0 \xa0</p><p>What service can you use to easily capture, transform, and load streaming data into Amazon S3, Amazon Elasticsearch Service, and Splunk?\xa0 </p>', 'answers': ['Amazon Kinesis Data Firehose', 'Amazon Kinesis', 'Amazon Redshift', 'Amazon Macie']}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A large financial company has recently adopted a hybrid cloud architecture to integrate their on-premise data center and their AWS Cloud. Your manager has instructed you to create a new VPC network topology which must support all Internet-facing web applications as well as the internally-facing applications that is accessed by employees only over VPN. To ensure high-availability and fault tolerance, both of their Internet-facing and internally-facing financial applications must be able to leverage at least two AZs for high availability. \n\nWhat is the minimum number of subnets that you must create within your VPC to accommodate these requirements?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180578, 'original_assessment_id': 2566990, 'section': 'EC2', 'prompt': {'explanation': '<p>In this scenario, the requirement is to have at least 2 Availability Zones for both Internet-facing (public) and Internally-facing (private) applications. Remember that one subnet is mapped into one specific Availability Zone. Since we need to have at least 2 public and 2 private subnets, the correct answer is 4 subnets.&nbsp;</p> <p>A VPC spans all the Availability Zones in the region. After creating a VPC, you can add one or more subnets in each Availability Zone. When you create a subnet, you specify the CIDR block for the subnet, which is a subset of the VPC CIDR block. Each subnet must reside entirely within one Availability Zone and cannot span zones. Availability Zones are distinct locations that are engineered to be isolated from failures in other Availability Zones. By launching instances in separate Availability Zones, you can protect your applications from the failure of a single location. We assign a unique ID to each subnet.</p> <p>&nbsp;</p> <p><strong>References</strong>:</p> <p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>A large financial company has recently adopted a hybrid cloud architecture to integrate their on-premise data center and their AWS Cloud. Your manager has instructed you to create a new VPC network topology which must support all Internet-facing web applications as well as the internally-facing applications that is accessed by employees only over VPN. To ensure high-availability and fault tolerance, both of their Internet-facing and internally-facing financial applications must be able to leverage at least two AZs for high availability. </p>\n\n<p>What is the minimum number of subnets that you must create within your VPC to accommodate these requirements?</p>', 'answers': ['<p>1 subnet</p>', '<p>2 subnets</p>', '<p>3 subnets</p>', '<p>4 subnets</p>', '<p>5 subnets</p>', '<p>6\xa0subnets</p>']}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A manufacturing company has EC2 instances running in AWS. The EC2 instances are configured with Auto Scaling. There are a lot of requests being lost because of too much load on the servers. The Auto Scaling is launching new EC2 instances to take the load accordingly yet, there are still some requests that are being lost. Which of the following is the most cost-effective solution to avoid losing recently submitted requests?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180580, 'original_assessment_id': 2566992, 'section': 'SQS', 'prompt': {'explanation': '<p>&nbsp;</p><p>In this scenario, Amazon SQS is the best solution to avoid having lost messages.</p><p>Amazon Simple Queue Service (SQS) is a fully managed message queuing service that makes it easy to decouple and scale microservices, distributed systems, and serverless applications. Building applications from individual components that each perform a discrete function improves scalability and reliability, and is best practice design for modern applications. SQS makes it simple and cost-effective to decouple and coordinate the components of a cloud application. Using SQS, you can send, store, and receive messages between software components at any volume, without losing messages or requiring other services to be always available.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/sqs/" target="_blank" rel="noopener">https://aws.amazon.com/sqs/</a></p><p>&nbsp;</p>', 'answers': ['Use an SQS queue to decouple the application components', 'Keep one extra Spot EC2 instance always ready in case a spike occurs.', 'Use larger instances for your application', 'Pre-warm your Elastic Load Balancer'], 'question': 'A manufacturing company has EC2 instances running in AWS. The EC2 instances are configured with Auto Scaling. There are a lot of requests being lost because of too much load on the servers. The Auto Scaling is launching new EC2 instances to take the load accordingly yet, there are still some requests that are being lost. <br /><br />Which of the following is the most cost-effective solution to avoid losing recently submitted requests?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have an On-Demand EC2 instance located in a subnet in AWS which hosts a web application. The security group attached to this EC2 instance has the following Inbound Rules:\u200b The Route table attached to the VPC is shown below. You can establish an SSH connection into the EC2 instance from the internet. However, you are not able to connect to the web server using your Chrome browser.\u200bWhich of the below steps would resolve the issue?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180582, 'original_assessment_id': 2566994, 'section': 'VPC', 'prompt': {'explanation': '<p>The scenario is that you can already connect to the EC2 instance via SSH. This means that there is no problem in the Route Table of your VPC. To fix this issue, you simply need to update your Security Group and&nbsp;add an Inbound rule to allow HTTP traffic.</p><ul><li>Option 2 is incorrect as removing the SSH rule will not solve the issue. It will just disable SSH traffic that is already available.</li><li>Options 3 and 4 are incorrect as there is no need to change the Route Tables.</li></ul><br /><p>References:</p><p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You have an On-Demand EC2 instance located in a subnet in AWS which hosts a web application. The security group attached to this EC2 instance has the following Inbound Rules:<br><img src="https://udemy-images.s3.amazonaws.com/redactor/raw/2018-01-30_05-56-46-caf703faa13a0b156726e3dbd9b2f558.png">\u200b <br><br>The Route table attached to the VPC is shown below. You can establish an SSH connection into the EC2 instance from the internet. However, you are not able to connect to the web server using your Chrome browser.<br><img src="https://udemy-images.s3.amazonaws.com/redactor/raw/2018-01-30_05-56-46-3907edec8b91dda5adcc1d2073c61658.png">\u200b<br><br>Which of the below steps would resolve the issue?</p>', 'answers': ['In the Security Group, add an Inbound HTTP rule.', ' In the Security Group, remove the SSH rule.', 'In the Route table, add this new route entry: 0.0.0.0 -&gt; igw-b51618cc', 'In the Route table, add this new route entry: 10.0.0.0/27 -&gt; local']}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a startup as its AWS Chief Architect. You are currently assigned on a project that currently develops an online registration platform for events which uses Simple Workflow for complete control of your orchestration logic. A decider ingests the customer name, address, contact number, and email address while the activity workers update the customer with the status of their online application status via email. Recently, you were having problems with your online registration platform which was solved by checking the decision task of your workflow.\xa0 \xa0In SWF, what is the purpose of a decision task?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180600, 'original_assessment_id': 2567012, 'section': 'SWF', 'prompt': {'explanation': '<p>The decider can be viewed as a special type of worker. Like workers, it can be written in any language and asks Amazon SWF for tasks. However, it handles special tasks called decision tasks.</p><p>Amazon SWF issues decision tasks whenever a workflow execution has transitions such as an activity task completing or timing out. A decision task contains information on the inputs, outputs, and current state of previously initiated activity tasks. Your decider uses this data to decide the next steps, including any new activity tasks, and returns those to Amazon SWF. Amazon SWF in turn enacts these decisions, initiating new activity tasks where appropriate and monitoring them.</p><p>By responding to decision tasks in an ongoing manner, the decider controls the order, timing, and concurrency of activity tasks and consequently the execution of processing steps in the application. SWF issues the first decision task when an execution starts. From there on, Amazon SWF enacts the decisions made by your decider to drive your execution. The execution continues until your decider makes a decision to complete it.</p><p>&nbsp;</p><p>Resources:</p><p><a href="https://aws.amazon.com/swf/faqs/">https://aws.amazon.com/swf/faqs/</a></p><p><a href="http://docs.aws.amazon.com/amazonswf/latest/developerguide/swf-dg-dev-deciders.html">http://docs.aws.amazon.com/amazonswf/latest/developerguide/swf-dg-dev-deciders.html</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are working for a startup as its AWS Chief Architect. You are currently assigned on a project that currently develops an online registration platform for events which uses Simple Workflow for complete control of your orchestration logic. A decider ingests the customer name, address, contact number, and email address while the activity workers update the customer with the status of their online application status via email. Recently, you were having problems with your online registration platform which was solved by checking the decision task of your workflow.\xa0 \xa0</p><p>In SWF, what is the purpose of a decision task?\xa0 </p>', 'answers': ['It defines all the activities in the workflow.', 'It tells the decider the state of the workflow execution.', 'It tells the worker to perform a function.', 'It represents a single task in the workflow.']}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are a Solutions Architect in your company where you are tasked to set up a cloud infrastructure. In the planning, it was discussed that you will need two EC2 instances which should continuously run for three years. The CPU utilization of the EC2 instances is also expected to be stable and predictable.Which is the most cost-efficient Amazon EC2 Pricing type that is most appropriate for this scenario?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180590, 'original_assessment_id': 2567002, 'section': 'EC2', 'prompt': {'explanation': '<p>Reserved Instances provide you with a significant discount (up to 75%) compared to On-Demand instance pricing. In addition, when Reserved Instances are assigned to a specific Availability Zone, they provide a capacity reservation, giving you additional confidence in your ability to launch instances when you need them.</p><p>For applications that have steady state or predictable usage, Reserved Instances can provide significant savings compared to using On-Demand instances.</p><p>Reserved Instances are recommended for:</p><ul><li>-Applications with steady state usage</li><li>-Applications that may require reserved capacity</li><li>-Customers that can commit to using EC2 over a 1 or 3 year term to reduce their total computing costs</li></ul><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/ec2/pricing/">https://aws.amazon.com/ec2/pricing/</a></p><p><a href="https://aws.amazon.com/ec2/pricing/reserved-instances/">https://aws.amazon.com/ec2/pricing/reserved-instances/</a></p><p>&nbsp;</p><p>&nbsp;</p>', 'answers': ['Reserved Instances', 'On-Demand instances', 'Spot instances', 'Dedicated Hosts'], 'question': 'You are a Solutions Architect in your company where you are tasked to set up a cloud infrastructure. In the planning, it was discussed that you will need two EC2 instances which should continuously run for three years. The CPU utilization of the EC2 instances is also expected to be stable and predictable.<br /><br />Which is the most cost-efficient Amazon EC2 Pricing type that is most appropriate for this scenario?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as a Solutions Architect for an aerospace manufacturer which heavily uses AWS. They are running a cluster of multi-tier applications that spans multiple servers for your wind simulation model and how it affects your state-of-the-art wing design. Currently, you are experiencing a slowdown in your applications and upon further investigation, it was discovered that it is due to latency issues.\xa0 \xa0Which of the following EC2 features should you use to optimize performance for a compute cluster that requires low network latency?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180584, 'original_assessment_id': 2566996, 'section': 'EC2', 'prompt': {'explanation': '<p>You can launch EC2 instances in a placement group, which determines how instances are placed on underlying hardware. When you create a placement group, you specify one of the following strategies for the group:</p> <ul> <li><strong>Cluster</strong> - clusters instances into a low-latency group in a single Availability Zone</li> <li><strong>Spread</strong> - spreads instances across underlying hardware</li> </ul> <p>Option 1 is incorrect because multiple availability zones are mainly used for achieving high availability when one of the AWS AZ&rsquo;s goes down and are not used for low network latency. Use Spread Placement Groups instead for multiple availability zones.</p> <p>Option 2 is incorrect because Direct Connect bypasses the public Internet and establishes a secure, dedicated connection from your on-premise data center into AWS and not for having low latency within your AWS network. Use Placement Groups instead for low network latency.</p> <p>Option 3 is incorrect because EC2 Dedicated Instances are EC2 instances that run in a VPC on hardware that is dedicated to a single customer and are physically isolated at the host hardware level from instances that belong to other AWS accounts. It is not used for reducing latency.</p> <p>Option 5 is incorrect because VPC private subnets are used for isolating your applications from the rest of the network and not for reducing the latency between your applications. </p> <p><strong>Reference:</strong></p> <p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html</a></p>', 'feedbacks': ['', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are working as a Solutions Architect for an aerospace manufacturer which heavily uses AWS. They are running a cluster of multi-tier applications that spans multiple servers for your wind simulation model and how it affects your state-of-the-art wing design. Currently, you are experiencing a slowdown in your applications and upon further investigation, it was discovered that it is due to latency issues.\xa0 \xa0</p><p>Which of the following EC2 features should you use to optimize performance for a compute cluster that requires low network latency?\xa0 </p>', 'answers': ['Multiple Availability Zones', 'AWS Direct Connect', 'EC2 Dedicated Instances', 'Placement Groups', 'VPC private subnets']}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You installed sensors to track the number of visitors that goes to the park. The data is sent everyday to an Amazon Kinesis stream with default settings for processing, in which a consumer is configured to process the data every other day. You noticed that your S3 bucket is not receiving all of the data that is being sent to the Kinesis stream. You checked the sensors if they are\xa0properly sending the data to Amazon Kinesis and verified that the data is indeed\xa0sent everyday.What could be the reason for this?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180592, 'original_assessment_id': 2567004, 'section': 'Kinesis', 'prompt': {'explanation': '<p>Kinesis Data Streams supports changes to the data record retention period of your stream. A Kinesis data stream is an ordered sequence of data records meant to be written to and read from in real-time. Data records are therefore stored in shards in your stream temporarily.</p><p>The time period from when a record is added to when it is no longer accessible is called the&nbsp;<em>retention period</em>. A Kinesis data stream stores records from <strong>24 hours by default</strong>&nbsp;to a maximum of 168 hours.</p><p>This is the reason why there are missing data in your S3 bucket. To fix this, you can either configure your sensors to send the data everyday instead of every other day or alternatively, you can increase the retention period of your Kinesis data stream.</p><br /><p>References:</p><p><a href="http://docs.aws.amazon.com/streams/latest/dev/kinesis-extended-retention.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/streams/latest/dev/kinesis-extended-retention.html</a></p>', 'feedbacks': ['', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You installed sensors to track the number of visitors that goes to the park. The data is sent everyday to an Amazon Kinesis stream with default settings for processing, in which a consumer is configured to process the data every other day. You noticed that your S3 bucket is not receiving all of the data that is being sent to the Kinesis stream. You checked the sensors if they are\xa0properly sending the data to Amazon Kinesis and verified that the data is indeed\xa0sent everyday.<br><br>What could be the reason for this?</p>', 'answers': ['There is a problem in the sensors. They probably had some intermittent connection hence, the data is not sent to the stream.', 'By default, Amazon S3 stores the data for 1 day and moves it to Amazon Glacier.', 'Your AWS account was hacked and someone has deleted some data in your Kinesis stream.', 'Amazon Kinesis streams are not meant to process data.', 'By default, the data records are only accessible for 24 hours from the time they are added to a Kinesis stream.']}, 'related_lectures': [], 'correct_response': ['e'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are automating the creation of EC2 instances in your VPC. Hence, you wrote a python script to trigger the Amazon EC2 API to request 50 EC2 instances in a single Availability Zone. However, you noticed that after 20 successful requests, subsequent requests failed. What could be a reason for this issue and how would you resolve it?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180594, 'original_assessment_id': 2567006, 'section': 'EC2', 'prompt': {'explanation': '<p>You are limited to running up to a total of 20 On-Demand instances across the instance family, purchasing 20 Reserved Instances and requesting Spot Instances per your dynamic Spot limit per region.&nbsp;If you wish to run more than 20 instances, complete the Amazon EC2 instance request form.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html#limits_ec2">https://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html#limits_ec2</a></p><p><a href="https://aws.amazon.com/ec2/faqs/#How_many_instances_can_I_run_in_Amazon_EC2">https://aws.amazon.com/ec2/faqs/#How_many_instances_can_I_run_in_Amazon_EC2</a></p>', 'answers': ['There was an issue with the Amazon EC2 API. Just resend the requests and these will be provisioned successfully.', 'By default, AWS allows you to provision a maximum of 20 instances per region. Select a different region and retry the failed request.', 'By default, AWS allows you to provision a maximum of 20 instances per Availability Zone. Select a different Availability Zone and retry the failed request.', 'There is a soft limit of 20 instances per region which is why subsequent requests failed. Just submit the limit increase form to AWS and retry the failed requests once approved.'], 'question': 'You are automating the creation of EC2 instances in your VPC. Hence, you wrote a python script to trigger the Amazon EC2 API to request 50 EC2 instances in a single Availability Zone. However, you noticed that after 20 successful requests, subsequent requests failed. <br /><br />What could be a reason for this issue and how would you resolve it?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as an IT Consultant for a large investment bank that generates large financial datasets with millions of rows. The data must be stored in a columnar fashion to reduce the number of disk I/O requests and reduces the amount of data needed to load from disk. The bank has an existing third-party business intelligence application which will connect to storage service and then generate daily and monthly financial reports for its clients around the globe.\xa0 In this scenario, which is the best storage service to use to meet the requirement?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180610, 'original_assessment_id': 2567022, 'section': 'Redshift', 'prompt': {'explanation': '<p>Amazon Redshift is a fast, scalable data warehouse that makes it simple and cost-effective to analyze all your data across your data warehouse and data lake. Redshift delivers ten times faster performance than other data warehouses by using machine learning, massively parallel query execution, and columnar storage on high-performance disk.</p> <p>In this scenario, there is a requirement to have a storage service which will be used by a business intelligence application and where the data must be stored in a columnar fashion. Business Intelligence reporting systems is a type of Online Analytical Processing (OLAP) which Redshift is known to support. In addition, Redshift also provides columnar storage unlike the other options. Hence, the correct answer in this scenario is Option 1: Amazon Redshift.</p> <p>&nbsp;</p> <p><strong>References: </strong></p> <p><a href="https://docs.aws.amazon.com/redshift/latest/dg/c_columnar_storage_disk_mem_mgmnt.html ">https://docs.aws.amazon.com/redshift/latest/dg/c_columnar_storage_disk_mem_mgmnt.html </a></p> <p><a href="https://aws.amazon.com/redshift/">https://aws.amazon.com/redshift/</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are working as an IT Consultant for a large investment bank that generates large financial datasets with millions of rows. The data must be stored in a columnar fashion to reduce the number of disk I/O requests and reduces the amount of data needed to load from disk. The bank has an existing third-party business intelligence application which will connect to storage service and then generate daily and monthly financial reports for its clients around the globe.\xa0 </p><p>In this scenario, which is the best storage service to use to meet the requirement?</p>', 'answers': ['<p>Amazon Redshift</p>', '<p>Amazon RDS</p>', '<p>ElastiCache</p>', '<p>DynamoDB</p>', '<p>Amazon Aurora</p>', '<p>Amazon S3</p>']}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A global online sports betting company has its popular web application hosted in AWS. They are planning to develop a new online portal for their new business venture and they hired you to implement the cloud architecture for a new online portal that will accept bets globally for world sports. You started to design the system with a relational database that runs on a single EC2 instance which requires a single EBS volume that can support up to 30,000 IOPS.   In this scenario, which Amazon EBS volume type can you use that will meet the performance requirements of this new online portal?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180596, 'original_assessment_id': 2567008, 'section': 'EBS', 'prompt': {'explanation': '<p>Since the requirement is 30,000 IOPS, you have to use an EBS type of Provisioned IOPS SSD, as this type can handle a maximum of 32,000 IOPS. This provides sustained performance for mission-critical low-latency workloads.</p> <p>&nbsp;</p> <p>References:&nbsp;</p> <p><a href="https://aws.amazon.com/ebs/details/">https://aws.amazon.com/ebs/details/</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>A global online sports betting company has its popular web application hosted in AWS. They are planning to develop a new online portal for their new business venture and they hired you to implement the cloud architecture for a new online portal that will accept bets globally for world sports. You started to design the system with a relational database that runs on a single EC2 instance which requires a single EBS volume that can support up to 30,000 IOPS.   </p><p>In this scenario, which Amazon EBS volume type can you use that will meet the performance requirements of this new online portal?</p>', 'answers': ['<p>EBS Provisioned IOPS SSD</p>', '<p>EBS Throughput Optimized HDD</p>', '<p>EBS General Purpose SSD</p>', '<p>EBS Cold HDD</p>']}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A large insurance company has an AWS account that contains three VPCs (DEV, UAT and PROD) in the same region. UAT is peered to both PROD and DEV using a VPC peering connection. All VPCs have non-overlapping CIDR blocks. The company wants to push minor code releases from Dev to Prod to speed up time to market. Which of the following options helps the company accomplish this?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180598, 'original_assessment_id': 2567010, 'section': 'VPC', 'prompt': {'explanation': '<p>A VPC peering connection is a networking connection between two VPCs that enables you to route traffic between them privately. Instances in either VPC can communicate with each other as if they are within the same network. You can create a VPC peering connection between your own VPCs, with a VPC in another AWS account, or with a VPC in a different AWS Region.</p><p>AWS uses the existing infrastructure of a VPC to create a VPC peering connection; it is neither a gateway nor a VPN connection, and does not rely on a separate piece of physical hardware. There is no single point of failure for communication or a bandwidth bottleneck.&nbsp;</p><p>Options 2 and 3 are incorrect. Even if you configure the route tables, the two VPCs will still be disconnected until you set up a VPC peering connection between them.</p><p>Option 4 is incorrect because you cannot peer two VPCs with overlapping CIDR blocks.</p><p>Option 5 is incorrect as transitive VPC peering is not allowed hence, even though DEV and PROD are both connected in UAT, these two VPCs do not have a direct connection to each other.&nbsp;</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-peering.html">https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-peering.html</a></p><p>&nbsp;</p>', 'answers': ['Create a new VPC peering connection between PROD and DEV with the appropriate routes.', 'Create a new entry to PROD in the DEV route table using the VPC peering connection as the target.', 'Attach a second gateway to DEV. Add a new entry in the PROD route table identifying the gateway as the target.', 'Change the DEV and PROD VPCs to have overlapping CIDR blocks to be able to connect them.', 'Do nothing. Since these two VPCs are already connected via UAT, they already have a connection to each other.'], 'question': 'A large insurance company has an AWS account that contains three VPCs (DEV, UAT and PROD) in the same region. UAT is peered to both PROD and DEV using a VPC peering connection. All VPCs have non-overlapping CIDR blocks. The company wants to push minor code releases from Dev to Prod to speed up time to market. <br /><br />Which of the following options helps the company accomplish this?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for an insurance firm as their Senior Solutions Architect. The firm has an application which processes thousands of customer data stored in an Amazon MySQL database with Multi-AZ deployments configuration for high availability in case of downtime. For the past few days, you noticed an increasing trend of read and write operations, which is increasing the latency of the queries to your database. You are planning to use the standby database instance to balance the read and write operations from the primary instance.\xa0 When running your primary Amazon RDS Instance as a Multi-AZ deployment, can you use the standby instance for read and write operations?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180616, 'original_assessment_id': 2567028, 'section': 'RDS', 'prompt': {'explanation': '<p>The answer is No. The standby instance&nbsp;will not perform any read and write operations while the primary instance is running.</p><p>Multi-AZ deployments for the MySQL, MariaDB, Oracle, and PostgreSQL engines utilize synchronous physical replication to keep data on the standby up-to-date with the primary. Multi-AZ deployments for the SQL Server engine use synchronous logical replication to achieve the same result, employing SQL Server-native Mirroring technology. Both approaches safeguard your data in the event of a DB Instance failure or loss of an Availability Zone.</p><p>If a storage volume on your primary instance fails in a Multi-AZ deployment, Amazon RDS automatically initiates a failover to the up-to-date standby (or to a replica in the case of Amazon Aurora). Compare this to a Single-AZ deployment: in case of a Single-AZ database failure, a user-initiated point-in-time-restore operation will be required. This operation can take several hours to complete, and any data updates that occurred after the latest restorable time (typically within the last five minutes) will not be available.</p><p>&nbsp;</p><p>Resources:</p><p><a href="https://aws.amazon.com/rds/details/multi-az/">https://aws.amazon.com/rds/details/multi-az/</a></p><p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are working for an insurance firm as their Senior Solutions Architect. The firm has an application which processes thousands of customer data stored in an Amazon MySQL database with Multi-AZ deployments configuration for high availability in case of downtime. For the past few days, you noticed an increasing trend of read and write operations, which is increasing the latency of the queries to your database. You are planning to use the standby database instance to balance the read and write operations from the primary instance.\xa0 </p><p>When running your primary Amazon RDS Instance as a Multi-AZ deployment, can you use the standby instance for read and write operations?\xa0 </p>', 'answers': ['Yes', 'Only with Microsoft SQL Server-based RDS', 'Only for Oracle RDS instances', 'No']}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multi-select', 'question_plain': 'A music company is storing data on Amazon Simple Storage Service (S3). The company’s security policy requires that data is encrypted at rest. Which of the following methods can achieve this? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180602, 'original_assessment_id': 2567014, 'section': 'S3', 'prompt': {'explanation': '<p>Data protection refers to protecting data while in-transit (as it travels to and from Amazon S3) and at rest (while it is stored on disks in Amazon S3 data centers). You can protect data in transit by using SSL or by using client-side encryption. You have the following options of protecting data at rest in Amazon S3:</p><p><strong>Use Server-Side Encryption</strong>&nbsp;&ndash; You request Amazon S3 to encrypt your object before saving it on disks in its data centers and decrypt it when you download the objects.</p><ul><li>-Use Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3)</li><li>-Use Server-Side Encryption with AWS KMS-Managed Keys (SSE-KMS)</li><li>-Use Server-Side Encryption with Customer-Provided Keys (SSE-C)</li></ul><p>&nbsp;</p><p><strong>Use Client-Side Encryption</strong>&nbsp;&ndash; You can encrypt data client-side and upload the encrypted data to Amazon S3. In this case, you manage the encryption process, the encryption keys, and related tools.</p><ul><li>-Use Client-Side Encryption with AWS KMS&ndash;Managed Customer Master Key (CMK)</li><li>-Use Client-Side Encryption Using a Client-Side Master Key</li></ul><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingEncryption.html">http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingEncryption.html</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>A music company is storing data on Amazon Simple Storage Service (S3). The company’s security policy requires that data is encrypted at rest. <br><br>Which of the following methods can achieve this? (Choose 3)</p>', 'answers': ['Use Amazon S3 server-side encryption with AWS Key Management Service managed keys.', 'Use Amazon S3 server-side encryption with customer-provided keys.', 'Use Amazon S3 bucket policies to restrict access to the data at rest.', 'Use Amazon S3 server-side encryption with EC2 key pair.', 'Encrypt the data on the client-side before ingesting to Amazon S3 using their own master key.', 'Use SSL to encrypt the data while in transit to Amazon S3.']}, 'related_lectures': [], 'correct_response': ['a', 'b', 'e'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are working for an investment bank as their IT Consultant. You are working with their IT team to handle the launch of their digital wallet system. The applications will run on multiple EBS-backed EC2 instances which will store the logs, transactions, and billing statements of the user in an S3 bucket. Due to tight security and compliance requirements, you are exploring options on how to safely store sensitive data on the EBS volumes and S3.\xa0 \xa0Which of the below options should be carried out on AWS when storing sensitive data? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180606, 'original_assessment_id': 2567018, 'section': 'EBS', 'prompt': {'explanation': '<p>Amazon EBS encryption offers a simple encryption solution for your EBS volumes without the need to build, maintain, and secure your own key management infrastructure.&nbsp;</p> <p>In Amazon S3, data protection refers to protecting data while in-transit (as it travels to and from Amazon S3) and at rest (while it is stored on disks in Amazon S3 data centers). You can protect data in transit by using SSL or by using client-side encryption. You have the following options to protect data at rest in Amazon S3.</p> <div> <ul type="disc"> <li> <p><strong>Use Server-Side Encryption</strong>&nbsp;&ndash; You request Amazon S3 to encrypt your object before saving it on disks in its data centers and decrypt it when you download the objects.</p> </li> <li> <p><strong>Use Client-Side Encryption</strong>&nbsp;&ndash; You can encrypt data client-side and upload the encrypted data to Amazon S3. In this case, you manage the encryption process, the encryption keys, and related tools.</p> </li> </ul> </div> <p>References:</p> <p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html</a></p> <p><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingEncryption.html">http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingEncryption.html</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are working for an investment bank as their IT Consultant. You are working with their IT team to handle the launch of their digital wallet system. The applications will run on multiple EBS-backed EC2 instances which will store the logs, transactions, and billing statements of the user in an S3 bucket. Due to tight security and compliance requirements, you are exploring options on how to safely store sensitive data on the EBS volumes and S3.\xa0 \xa0</p><p>Which of the below options should be carried out on AWS when storing sensitive data? (Choose 3)\xa0 </p>', 'answers': ['<p>Create an EBS Snapshot</p>', 'Enable EBS Encryption', 'Encrypt the file system on an EBS volume using Linux tools', 'Enable Amazon S3 Server-Side and Client-Side Encryption']}, 'related_lectures': [], 'correct_response': ['b', 'c', 'd'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A document sharing website is using AWS as its cloud infrastructure. Free users can upload a total of 5 GB data while premium users can upload as much as 5 TB. Their application uploads the user files, which can have a max file size of 1 TB, to an S3 Bucket. In this scenario, what is the best way for the application to upload the large files in S3?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180604, 'original_assessment_id': 2567016, 'section': 'S3', 'prompt': {'explanation': '<p>The total volume of data and number of objects you can store are unlimited. Individual Amazon S3 objects can range in size from a minimum of 0 bytes to a maximum of 5 terabytes. The largest object that can be uploaded in a single PUT is 5 gigabytes. For objects larger than 100 megabytes, customers should consider using the Multipart Upload capability.</p><p>The Multipart upload API enables you to upload large objects in parts. You can use this API to upload new large objects or make a copy of an existing object. Multipart uploading is a three-step process: you initiate the upload, you upload the object parts, and after you have uploaded all the parts, you complete the multipart upload. Upon receiving the complete multipart upload request, Amazon S3 constructs the object from the uploaded parts and you can then access the object just as you would any other object in your bucket.</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html">https://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html</a></p><p><a href="https://aws.amazon.com/s3/faqs/">https://aws.amazon.com/s3/faqs/</a></p><p>&nbsp;</p><p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>A document sharing website is using AWS as its cloud infrastructure. Free users can upload a total of 5 GB data while premium users can upload as much as 5 TB. Their application uploads the user files, which can have a max file size of 1 TB, to an S3 Bucket. </p><p>In this scenario, what is the best way for the application to upload the large files in S3?</p>', 'answers': ['Use a single PUT request to upload the large file', 'Use Amazon Snowball', 'Use AWS Import/Export', 'Use Multipart Upload']}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'One of your clients wants to leverage on Amazon S3 and Amazon Glacier as part of their backup and archive infrastructure. They created a new S3 bucket called “tutorialsdojobackup”. To support this integration between AWS and their on-premise network, they decided to use a third-party software.Which approach will limit the access of the third party software to the Amazon S3 bucket only and not to other AWS resources?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180608, 'original_assessment_id': 2567020, 'section': 'S3', 'prompt': {'explanation': '<p>In this scenario, you have to provide access to your VPC to the third party software by creating a new IAM user. Since you want to limit the access of the third party software, you can simply manage the available AWS resources that it can communicate with by setting up a custom user policy, which will only allow access to a specific S3 bucket.</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/example-policies-s3.html">https://docs.aws.amazon.com/AmazonS3/latest/dev/example-policies-s3.html</a></p><p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/walkthrough1.html">https://docs.aws.amazon.com/AmazonS3/latest/dev/walkthrough1.html</a></p>', 'answers': ['Setup a custom bucket policy limited to the Amazon S3 API in the Amazon Glacier archive “tutorialsdojobackup”.', 'A custom S3 bucket policy limited to the Amazon S3 API in “tutorialsdojobackup”.', 'A custom IAM user policy limited to the Amazon S3 API for the Amazon Glacier archive “tutorialsdojobackup”.', 'In IAM, setup a custom user policy for the third party software that is limited to the Amazon S3 API in the "tutorialsdojobackup" bucket.'], 'question': 'One of your clients wants to leverage on Amazon S3 and Amazon Glacier as part of their backup and archive infrastructure. They created a new S3 bucket called “tutorialsdojobackup”. To support this integration between AWS and their on-premise network, they decided to use a third-party software.<br /><br />Which approach will limit the access of the third party software to the Amazon S3 bucket only and not to other AWS resources?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a Social Media Analytics company as its head data analyst. You want to collect gigabytes of data per second from websites and social media feeds to gain insights from data generated by its offerings and continuously improve the user experience. To meet this design requirement, you have developed an application hosted on an Auto Scaling group of Spot EC2 instances which processes the data and stores the results to DynamoDB and Redshift.\xa0 \xa0Which AWS service can you use to collect and process large streams of data records in real time?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180620, 'original_assessment_id': 2567032, 'section': 'Kinesis', 'prompt': {'explanation': '<p>Amazon Kinesis Data Streams is used to collect and process large streams of data records in real time. You can use Kinesis Data Streams for rapid and continuous data intake and aggregation. The type of data used includes IT infrastructure log data, application logs, social media, market data feeds, and web clickstream data. Because the response time for the data intake and processing is in real time, the processing is typically lightweight.</p><p>&nbsp;</p><p>Resources:</p><p><a href="https://docs.aws.amazon.com/streams/latest/dev/introduction.html">https://docs.aws.amazon.com/streams/latest/dev/introduction.html</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are working for a Social Media Analytics company as its head data analyst. You want to collect gigabytes of data per second from websites and social media feeds to gain insights from data generated by its offerings and continuously improve the user experience. To meet this design requirement, you have developed an application hosted on an Auto Scaling group of Spot EC2 instances which processes the data and stores the results to DynamoDB and Redshift.\xa0 \xa0</p><p>Which AWS service can you use to collect and process large streams of data records in real time?\xa0 </p>', 'answers': ['Amazon S3', 'Amazon Redshift', 'Amazon SWF', 'Amazon Kinesis Data Streams']}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a startup company that has resources deployed on the AWS Cloud. Your company is now going through a set of scheduled audits by an external auditing firm for compliance. Which of the following services available in AWS can be utilized to help ensure the right information is present for auditing purposes?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180612, 'original_assessment_id': 2567024, 'section': 'CloudTrail', 'prompt': {'explanation': '<p>AWS CloudTrail is a service that enables governance, compliance, operational auditing, and risk auditing of your AWS account. With CloudTrail, you can log, continuously monitor, and retain account activity related to actions across your AWS infrastructure. CloudTrail provides event history of your AWS account activity, including actions taken through the AWS Management Console, AWS SDKs, command line tools, and other AWS services. This event history simplifies security analysis, resource change tracking, and troubleshooting.</p><p>CloudTrail provides visibility into user activity by recording actions taken on your account. CloudTrail records important information about each action, including who made the request, the services used, the actions performed, parameters for the actions, and the response elements returned by the AWS service. This information helps you to track changes made to your AWS resources and troubleshoot operational issues. CloudTrail makes it easier to ensure compliance with internal policies and regulatory standards.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/cloudtrail/">https://aws.amazon.com/cloudtrail/</a></p><p>&nbsp;</p>', 'answers': ['AWS CloudTrail', 'AWS VPC', 'AWS EC2', 'AWS Cloudwatch'], 'question': 'You are working for a startup company that has resources deployed on the AWS Cloud. Your company is now going through a set of scheduled audits by an external auditing firm for compliance. <br /><br />Which of the following services available in AWS can be utilized to help ensure the right information is present for auditing purposes?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are working for a FinTech startup as their AWS Solutions Architect. You deployed an application on different EC2 instances with Elastic IP addresses attached for easy DNS resolution and configuration. These servers are only accessed from 8 AM to 6 PM and can be stopped from 6 PM to 8 AM for cost efficiency using Lambda with the script that automates this based on tags.\xa0 \xa0Which of the following will occur when an EC2-VPC instance with an associated Elastic IP is stopped and started? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180614, 'original_assessment_id': 2567026, 'section': 'EC2', 'prompt': {'explanation': '<p>This question did not mention the specific type of EC2 instance however, it says that it will be stopped and started. Since only EBS-backed instances can be stopped and restarted, it is implied that the instance is EBS-backed. Remember that an&nbsp;instance store-backed instance can only be rebooted or terminated and its data will be erased if the EC2 instance is terminated.</p><p>If you stopped an EBS-backed EC2 instance, the volume is preserved but the data in any attached Instance store volumes will be erased. Keep in mind that an EC2 instance has an underlying physical host computer. If the instance is stopped, AWS usually moves the instance to a new host computer. Your instance may stay on the same host computer if there are no problems with the host computer. In addition, its Elastic IP address is disassociated from the instance if it is an EC2-Classic instance. Otherwise, if it is an EC2-VPC instance, the Elastic IP address remains associated.</p><p>&nbsp;</p><p>Resources:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html</a></p><p>&nbsp;</p>', 'feedbacks': ['', '', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are working for a FinTech startup as their AWS Solutions Architect. You deployed an application on different EC2 instances with Elastic IP addresses attached for easy DNS resolution and configuration. These servers are only accessed from 8 AM to 6 PM and can be stopped from 6 PM to 8 AM for cost efficiency using Lambda with the script that automates this based on tags.\xa0 \xa0</p><p>Which of the following will occur when an EC2-VPC instance with an associated Elastic IP is stopped and started? (Choose 2)\xa0 </p>', 'answers': ['The underlying host for the instance is possibly changed.', 'The ENI (Elastic Network Interface) is detached.', 'All data on the attached instance-store devices will be lost.', '<p>The Elastic IP address is disassociated with the instance.</p>', 'There will be no changes.', '<p>All data on the attached instance-store devices will remain.</p>']}, 'related_lectures': [], 'correct_response': ['a', 'c'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a large IT consultancy company. One of your clients is launching a two-tier, highly available web application to AWS. Which service provides durable storage for static content while lowering the CPU utilization for the web tier?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180618, 'original_assessment_id': 2567030, 'section': 'S3', 'prompt': {'explanation': '<p>Amazon S3 is storage for the Internet. It&rsquo;s a simple storage service that offers software developers a durable, highly-scalable, reliable, and low-latency data storage infrastructure at very low costs.&nbsp; Amazon S3 provides customers with a highly durable storage infrastructure. Versioning offers an additional level of protection by providing a means of recovery when customers accidentally overwrite or delete objects.&nbsp;</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/s3/faqs/">https://aws.amazon.com/s3/faqs/</a>&nbsp;</p>', 'answers': ['Amazon EBS volume', 'Amazon S3', 'Amazon EC2 instance store', 'Amazon RDS instance'], 'question': 'You are working for a large IT consultancy company. One of your clients is launching a two-tier, highly available web application to AWS. Which service provides durable storage for static content while lowering the CPU utilization for the web tier?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multi-select', 'question_plain': 'An online stock trading application that stores financial data in an S3 bucket has a lifecycle policy that moves older data to Glacier every month. There is a strict compliance requirement where a surprise audit can happen at anytime and you should be able to retrieve the required data in under 15 minutes under all circumstances. Your manager instructed you to ensure that retrieval capacity is available when you need it and should handle up to 150 MB/s of retrieval throughput.\xa0 \xa0Which of the following should you do to meet the above requirement? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180622, 'original_assessment_id': 2567034, 'section': 'Glacier', 'prompt': {'explanation': '<p>Expedited retrievals allow you to quickly access your data when occasional urgent requests for a subset of archives are required. For all but the largest archives (250 MB+), data accessed using Expedited retrievals are typically made available within 1&ndash;5 minutes. Provisioned Capacity ensures that retrieval capacity for Expedited retrievals is available when you need it.</p> <p>To make an Expedited, Standard, or Bulk retrieval, set the Tier parameter in the Initiate Job (POST jobs) REST API request to the option you want, or the equivalent in the AWS CLI or AWS SDKs. If you have purchased provisioned capacity, then all expedited retrievals are automatically served through your provisioned capacity.</p> <p>Provisioned capacity ensures that your retrieval capacity for expedited retrievals is available when you need it. Each unit of capacity provides that at least three expedited retrievals can be performed every five minutes and provides up to 150 MB/s of retrieval throughput. You should purchase provisioned retrieval capacity if your workload requires highly reliable and predictable access to a subset of your data in minutes. Without provisioned capacity Expedited retrievals are accepted, except for rare situations of unusually high demand. However, if you require access to Expedited retrievals under all circumstances, you must purchase provisioned retrieval capacity.</p> <p>Option 1 is incorrect because Standard retrievals typically complete within 3&ndash;5 hours hence, this does not satisfy the requirement of retrieving the data within 15 minutes. The provisioned capacity option is not compatible with Standard retrievals.</p> <p>Option 3 is incorrect because Bulk retrievals typically complete within 5&ndash;12 hours hence, this does not satisfy the requirement of retrieving the data within 15 minutes. The provisioned capacity option is also not compatible with Bulk retrievals.</p> <p>Option 4 is incorrect because Amazon Glacier Select is not an archive retrieval option and is primarily used to perform filtering operations using simple Structured Query Language (SQL) statements directly on your data archive in Glacier.</p> <p>Option 5 is incorrect because using ranged archive retrievals is not enough to meet the requirement of retrieving the whole archive in the given timeframe. In addition, it does not provide additional retrieval capacity which is what the provisioned capacity option can offer.</p> <p><strong>References: </strong></p> <p><a href="https://docs.aws.amazon.com/amazonglacier/latest/dev/downloading-an-archive-two-steps.html ">https://docs.aws.amazon.com/amazonglacier/latest/dev/downloading-an-archive-two-steps.html </a></p> <p><a href="https://docs.aws.amazon.com/amazonglacier/latest/dev/glacier-select.html">https://docs.aws.amazon.com/amazonglacier/latest/dev/glacier-select.html</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>An online stock trading application that stores financial data in an S3 bucket has a lifecycle policy that moves older data to Glacier every month. There is a strict compliance requirement where a surprise audit can happen at anytime and you should be able to retrieve the required data in under 15 minutes under all circumstances. Your manager instructed you to ensure that retrieval capacity is available when you need it and should handle up to 150 MB/s of retrieval throughput.\xa0 \xa0</p><p>Which of the following should you do to meet the above requirement? (Choose 2)</p>', 'answers': ['<p>Use Standard Retrieval to access the financial data.</p>', '<p>Use Expedited Retrieval to access the financial data.</p>', '<p>Use Bulk Retrieval to access the financial data.</p>', '<p>Retrieve the data using Amazon Glacier Select.</p>', '<p>Specify a range, or portion, of the financial data archive to retrieve.</p>', '<p>Purchase provisioned retrieval capacity.</p>']}, 'related_lectures': [], 'correct_response': ['b', 'f'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as an IT Consultant for a large media company where you are tasked to design a web application that stores static assets in an Amazon Simple Storage Service (S3) bucket. You expect this S3 bucket to immediately receive over 2000 PUT requests and 3500 GET requests per second at peak hour. What should you do to ensure optimal performance?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180624, 'original_assessment_id': 2567036, 'section': 'S3', 'prompt': {'explanation': '<p>Amazon S3 now provides increased performance to support at least 3,500 requests per second to add data and 5,500 requests per second to retrieve data, which can save significant processing time for no additional charge.&nbsp;Each S3 prefix can support these request rates, making it simple to increase performance significantly.</p> <div class="aws-text-box section"> <div class="  "> <p>Applications running on Amazon S3 today will enjoy this performance improvement with no changes, and customers building new applications on S3 do not have to make any application customizations to achieve this performance. Amazon S3\'s support for parallel requests means you can scale your S3 performance by the factor of your compute cluster, without making any customizations to your application. Performance scales per prefix, so you can use as many prefixes as you need in parallel to achieve the required throughput. There are no limits to the number of prefixes.</p> </div> </div> <div class="aws-text-box section"> <div class="  "> <p>This S3 request rate performance increase removes any previous guidance to randomize object prefixes to achieve faster performance. That means you can now use logical or sequential naming patterns in S3 object naming without any performance implications. This improvement is now available in all&nbsp;AWS Regions.&nbsp;</p> </div> </div> <p>&nbsp;&nbsp;</p> <p><strong>References:&nbsp;</strong></p> <p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/request-rate-perf-considerations.html">https://docs.aws.amazon.com/AmazonS3/latest/dev/request-rate-perf-considerations.html</a></p> <p><a href="https://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/">https://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/</a></p> <p>&nbsp;</p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are working as an IT Consultant for a large media company where you are tasked to design a web application that stores static assets in an Amazon Simple Storage Service (S3) bucket. You expect this S3 bucket to immediately receive over 2000 PUT requests and 3500 GET requests per second at peak hour. <br><br>What should you do to ensure optimal performance?</p>', 'answers': ['Use Amazon Glacier instead.', 'Add a random prefix to the key names.', 'Do nothing. Amazon S3 will automatically manage performance at this scale.', 'Use a predictable naming scheme in the key names such as sequential numbers or date time sequences.']}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': "You are working as a Solutions Architect for a multinational financial firm. They have a global online trading platform in which the users from all over the world regularly upload terabytes of transaction data to a centralized S3 bucket. What AWS feature should you use in your present system to improve throughput and ensure consistently fast data transfer to the Amazon S3 bucket, regardless of your user's location?", '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180626, 'original_assessment_id': 2567038, 'section': 'S3', 'prompt': {'explanation': '<p>Amazon S3 Transfer Acceleration enables fast, easy, and secure transfers of files over long distances between your client and your Amazon S3 bucket. Transfer Acceleration leverages Amazon CloudFront&rsquo;s globally distributed AWS Edge Locations. As data arrives at an AWS Edge Location, data is routed to your Amazon S3 bucket over an optimized network path.&nbsp;</p><p>&nbsp;</p><p>Resources:</p><p><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html">http://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': "You are working as a Solutions Architect for a multinational financial firm. They have a global online trading platform in which the users from all over the world regularly upload terabytes of transaction data to a centralized S3 bucket. What AWS feature should you use in your present system to improve throughput and ensure consistently fast data transfer to the Amazon S3 bucket, regardless of your user's location?", 'answers': ['FTP', 'AWS Direct Connect', 'Amazon S3 Transfer Acceleration', 'Amazon S3 RRS']}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are a new Solutions Architect working for a financial company. Your manager wants to have the ability to automatically transfer obsolete data from their S3 bucket to a low cost storage system in AWS. What is the best solution you can provide to them?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180628, 'original_assessment_id': 2567040, 'section': 'S3', 'prompt': {'explanation': '<p>In this scenario, you can use lifecycle policies in S3 to automatically move obsolete data to Glacier.</p><p>Lifecycle configuration in Amazon S3 enables you to specify the lifecycle management of objects in a bucket. The configuration is a set of one or more rules, where each rule defines an action for Amazon S3 to apply to a group of objects. These actions can be classified as follows:</p><ul><li><strong>Transition actions</strong>&nbsp;&ndash; In which you define when objects transition to another storage class.&nbsp;For example, you may choose to transition objects to the STANDARD_IA (IA, for infrequent access) storage class 30 days after creation, or archive objects to the GLACIER storage class one year after creation.</li><li><strong>Expiration actions</strong>&nbsp;&ndash; In which you specify when the objects expire. Then Amazon S3 deletes the expired objects on your behalf.</li></ul><p>&nbsp;</p><p>Option 1 is incorrect because you don\'t need to create a scheduled job in EC2 as you can just simply use the lifecycle policy in S3.&nbsp;</p><p>Options 3 and 4 are incorrect as SQS and SWF are not storage services.</p><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html">http://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html</a></p><p><a href="https://aws.amazon.com/blogs/aws/archive-s3-to-glacier/">https://aws.amazon.com/blogs/aws/archive-s3-to-glacier/</a></p>', 'answers': ['Use an EC2 instance and a scheduled job to transfer the obsolete data from their S3 location to Amazon Glacier.', 'Use Lifecycle Policies in S3 to move obsolete data to Glacier.', 'Use AWS SQS.', 'Use AWS SWF.'], 'question': 'You are a new Solutions Architect working for a financial company. Your manager wants to have the ability to automatically transfer obsolete data from their S3 bucket to a low cost storage system in AWS. <br /><br />What is the best solution you can provide to them?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are designing a social media website for a startup company and the founders want to know the ways to mitigate distributed denial-of-service (DDoS) attacks to their website. Which of the following are viable mitigation techniques? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180630, 'original_assessment_id': 2567042, 'section': 'Security', 'prompt': {'explanation': '<p>A Denial of Service (DoS) attack is an attack that can make your website or application unavailable to end users. To achieve this, attackers use a variety of techniques that consume network or other resources, disrupting access for legitimate end users.</p><p>To protect your system from SoS attack, you can the following:</p><ul><li>-Use an Amazon CloudFront service for distributing both static and dynamic content.</li><li>-Use an Application Load Balancer with Auto Scaling groups for your EC2 instances then restrict direct Internet traffic to your Amazon RDS database by deploying to a private subnet.</li><li>-Setup alerts in Amazon CloudWatch to look for high <code>Network In</code> and CPU utilization.</li></ul><br /><p>Services that are available within AWS Regions, like Elastic Load Balancing and Amazon Elastic Compute Cloud (EC2), allow you to build Distributed Denial of Service resiliency and scale to handle unexpected volumes of traffic within a given region. Services that are available in AWS edge locations, like Amazon CloudFront, AWS WAF, Amazon Route53, and Amazon API Gateway, allow you to take advantage of a global network of edge locations that can provide your application with greater fault tolerance and increased scale for managing larger volumes of traffic.&nbsp;</p><p>&nbsp;</p><p>Resources:</p><p><a href="https://d0.awsstatic.com/whitepapers/DDoS_White_Paper_June2015.pdf">https://d0.awsstatic.com/whitepapers/DDoS_White_Paper_June2015.pdf</a></p>', 'answers': ['Write a shell script to quickly add and remove rules to the instance firewall.', 'Use Dedicated EC2 instances to ensure that each instance has the maximum performance possible.', 'Use an Amazon CloudFront service for distributing both static and dynamic content.', 'Use an Application Load Balancer with Auto Scaling groups for your EC2 instances then restrict direct Internet traffic to your Amazon RDS database by deploying to a private subnet.', 'Setup alerts in Amazon CloudWatch to look for high <code>Network In</code> and CPU utilization.', 'Add multiple elastic network interfaces (ENIs) to each EC2 instance to increase the network bandwidth.'], 'question': 'You are designing a social media website for a startup company and the founders want to know the ways to mitigate distributed denial-of-service (DDoS) attacks to their website. <br /><br />Which of the following are viable mitigation techniques? (Choose 3)'}, 'related_lectures': [], 'correct_response': ['c', 'd', 'e'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a tech company that uses a lot of EBS volumes in their EC2 instances. An incident occurred that requires you to delete the EBS volumes and then re-create them again.\xa0 \xa0What step should you do before you delete the EBS volumes?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180632, 'original_assessment_id': 2567044, 'section': 'EBS', 'prompt': {'explanation': '<p>You can back up the data on your Amazon EBS volumes to Amazon S3 by taking point-in-time snapshots. Snapshots are&nbsp;<em>incremental</em>&nbsp;backups, which means that only the blocks on the device that have changed after your most recent snapshot are saved.&nbsp;</p><p>When you no longer need an Amazon EBS volume, you can delete it. After deletion, its data is gone and the volume can\'t be attached to any instance. However, before deletion, you can store a snapshot of the volume, which you can use to re-create the volume later.</p><ul><li>Option 1 is incorrect as there is no such thing as&nbsp;CopyEBSVolume command.</li><li>Options 3 and 4 are wrong as these actions take a lot of time. The best and easiest way is to create a snapshot.</li></ul><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-deleting-volume.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-deleting-volume.html</a></p><p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are working for a tech company that uses a lot of EBS volumes in their EC2 instances. An incident occurred that requires you to delete the EBS volumes and then re-create them again.\xa0 \xa0</p><p>What step should you do before you delete the EBS volumes?</p>', 'answers': ['Create a copy of the EBS volume using the CopyEBSVolume command.', 'Store a snapshot of the volume.', 'Download the content to an EC2 instance.', 'Back up the data into a physical disk.']}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': "One of your clients is leveraging on Amazon S3 in the ap-southeast-1 region to store their training videos for their employee onboarding process. The client is storing the videos using the Standard Storage class. Where are your client's training videos replicated?", '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180634, 'original_assessment_id': 2567046, 'section': 'S3', 'prompt': {'explanation': '<p>Amazon S3 runs on the world&rsquo;s largest global cloud infrastructure and was built from the ground up to deliver a customer promise of 99.999999999% durability. Data is automatically distributed across a minimum of three physical facilities that are geographically separated within an AWS Region, and Amazon S3 can also automatically replicate data to any other AWS Region.</p><p>Since the question did not say that the&nbsp;Cross-region replication (CRR) is enabled, then the correct answer is Option 3. Amazon S3 replicates the data to multiple facilities in the same region where it is located, which is ap-southeast-1</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/s3/">https://aws.amazon.com/s3/</a></p>', 'answers': ['A single facility in ap-southeast-1 and a single facility in eu-central-1', 'A single facility in ap-southeast-1 and a single facility in us-east-1', 'Multiple facilities in ap-southeast-1', 'A single facility in ap-southeast-1'], 'question': "One of your clients is leveraging on Amazon S3 in the ap-southeast-1 region to store their training videos for their employee onboarding process. The client is storing the videos using the Standard Storage class. <br /><br />Where are your client's training videos replicated?"}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multi-select', 'question_plain': 'Your company has recently deployed a new web application which uses a serverless-based architecture in AWS. Your manager instructed you to implement CloudWatch metrics to monitor your systems more effectively. You know that Lambda automatically monitors functions on your behalf and reports metrics through Amazon CloudWatch.\xa0 \xa0In this scenario, what types of data do these metrics monitor? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180636, 'original_assessment_id': 2567048, 'section': 'Lambda', 'prompt': {'explanation': '<p>AWS Lambda automatically monitors functions on your behalf, reporting metrics through Amazon CloudWatch. These metrics include total requests, latency, and error rates. The throttles, Dead Letter Queues errors and Iterator age for stream-based invocations are also monitored.</p> <p>You can monitor metrics for Lambda and view logs by using the Lambda console, the CloudWatch console, the AWS CLI, or the CloudWatch API.&nbsp;</p> <p>&nbsp;</p> <p><strong>References:</strong></p> <p><a href="https://docs.aws.amazon.com/lambda/latest/dg/monitoring-functions-access-metrics.html">https://docs.aws.amazon.com/lambda/latest/dg/monitoring-functions-access-metrics.html</a></p> <p><a href="https://docs.aws.amazon.com/lambda/latest/dg/monitoring-functions-metrics.html">https://docs.aws.amazon.com/lambda/latest/dg/monitoring-functions-metrics.html</a>&nbsp;</p>', 'feedbacks': ['', '', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>Your company has recently deployed a new web application which uses a serverless-based architecture in AWS. Your manager instructed you to implement CloudWatch metrics to monitor your systems more effectively. You know that Lambda automatically monitors functions on your behalf and reports metrics through Amazon CloudWatch.\xa0 \xa0</p><p>In this scenario, what types of data do these metrics monitor? (Choose 3)</p>', 'answers': ['<p><code>Duration</code></p>', '<p><code>Invocations</code> </p>', '<p><code>Errors</code> </p>', '<p><code>IteratorSize</code> </p>', '<p><code>Dead Letter Queue</code> </p>', '<p><code>ReservedConcurrentExecutions</code> </p>']}, 'related_lectures': [], 'correct_response': ['a', 'b', 'c'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A company is hosting EC2 instances that are on non-production environment and processing non-priority batch loads, which can be interrupted at any time.\xa0 \xa0What is the best instance purchasing option which can be applied to your EC2 instances in this case?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180638, 'original_assessment_id': 2567050, 'section': 'EC2', 'prompt': {'explanation': '<p>Amazon EC2 Spot instances are spare compute capacity in the AWS cloud available to you at steep discounts compared to On-Demand prices. It can be interrupted by AWS EC2 with two minutes of notification when the EC2 needs the capacity back.&nbsp;</p><br /><p>Resources:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html"  target="_blank" >http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html</a></p><p><a href="https://aws.amazon.com/ec2/spot/"  target="_blank" >https://aws.amazon.com/ec2/spot/</a></p><p>&nbsp;</p>', 'feedbacks': ['', '', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>A company is hosting EC2 instances that are on non-production environment and processing non-priority batch loads, which can be interrupted at any time.\xa0 \xa0</p><p>What is the best instance purchasing option which can be applied to your EC2 instances in this case?\xa0 </p>', 'answers': ['Reserved Instances', 'On-Demand Instances', 'Spot Instances', 'Regular Instances', '<p>Scheduled Reserved Instances\xa0 </p>', '<p>Capacity Reservations\xa0 </p>']}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as a Solutions Architect for a leading airline company where you are building a decoupled application in AWS using EC2, Auto Scaling group, S3 and SQS. You designed the architecture in such a way that the EC2 instances will consume the message from the SQS queue and will automatically scale up or down based on the number of messages in the queue.\xa0 \xa0In this scenario, which of the following statements is false about SQS?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180658, 'original_assessment_id': 2567070, 'section': 'SQS', 'prompt': {'explanation': '<p>All of the answers are correct except for option 2. Only FIFO queues can preserve the order of messages and not standard queues. </p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/sqs/faqs/">https://aws.amazon.com/sqs/faqs/</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are working as a Solutions Architect for a leading airline company where you are building a decoupled application in AWS using EC2, Auto Scaling group, S3 and SQS. You designed the architecture in such a way that the EC2 instances will consume the message from the SQS queue and will automatically scale up or down based on the number of messages in the queue.\xa0 \xa0</p><p>In this scenario, which of the following statements is false about SQS?</p>', 'answers': ['Standard queues provide at-least-once delivery, which means that each message is delivered at least once.', 'Standard queues preserve the order of messages.', 'Amazon SQS can help you build a distributed application with decoupled components.', 'FIFO queues provide exactly-once processing.']}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'The media company that you are working for has a video transcoding application running on Amazon EC2. Each EC2 instance polls a queue to find out which video should be transcoded, and then runs a transcoding process. If this process is interrupted, the video will be transcoded by another instance based on the queuing system. This application has a large backlog of videos which need to be transcoded. Your manager would like to reduce this backlog by adding more EC2 instances however, these instances are only needed until the backlog is reduced. In this scenario, which type of Amazon EC2 instance is best to use?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180640, 'original_assessment_id': 2567052, 'section': 'EC2', 'prompt': {'explanation': '<p>You require an instance that will be used not as a primary server but as a spare compute resource to augment the transcoding process of your application. These instances should also be terminated once the backlog has been significantly reduced. Hence, an Amazon EC2 Spot instance is the best option for this scenario.</p><p>Amazon EC2 Spot instances are <strong>spare</strong> compute capacity in the AWS cloud available to you at steep discounts compared to On-Demand prices. EC2 Spot enables you to optimize your costs on the AWS cloud and scale your application\'s throughput up to 10X for the same budget. By simply selecting Spot when launching EC2 instances, you can save up-to 90% on On-Demand prices. The only difference between On-Demand instances and Spot Instances is that Spot instances can be interrupted by EC2 with two minutes of notification when the EC2 needs the capacity back.&nbsp;</p><p>Options 1 and 3 are incorrect as Reserved and Dedicated instances do not act as spare computer capacity.</p><p>Option 4 is a valid option but a Spot instance is much cheaper than On-Demand.&nbsp;</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/how-spot-instances-work.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/how-spot-instances-work.html</a></p><p>&nbsp;</p><p>&nbsp;</p>', 'answers': ['Reserved instances', 'Spot instances', 'Dedicated instances', 'On-demand instances'], 'question': 'The media company that you are working for has a video transcoding application running on Amazon EC2. Each EC2 instance polls a queue to find out which video should be transcoded, and then runs a transcoding process. If this process is interrupted, the video will be transcoded by another instance based on the queuing system. This application has a large backlog of videos which need to be transcoded. Your manager would like to reduce this backlog by adding more EC2 instances however, these instances are only needed until the backlog is reduced. <br /><br />In this scenario, which type of Amazon EC2 instance is best to use?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You recently quit your job as you are starting a new tech startup company. AWS is your first choice to launch your new Virtual Private Cloud and other cloud services. In the VPC wizard, what are the valid options available when creating a Virtual Private Cloud? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180642, 'original_assessment_id': 2567054, 'section': 'VPC', 'prompt': {'explanation': '<p>The VPC Wizard offers the following configuration:</p><ol><li>VPC with a Single Public Subnet</li><li>VPC with Public and Private Subnets</li><li>VPC with Public and Private Subnets and Hardware VPN Access</li><li>VPC with a Private Subnet Only and Hardware VPN Access</li></ol><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenarios.html">https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenarios.html</a></p><p><a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario3.html#VPC_Scenario3_Implementation">https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario3.html#VPC_Scenario3_Implementation</a></p><p><a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario4.html#VPC_Scenario4_Implementation">https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario4.html#VPC_Scenario4_Implementation</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You recently quit your job as you are starting a new tech startup company. AWS is your first choice to launch your new Virtual Private Cloud and other cloud services. In the VPC wizard, what are the valid options available when creating a Virtual Private Cloud? (Choose 2)</p>', 'answers': ['VPC with a Single Private Subnet', 'VPC with Public and Private Subnets', 'VPC with Public and Private Subnets and Hardware VPN Access', 'VPC with a Dual Private Subnet', 'VPC with Private Subnets and Hardware VPN Access', '<p>VPC with a Public Subnet Only and Hardware VPN Access</p>']}, 'related_lectures': [], 'correct_response': ['b', 'c'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Your manager asked you to look for a hybrid cloud storage solution for your company. You want to recommend AWS Storage Gateway as a cloud storage but first, you need to prepare a list of the use cases for this service to ensure that it is indeed the right service for your organization. What is the main use case of AWS Storage Gateway?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180644, 'original_assessment_id': 2567056, 'section': 'Storage Gateway', 'prompt': {'explanation': '<p>The AWS Storage Gateway service helps customers seamlessly integrate existing on-premises applications, infrastructure, and data with the AWS Cloud. The service uses locally deployed virtual appliances and industry-standard storage protocols to connect existing storage applications and workflows to AWS cloud storage services for minimal process disruption.</p> <p>Local Storage Gateway appliances cache frequently accessed data on-premises to provide low-latency performance while securely and durably storing data in Amazon S3, Amazon EBS, or Amazon Glacier cloud storage.</p> <p>Customers commonly use hybrid cloud storage for use cases such as:</p> <ul> <li><strong>Hybrid cloud workloads.</strong>&nbsp;Cloud-backed file services, big data analytics and data lakes, cloud bursting, or cloud data migration architectures may need local capacity and performance with a connection to a central storage repository in the cloud. Storage Gateway streamlines moving data between your organization and AWS to manage workloads in the cloud.</li> <li><strong>Backup, archive, and disaster recovery.</strong> Storage Gateway is a drop-in replacement for tape and tape automation, and integrates with leading industry backup software packages. Storage Gateway can take snapshots of your local volumes, which can restored as Amazon EBS volumes in the event of a local site disaster.</li> <li><strong>Tiered Storage.</strong>&nbsp;Some customers design storage architectures that preserve or extend high performance on-premises investments by adding a lower cost, on-demand cloud tier. This is ideal for archival or cost-reduction projects.</li> </ul> <p>&nbsp;</p> <p><strong>References:</strong></p> <p><a href="https://aws.amazon.com/storagegateway/">https://aws.amazon.com/storagegateway/</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': 'Your manager asked you to look for a hybrid cloud storage solution for your company. You want to recommend AWS Storage Gateway as a cloud storage but first, you need to prepare a list of the use cases for this service to ensure that it is indeed the right service for your organization. <br><br>What is the main use case of AWS Storage Gateway?', 'answers': ['It helps customers to seamlessly integrate existing on-premises applications, infrastructure, and data with the AWS Cloud.', 'A fast and secure connection to Amazon Glacier.', 'It is a durable storage solution that provides an on-premises storage.', 'It provides a secured data warehouse service in the Cloud.']}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multi-select', 'question_plain': 'An online job site is using NGINX for its application servers hosted in EC2 instances and MongoDB Atlas for its database-tier. MongoDB Atlas is a fully automated third-party cloud service which is not provided by AWS, but supports VPC peering to connect to your VPC.\xa0 Which of the following items are invalid VPC peering configurations? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180646, 'original_assessment_id': 2567058, 'section': 'VPC', 'prompt': {'explanation': '<p>Options 1, 2 and 3 are all invalid VPC Peering configurations, while the other options are the valid ones.</p> <p>A VPC peering connection is a networking connection between two VPCs that enables you to route traffic between them privately. Instances in either VPC can communicate with each other as if they are within the same network. You can create a VPC peering connection between your own VPCs, with a VPC in another AWS account, or with a VPC in a different AWS Region.</p> <p>AWS uses the existing infrastructure of a VPC to create a VPC peering connection; it is neither a gateway nor a VPN connection, and does not rely on a separate piece of physical hardware. There is no single point of failure for communication or a bandwidth bottleneck.</p> <p>&nbsp;</p> <p><strong>References:</strong></p> <p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/PeeringGuide/invalid-peering-configurations.html">http://docs.aws.amazon.com/AmazonVPC/latest/PeeringGuide/invalid-peering-configurations.html</a></p> <p><a href="https://docs.aws.amazon.com/vpc/latest/peering/peering-configurations-partial-access.html">https://docs.aws.amazon.com/vpc/latest/peering/peering-configurations-partial-access.html</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>An online job site is using NGINX for its application servers hosted in EC2 instances and MongoDB Atlas for its database-tier. MongoDB Atlas is a fully automated third-party cloud service which is not provided by AWS, but supports VPC peering to connect to your VPC.\xa0 </p><p>Which of the following items are invalid VPC peering configurations? (Choose 3)</p>', 'answers': ['Overlapping CIDR blocks', 'Transitive Peering', 'Edge to Edge routing via a gateway', 'One to one relationship between two Virtual Private Cloud networks', '<p>One VPC Peered with two VPCs using longest prefix match</p>', '<p>Two VPCs peered to a specific CIDR block in one VPC</p>']}, 'related_lectures': [], 'correct_response': ['a', 'b', 'c'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are a new Solutions Architect in your company. Upon checking the existing Inbound Rules of your Network ACL, you saw this configuration:If a computer with an IP address of 110.238.109.37 sends a request to your VPC, what will happen?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180648, 'original_assessment_id': 2567060, 'section': 'VPC', 'prompt': {'explanation': '<p>Rules are evaluated starting with the lowest numbered rule. As soon as a rule matches traffic, it\'s applied immediately regardless of any higher-numbered rule that may contradict it.</p><p>We have 3 rules here:</p><ul><li>1. Rule 100 permits all traffic from any source.</li><li>2. Rule 101 denies all traffic coming from 110.238.109.37</li><li>3. The Default Rule (*) denies all traffic from any source.</li></ul><br /><p>The Rule 100 will first be evaluated. If there is a match, then it will allow the request. Otherwise, it will then go to Rule 101 to repeat the same process until it goes to the default rule. In this case, when there is a request from 110.238.109.37, it will go through Rule 100 first. As Rule 100 says it will permit all traffic from any source, it will allow this request and will not further evaluate Rule 101 (which denies 110.238.109.37) nor the default rule.</p><br /><p>References:</p><p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_ACLs.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_ACLs.html</a></p>', 'answers': ['Initially, it will be allowed and then after a while, the connection will be denied.', 'Initially, it will be denied and then after a while, the connection will be allowed.', 'It will be allowed.', 'It will be denied.'], 'question': 'You are a new Solutions Architect in your company. Upon checking the existing Inbound Rules of your Network ACL, you saw this configuration:<br /><p><img src="https://udemy-images.s3.amazonaws.com/redactor/raw/2018-02-03_09-36-25-e4a7214623d1499d801d9fe0f021596a.png" width="720" height="246" /></p><br /><br />If a computer with an IP address of 110.238.109.37 sends a request to your VPC, what will happen?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Your company has an e-commerce application that saves the transaction logs to an S3 bucket. You are instructed by the CTO to configure the application to keep the transaction logs for one month for troubleshooting purposes, and then afterwards, purge the logs. What should you do to accomplish this requirement?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180650, 'original_assessment_id': 2567062, 'section': 'S3', 'prompt': {'explanation': '<p>In this scenario, the best way to accomplish the requirement is to simply configure the lifecycle configuration rules on the Amazon S3 bucket to purge the transaction logs after a month.&nbsp;</p><p>Lifecycle configuration enables you to specify the lifecycle management of objects in a bucket. The configuration is a set of one or more rules, where each rule defines an action for Amazon S3 to apply to a group of objects. These actions can be classified as follows:</p><div><ul><li><strong>Transition actions</strong>&nbsp;&ndash; In which you define when objects transition to another&nbsp;storage class. For example, you may choose to transition objects to the STANDARD_IA (IA, for infrequent access) storage class 30 days after creation, or archive objects to the GLACIER storage class one year after creation.</li><li><strong>Expiration actions</strong>&nbsp;&ndash; In which you specify when the objects expire. Then Amazon S3 deletes the expired objects on your behalf.</li></ul></div><p>&nbsp;</p><p>Resources:</p><p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html">https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': 'Your company has an e-commerce application that saves the transaction logs to an S3 bucket. You are instructed by the CTO to configure the application to keep the transaction logs for one month for troubleshooting purposes, and then afterwards, purge the logs. What should you do to accomplish this requirement?', 'answers': ['Add a new bucket policy on the Amazon S3 bucket.', 'Configure the lifecycle configuration rules on the Amazon S3 bucket to purge the transaction logs after a month ', 'Create a new IAM policy for the Amazon S3 bucket that automatically deletes the logs after a month', 'Enable CORS on the Amazon S3 bucket which will enable the automatic monthly deletion of data']}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'In Amazon EC2 security groups, what does the revoke-security-group-ingress command do?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180652, 'original_assessment_id': 2567064, 'section': 'RDS', 'prompt': {'feedbacks': ['', '', '', ''], 'explanation': '<p>The <strong>revoke-security-group-ingress</strong> command removes one or more ingress rules from a security group.</p><p>This example removes TCP port 22 access for the&nbsp;<tt class="docutils literal"><span class="pre">203.0.113.0/24</span></tt>&nbsp;address range from the security group named&nbsp;<tt class="docutils literal"><span class="pre">MySecurityGroup</span></tt>. If the command succeeds, no output is returned.</p><p>Command:</p><div class="highlight-python"><pre>aws ec2 revoke-security-group-ingress --group-name MySecurityGroup --protocol tcp --port 22 --cidr 203.0.113.0/24<br /><br /></pre></div><p>Resources:</p><p><a href="https://aws.amazon.com/rds/details/multi-az/">https://aws.amazon.com/rds/details/multi-az/</a></p><p>&nbsp;</p>', 'relatedLectureIds': '', 'answers': ['Removes one or more security groups from a rule.', 'Removes one or more security groups from an Amazon EC2 instance.', 'Removes one or more ingress rules from a security group.', 'Removes one or more egress rules from a security group.'], 'question': '<p>In Amazon EC2 security groups, what does the <code>revoke-security-group-ingress</code> command do?\xa0 </p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are unable to connect to your Spot EC2 instance via SSH. Which of the following should you check and possibly correct to restore connectivity?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180654, 'original_assessment_id': 2567066, 'section': 'Security', 'prompt': {'explanation': '<p>When connecting to your EC2 instance via SSH, you need to ensure that port 22 is allowed on the security group of your EC2 instance.</p><p>A&nbsp;<em>security group</em>&nbsp;acts as a virtual firewall that controls the traffic for one or more instances. When you launch an instance, you associate one or more security groups with the instance. You add rules to each security group that allow traffic to or from its associated instances. You can modify the rules for a security group at any time; the new rules are automatically applied to all instances that are associated with the security group.&nbsp;&nbsp;</p><p>Option 1 is incorrect as it is unlikely that the issue is caused by a missing OS security patch.</p><p>Option 2 is incorrect because an IAM role is not pertinent to security groups.</p><p>Option 3 is incorrect because this is relevant to RDP and not SSH.</p><p>Option 5 is incorrect as port 443 is for HTTPS and not SSH.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-network-security.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-network-security.html</a></p><p>&nbsp;</p>', 'answers': ['Apply the most recent OS security patches.', 'Configure the IAM role to permit SSH connections to your EC2 instance.', 'Configure the Security Group of the EC2 instance to permit ingress traffic over port 3389 from your IP.', 'Configure the Security Group of the EC2 instance to permit ingress traffic over port 22 from your IP.', 'Configure the Security Group of the EC2 instance to permit ingress traffic over port 443 from your IP.'], 'question': 'You are unable to connect to your Spot EC2 instance via SSH. Which of the following should you check and possibly correct to restore connectivity?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multi-select', 'question_plain': 'In which of the following scenarios can you use both Simple Workflow Service (SWF) and Amazon EC2 as a solution? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180656, 'original_assessment_id': 2567068, 'section': 'SWF', 'prompt': {'explanation': '<p>You can use a combination of EC2 and SWF for the following scenarios:</p> <ul> <li>Managing a multi-step and multi-decision checkout process of an e-commerce mobile app.</li> <li>Orchestrating the execution of distributed business processes</li> </ul> <p>&nbsp;</p> <p>Amazon Simple Workflow Service (SWF) is a web service that makes it easy to coordinate work across distributed application components. Amazon SWF enables applications for a range of use cases, including media processing, web application back-ends, business process workflows, and analytics pipelines, to be designed as a coordination of tasks. Tasks represent invocations of various processing steps in an application which can be performed by executable code, web service calls, human actions, and scripts.&nbsp;</p> <p>Option 1 is incorrect as Elasticache is the best option for distributed session management.</p> <p>Option 4 is incorrect as SQS is the best service to use as a&nbsp;message queue.</p> <p>Option 5 is incorrect as Cloudfront is the best option for applications that require a global content delivery network.</p> <p>&nbsp;&nbsp;</p> <p><strong>References:</strong></p> <p><a href="https://aws.amazon.com/swf/">https://aws.amazon.com/swf/</a></p> <p><a href="https://aws.amazon.com/ec2/">https://aws.amazon.com/ec2/</a>&nbsp;</p>', 'feedbacks': ['', '', '', '', '', ''], 'relatedLectureIds': '', 'question': 'In which of the following scenarios can you use both Simple Workflow Service (SWF) and Amazon EC2 as a solution? (Choose 2)', 'answers': ['For a distributed session management for your mobile application.', 'Managing a multi-step and multi-decision checkout process of an e-commerce mobile app.', 'Orchestrating the execution of distributed business processes.', 'For applications that require a message queue.', 'For web applications that require content delivery networks.', '<p>For applications that need a highly scalable and durable storage.</p>']}, 'related_lectures': [], 'correct_response': ['b', 'c'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are a new Solutions Architect in a large insurance firm. To maintain compliance with HIPPA laws, all data being backed up or stored on Amazon S3 needs to be encrypted at rest. In this scenario, what is the best method of encryption for your data, assuming S3 is being used for storing financial-related data? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180660, 'original_assessment_id': 2567072, 'section': 'S3', 'prompt': {'explanation': '<p>Data protection refers to protecting data while in-transit (as it travels to and from Amazon S3) and at rest (while it is stored on disks in Amazon S3 data centers). You can protect data in transit by using SSL or by using client-side encryption. You have the following options of protecting data at rest in Amazon S3.</p><div><ul type="disc"><li><p><strong>Use Server-Side Encryption</strong>&nbsp;&ndash; You request Amazon S3 to encrypt your object before saving it on disks in its data centers and decrypt it when you download the objects.</p></li><li><p><strong>Use Client-Side Encryption</strong>&nbsp;&ndash; You can encrypt data client-side and upload the encrypted data to Amazon S3. In this case, you manage the encryption process, the encryption keys, and related tools.</p></li></ul></div><p>&nbsp;</p><p>The correct answers are:</p><ul><li>-Enable SSE on an S3 bucket to make use of AES-256 encryption</li><li>-Encrypt the data locally using your own encryption keys, then copy the data to Amazon S3 over HTTPS endpoints. This refers to using a Server-Side Encryption with Customer-Provided Keys (SSE-C).&nbsp;</li></ul><br /><p>Resources:</p><p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html">https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html</a></p><p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingClientSideEncryption.html">https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingClientSideEncryption.html</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are a new Solutions Architect in a large insurance firm. To maintain compliance with HIPPA laws, all data being backed up or stored on Amazon S3 needs to be encrypted at rest. In this scenario, what is the best method of encryption for your data, assuming S3 is being used for storing financial-related data? (Choose 2)</p>', 'answers': ['Enable SSE on an S3 bucket to make use of AES-256 encryption', 'Store the data in encrypted EBS snapshots', 'Encrypt the data locally using your own encryption keys, then copy the data to Amazon S3 over HTTPS endpoints', 'Store the data on EBS volumes with encryption enabled instead of using Amazon S3']}, 'related_lectures': [], 'correct_response': ['a', 'c'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A tech company is currently using Auto Scaling for their web application. A new AMI now needs to be used for launching a fleet of EC2 instances. Which of the following changes needs to be done?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180662, 'original_assessment_id': 2567074, 'section': 'Auto Scaling', 'prompt': {'explanation': '<p>For this scenario, you have to create a new launch configuration. Remember that&nbsp;you can\'t modify a launch configuration after you\'ve created it.</p><p>A&nbsp;<em>launch configuration</em>&nbsp;is a template that an Auto Scaling group uses to launch EC2 instances. When you create a launch configuration, you specify information for the instances such as the ID of the Amazon Machine Image (AMI), the instance type, a key pair, one or more security groups, and a block device mapping. If you\'ve launched an EC2 instance before, you specified the same information in order to launch the instance.</p><p>You can specify your launch configuration with multiple Auto Scaling groups. However, you can only specify one launch configuration for an Auto Scaling group at a time, and you can\'t modify a launch configuration after you\'ve created it. Therefore, if you want to change the launch configuration for an Auto Scaling group, you must create a launch configuration and then update your Auto Scaling group with the new launch configuration.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="http://docs.aws.amazon.com/autoscaling/latest/userguide/LaunchConfiguration.html">http://docs.aws.amazon.com/autoscaling/latest/userguide/LaunchConfiguration.html</a></p>', 'answers': ['Do nothing. You can start directly launching EC2 instances in the Auto Scaling group with the same launch configuration.', 'Create a new launch configuration.', 'Create a new target group.', 'Create a new target group and launch configuration.'], 'question': 'A tech company is currently using Auto Scaling for their web application. A new AMI now needs to be used for launching a fleet of EC2 instances. <br /><br />Which of the following changes needs to be done?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are working as a Cloud Engineer for a top aerospace engineering firm. One of your tasks is to set up a document storage system using S3 for all of the engineering files. In Amazon S3, which of the following statements are true? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180674, 'original_assessment_id': 2567086, 'section': 'S3', 'prompt': {'explanation': '<p>The correct answers are:&nbsp;</p> <ul> <li>Amazon S3 is a simple key-based object store.</li> <li>The total volume of data and number of objects you can store are unlimited.</li> <li>The largest object that can be uploaded in a single PUT is 5 GB.</li> </ul> <p>&nbsp;</p> <p>Option 2 is incorrect as the largest object that can be uploaded in a single PUT is 5 GB and not 5 TB. Remember that the upload limit depends on whether you upload an object using a single PUT operation or via Multipart Upload. The largest object that can be uploaded in a single PUT is 5 GB. Please take note the phrase "... in a single PUT". If you are using the multipart upload API, then the limit is 5 TB.</p> <p>Option 4 is incorrect as you can store virtually any kind of data in any format in S3.</p> <p>Option 6 is incorrect because although S3 is indeed an object storage service, it does not provide file system access semantics. EFS provides this feature but not S3.</p> <p>&nbsp;</p> <p><strong>References:</strong></p> <p><a href="https://aws.amazon.com/s3/faqs/">https://aws.amazon.com/s3/faqs/</a></p> <p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/UploadingObjects.html">https://docs.aws.amazon.com/AmazonS3/latest/dev/UploadingObjects.html</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are working as a Cloud Engineer for a top aerospace engineering firm. One of your tasks is to set up a document storage system using S3 for all of the engineering files. In Amazon S3, which of the following statements are true? (Choose 3)</p>', 'answers': ['The total volume of data and number of objects you can store are unlimited.', 'The largest object that can be uploaded in a single PUT is 5 TB.', 'Amazon S3 is a simple key-based object store.', 'You can only store ZIP or TAR files in S3.', '<p>The largest object that can be uploaded in a single PUT is 5 GB.</p>', '<p>S3 is an object storage service that provides file system access semantics (such as strong consistency and file locking), and concurrently-accessible storage.</p>']}, 'related_lectures': [], 'correct_response': ['a', 'c', 'e'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': "You are setting up the cloud architecture for an international money transfer service to be deployed in AWS which will have thousands of users around the globe. The service should be available 24/7 to avoid any business disruption and should be resilient enough to handle the outage of an entire AWS region. To meet this requirement, you have deployed your AWS resources to multiple AWS Regions. You need to use Route 53 and configure it to set all of your resources to be available all the time as much as possible. When a resource becomes unavailable, your Route 53 should detect that it's unhealthy and stop including it when responding to queries.\xa0 \xa0Which of the following is the most fault tolerant routing configuration that you should use in this scenario?", '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180664, 'original_assessment_id': 2567076, 'section': 'Route 53', 'prompt': {'explanation': '<p>You can use Route 53 health checking to configure active-active and active-passive failover configurations. You configure active-active failover using any routing policy (or combination of routing policies) other than failover, and you configure active-passive failover using the failover routing policy.</p> <p><strong>Active-Active Failover </strong></p> <p>Use this failover configuration when you want all of your resources to be available the majority of the time. When a resource becomes unavailable, Route 53 can detect that it\'s unhealthy and stop including it when responding to queries.</p> <p>In active-active failover, all the records that have the same name, the same type (such as A or AAAA), and the same routing policy (such as weighted or latency) are active unless Route 53 considers them unhealthy. Route 53 can respond to a DNS query using any healthy record.</p> <p><strong>Active-Passive Failover </strong></p> <p>Use an active-passive failover configuration when you want a primary resource or group of resources to be available the majority of the time and you want a secondary resource or group of resources to be on standby in case all the primary resources become unavailable. When responding to queries, Route 53 includes only the healthy primary resources. If all the primary resources are unhealthy, Route 53 begins to include only the healthy secondary resources in response to DNS queries.</p> <p>Options 2 and 4 are incorrect because an Active-Passive Failover is mainly used when you want a primary resource or group of resources to be available most of the time and you want a secondary resource or group of resources to be on standby in case all the primary resources become unavailable. In this scenario, all of your resources should be available all the time as much as possible which is why you have to use an Active-Active Failover instead.</p> <p>Option 3 is incorrect because you cannot set up an Active-Active Failover with One Primary and One Secondary Resource. Remember that an Active-Active Failover uses all available resources all the time without a primary nor a secondary resource.</p> <p><strong>References: </strong></p> <p><a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-types.html ">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-types.html </a></p> <p><a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html ">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html </a></p> <p><a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-configuring.html">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-configuring.html</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': "<p>You are setting up the cloud architecture for an international money transfer service to be deployed in AWS which will have thousands of users around the globe. The service should be available 24/7 to avoid any business disruption and should be resilient enough to handle the outage of an entire AWS region. To meet this requirement, you have deployed your AWS resources to multiple AWS Regions. You need to use Route 53 and configure it to set all of your resources to be available all the time as much as possible. When a resource becomes unavailable, your Route 53 should detect that it's unhealthy and stop including it when responding to queries.\xa0 \xa0</p><p>Which of the following is the most fault tolerant routing configuration that you should use in this scenario?\xa0 </p>", 'answers': ['<p>Configure an Active-Active Failover with Weighted routing policy.\xa0 </p>', '<p>Configure an Active-Passive Failover with Weighted Records.\xa0 </p>', '<p>Configure an Active-Active Failover with One Primary and One Secondary Resource.\xa0 </p>', '<p>Configure an Active-Passive Failover with Multiple Primary and Secondary Resources.\xa0 </p>']}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are working as a Solutions Architect for a global game development company in which you setup a new VPC for them. They have\xa0a web application currently running on twenty EC2 instances as part of an Auto Scaling group. All twenty instances have been running at a maximum of 100% CPU Utilization for the past 40 minutes however, the Auto Scaling group has not added any additional EC2 instances to the group. What could be the root cause of this issue? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180666, 'original_assessment_id': 2567078, 'section': 'EC2', 'prompt': {'explanation': '<p>The correct answers are:</p> <ul> <li>-You already have 20 on-demand instances running in your entire VPC.</li> <li>-The maximum size of your Auto Scaling group is set to twenty.</li> </ul><br /> <p>You are limited to running up to a total of 20 On-Demand instances across the instance family, purchasing 20 Reserved Instances, and requesting Spot Instances per your dynamic Spot limit per region.</p> <p>If the maximum size of your Auto Scaling group has already been reached, then it would not create any new EC2 instance.</p> <p>&nbsp;</p> <p>References:</p> <p><a href="https://aws.amazon.com/ec2/faqs/">https://aws.amazon.com/ec2/faqs/</a></p> <p><a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-target-tracking.html">https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-target-tracking.html</a></p> <p>&nbsp;</p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are working as a Solutions Architect for a global game development company in which you setup a new VPC for them. They have\xa0a web application currently running on twenty EC2 instances as part of an Auto Scaling group. All twenty instances have been running at a maximum of 100% CPU Utilization for the past 40 minutes however, the Auto Scaling group has not added any additional EC2 instances to the group. <br><br>What could be the root cause of this issue? (Choose 2)</p>', 'answers': ['You already have 20 on-demand instances running in your entire VPC.', 'The maximum size of your Auto Scaling group is set to twenty.', '<p>Your Auto Scaling group is not properly configured\xa0to scale up when the CPU Utilization goes 100%</p>', 'The scale up policy of your Auto Scaling group is not reached yet.', '<p>You can only\xa0have 20 on-demand instances running in your entire VPC at any given point in time.</p>']}, 'related_lectures': [], 'correct_response': ['a', 'b'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A new online banking platform has been re-designed to have a microservices architecture in which complex applications are decomposed into smaller, independent services. The new platform is using Docker considering that application containers are optimal for running small, decoupled services. \n\nWhich service can you use to migrate this new platform to AWS?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180668, 'original_assessment_id': 2567080, 'section': 'ECS', 'prompt': {'explanation': '<p>Amazon Elastic Container Service (Amazon ECS) is a highly scalable, fast, container management service that makes it easy to run, stop, and manage Docker containers on a cluster. You can host your cluster on a serverless infrastructure that is managed by Amazon ECS by launching your services or tasks using the Fargate launch type. For more control, you can host your tasks on a cluster of Amazon Elastic Compute Cloud (Amazon EC2) instances that you manage by using the EC2 launch type.</p> <p>&nbsp;</p> <p><strong>Reference:</strong></p> <p><a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html">https://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>A new online banking platform has been re-designed to have a microservices architecture in which complex applications are decomposed into smaller, independent services. The new platform is using Docker considering that application containers are optimal for running small, decoupled services. </p>\n\n<p>Which service can you use to migrate this new platform to AWS?</p>', 'answers': ['<p>EKS</p>', '<p>EFS</p>', '<p>ECS</p>', '<p>EBS</p>']}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a large telecommunications company where you need to run analytics against all combined log files from your Application Load Balancer as part of the regulatory requirements. Which AWS services can be used together to collect logs and then easily perform log analysis?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180670, 'original_assessment_id': 2567082, 'section': 'ELB', 'prompt': {'explanation': '<p>In this scenario, it is best to use a combination of Amazon S3 and Amazon EMR:&nbsp;Amazon S3 for storing ELB log files and Amazon EMR for analyzing the log files. Access logging in the ELB is stored in Amazon S3 which means that options 3 and 4 are both valid answers. However, log analysis can be automatically provided by Amazon EMR, which is more economical than building a custom-built log analysis application and hosting it in EC2. Hence, option 4 is the best answer between the two.&nbsp;&nbsp;</p><p>Access logging is an optional feature of Elastic Load Balancing that is disabled by default. After you enable access logging for your load balancer, Elastic Load Balancing captures the logs and stores them in the Amazon S3 bucket that you specify as compressed files. You can disable access logging at any time.</p><p>Amazon EMR provides a managed Hadoop framework that makes it easy, fast, and cost-effective to process vast amounts of data across dynamically scalable Amazon EC2 instances. It securely and reliably handles a broad set of big data use cases, including log analysis, web indexing, data transformations (ETL), machine learning, financial analysis, scientific simulation, and bioinformatics. You can also run other popular distributed frameworks such as Apache Spark, HBase, Presto, and Flink in Amazon EMR, and interact with data in other AWS data stores such as Amazon S3 and Amazon DynamoDB.&nbsp;</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/emr/">https://aws.amazon.com/emr/</a></p><p><a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-access-logs.html">https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-access-logs.html</a>&nbsp;</p>', 'answers': ['Amazon DynamoDB for storing and EC2 for analyzing the logs.', 'Amazon EC2 with EBS volumes for storing and analyzing the log files.', 'Amazon S3 for storing the ELB log files and an EC2 instance for analyzing the log files using a custom-built application.', 'Amazon S3 for storing ELB log files and Amazon EMR for analyzing the log files.'], 'question': 'You are working for a large telecommunications company where you need to run analytics against all combined log files from your Application Load Balancer as part of the regulatory requirements. <br /><br />Which AWS services can be used together to collect logs and then easily perform log analysis?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multi-select', 'question_plain': 'By default, what happens to your data when an EC2 instance created terminates? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180672, 'original_assessment_id': 2567084, 'section': 'EBS', 'prompt': {'explanation': '<p>By default, EBS volumes that are created and attached to an instance at launch are deleted when that instance is terminated. You can modify this behavior by changing the value of the flag&nbsp;<code>DeleteOnTermination</code>&nbsp;to&nbsp;<code>false</code>&nbsp;when you launch the instance. This modified value causes the volume to persist even after the instance is terminated, and enables you to attach the volume to another instance.</p><p>Options 2, 3, and 4 are correct. The root device volume is deleted by default. For EBS-backed instances, the volume is deleted as well. For Instance Store-Backed AMI, all the ephemeral (temporary) data are also deleted.</p><p>Option 1&nbsp;is incorrect. When the instance is terminated,&nbsp;the volume of an EBS-backed instance is deleted by default unless the&nbsp;<code>DeleteOnTermination</code>&nbsp;flag is set to&nbsp;<code>false</code>.</p><p>References:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumes.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumes.html</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': 'By default, what happens to your data when an EC2 instance created terminates? (Choose 3)', 'answers': ['<p>For EBS-backed instances, the root volume is persisted by default.</p>', 'The root device volume is deleted by default.', '<p>For EBS-backed instances, the root volume is deleted by default.</p>', '<p>For Instance Store-Backed AMI, all the data\xa0is deleted on all volumes.</p>']}, 'related_lectures': [], 'correct_response': ['b', 'c', 'd'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Your company is in a hurry of deploying their new web application written in NodeJS to AWS. As the Solutions Architect of the company, you were assigned to do the deployment without worrying about the underlying infrastructure that runs the application. Which service will you use to easily deploy and manage your new web application in AWS?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180676, 'original_assessment_id': 2567088, 'section': 'Elastic Beanstalk', 'prompt': {'explanation': '<p>With Elastic Beanstalk, you can quickly deploy and manage applications in the AWS Cloud without worrying about the infrastructure that runs those applications. AWS Elastic Beanstalk reduces management complexity without restricting choice or control. You simply upload your application, and Elastic Beanstalk automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring.</p> <p>Option 2 is incorrect because AWS CloudFront is a fast content delivery network (CDN) service that securely delivers data, videos, applications, and APIs to customers globally with low latency and high transfer speeds. It does not provide any deployment capability for your custom applications unlike Elastic Beanstalk.</p> <p>Option 3 is incorrect because although the CloudFormation service provides deployment capabilities, you will still have to design a custom template that contains the required AWS resources for your application needs. Hence, this will require more time to complete instead of just directly using Elastic Beanstalk.</p> <p>Option 4 is incorrect because although you can upload your NodeJS code in AWS CloudCommit, this service is just a fully-managed source control service that hosts secure Git-based repositiories and hence, it does not provide a way to deploy or manage your applications in AWS.</p> <p><strong>Reference:&nbsp;</strong></p> <p><a href="https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/Welcome.html">https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/Welcome.html</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>Your company is in a hurry of deploying their new web application written in NodeJS to AWS. As the Solutions Architect of the company, you were assigned to do the deployment without worrying about the underlying infrastructure that runs the application. Which service will you use to easily deploy and manage your new web application in AWS?\xa0 </p>', 'answers': ['AWS Elastic Beanstalk', '<p>AWS CloudFront\xa0 </p>', 'AWS Cloudformation', '<p>AWS CodeCommit\xa0 </p>']}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Your web application is relying entirely on slower disk-based databases, causing it to perform slowly. To improve its performance, you integrated an in-memory data store to your web application using ElastiCache. How does Amazon ElastiCache improve database performance?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180678, 'original_assessment_id': 2567090, 'section': 'ElastiCache', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>ElastiCache improves the performance of your database through caching query results.</p> <p>The primary purpose of an in-memory key-value store is to provide ultra-fast (submillisecond latency) and inexpensive access to copies of data. Most data stores have areas of data that are frequently accessed but seldom updated.&nbsp; Additionally, querying a database is always slower and more expensive than locating a key in a key-value pair cache. Some database queries are especially expensive to perform, for example, queries that involve joins across multiple tables or queries with intensive calculations.</p> <p>By caching such query results, you pay the price of the query once and then are able to quickly retrieve the data multiple times without having to re-execute the query.</p> <p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/images/ElastiCache-Caching.png" width="750" height="368" /></p> <p>&nbsp;</p> <p>Option 1 is incorrect because this option describes what CloudFront does and not ElastiCache.</p> <p>Option 2 is incorrect because&nbsp;this option describes what Amazon DynamoDB Accelerator (DAX) does and not ElastiCache.&nbsp;Amazon DynamoDB Accelerator (DAX) is a fully managed, highly available, in-memory cache for DynamoDB.</p> <p>Option 4 is incorrect because&nbsp;this option describes what an RDS Read Replica does and not ElastiCache.&nbsp;Amazon RDS Read Replicas enable you to create one or more read-only copies of your database instance within the same AWS Region or in a different AWS Region.</p> <p><strong>References:</strong></p> <p><a href="https://aws.amazon.com/elasticache/ ">https://aws.amazon.com/elasticache/</a></p> <p><a href="https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/elasticache-use-cases.html">https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/elasticache-use-cases.html</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p>It securely delivers data to customers globally with low latency and high transfer speeds.</p>', '<p>It provides an in-memory cache that delivers up to 10x performance improvement from milliseconds to microseconds or even at millions of requests per second.</p>', '<p>By caching SQL query results.</p>', '<p>It reduces the load on your database by routing read queries from your applications to the Read Replica.</p>'], 'question': '<p>Your web application is relying entirely on slower disk-based databases, causing it to perform slowly. To improve its performance, you integrated an in-memory data store to your web application using ElastiCache. How does Amazon ElastiCache improve database performance?</p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:26:57Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'In your VPC, you have a Classic Load Balancer distributing traffic to six EC2 instances that are evenly spread across two Availability Zones. However, you realize that only half of your EC2 instances are actually receiving traffic. What could be the most likely cause of this problem?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180680, 'original_assessment_id': 2567092, 'section': 'ELB', 'prompt': {'explanation': '<p>The reason why&nbsp;only half of your EC2 instances are actually receiving traffic is because the Cross-Zone Load Balancing option is disabled.</p><p>Cross-zone load balancing reduces the need to maintain equivalent numbers of instances in each enabled Availability Zone, and improves your application\'s ability to handle the loss of one or more instances.&nbsp;</p><p>When you create a Classic Load Balancer, the default for cross-zone load balancing depends on how you create the load balancer. With the API or CLI, cross-zone load balancing is disabled by default. With the AWS Management Console, the option to enable cross-zone load balancing is selected by default. After you create a Classic Load Balancer, you can enable or disable cross-zone load balancing at any time.</p><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/enable-disable-crosszone-lb.html">http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/enable-disable-crosszone-lb.html</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': 'In your VPC, you have a Classic Load Balancer distributing traffic to six EC2 instances that are evenly spread across two Availability Zones. However, you realize that only half of your EC2 instances are actually receiving traffic. <br><br>What could be the most likely cause of this problem? ', 'answers': ['The Classic Load Balancer listener is not set to port 80.', 'The security group of the EC2 instances does not allow HTTP traffic.', 'Cross-Zone Load Balancing is disabled.', 'The Classic Load Balancer listener is not set to port 22.']}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are trying to convince a team to use Amazon RDS Read Replica for your multi-tier web application. What are two benefits of using read replicas? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180682, 'original_assessment_id': 2567094, 'section': 'RDS', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>Amazon RDS Read Replicas provide enhanced performance and durability for database (DB) instances. This feature makes it easy to elastically scale out beyond the capacity constraints of a single DB instance for read-heavy database workloads.</p> <p>You can create one or more replicas of a given source DB Instance and serve high-volume application read traffic from multiple copies of your data, thereby increasing aggregate read throughput. Read replicas can also be promoted when needed to become standalone DB instances. Read replicas are available in Amazon RDS for MySQL, MariaDB, and PostgreSQL as well as Amazon Aurora.</p> <p>Option 2 is incorrect as the Read Replica only offers read operations.</p> <p>Option 4 is incorrect as this is a benefit of Multi-AZ and not of a Read Replica.</p> <p>Option 5 is incorrect because Read Replicas does not do anything to upgrade or increase the read throughput on the primary DB instance per se, but it provides a way for your application to fetch data from replicas. In this way, it improves the overall performance of your entire database-tier (and not just the primary DB instance).</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/rds/details/read-replicas/">https://aws.amazon.com/rds/details/read-replicas/</a></p>', 'feedbacks': ['', '', '', '', ''], 'answers': ['It provides elasticity to your Amazon RDS database.', 'Allows both read and write operations on the read replica to complement the primary database.', 'Improves performance of the primary database by taking workload from it.', 'Automatic failover in the case of Availability Zone service failures.', 'It enhances the read performance of your primary database.'], 'question': 'You are trying to convince a team to use Amazon RDS Read Replica for your multi-tier web application. What are two benefits of using read replicas? (Choose 2)'}, 'related_lectures': [], 'correct_response': ['a', 'c'], 'updated': '2018-11-21T07:28:01Z'}, {'assessment_type': 'multi-select', 'question_plain': 'Which of the following statements are true regarding Amazon VPC subnets? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180684, 'original_assessment_id': 2567096, 'section': 'VPC', 'prompt': {'explanation': '<p>Options B, D, and F are the right answers:</p><ul><li>-Each subnet maps to a single Availability Zone.&nbsp;</li><li>-Every subnet that you create is automatically associated with the main route table for the VPC.</li><li>-If a subnet\'s traffic is routed to an Internet gateway, the subnet is known as a public subnet.&nbsp;</li></ul><br /><p>Option 1 is incorrect because&nbsp;EC2 instances in a private subnet can communicate with the Internet not just by having an Elastic IP, but also with a public IP address.</p><p>Option 3 is incorrect because the&nbsp;allowed block size in VPC is between a /16 netmask (65,536 IP addresses) and /28 netmask (16 IP addresses) and not&nbsp;/27 netmask. For you to easily remember this,&nbsp;/27 netmask is equivalent to exactly 27 IP addresses but keep in mind that the limit is until /28 netmask.</p><p>Option 5 is incorrect because each subnet must reside entirely within one Availability Zone and cannot span zones.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html">https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html</a>&nbsp;</p>', 'answers': ['EC2 instances in a private subnet can communicate with the Internet only if they have an Elastic IP.', 'Each subnet maps to a single Availability Zone.', 'The allowed block size in VPC is between a /16 netmask (65,536 IP addresses) and /27 netmask (16 IP addresses).', 'Every subnet that you create is automatically associated with the main route table for the VPC. ', 'Each subnet spans to 2 Availability Zones.', "If a subnet's traffic is routed to an Internet gateway, the subnet is known as a public subnet."], 'question': 'Which of the following statements are true regarding Amazon VPC subnets? (Choose 3)'}, 'related_lectures': [], 'correct_response': ['b', 'd', 'f'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as a solutions architect for a tech company where you are instructed to build a web architecture using On-Demand EC2 instances and a database in AWS. However, due to budget constraints, the company instructed you to choose a database service in which they no longer need to worry about database management tasks such as hardware or software provisioning, setup, configuration, scaling and backups.Which database service in AWS is best to use in this scenario?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180686, 'original_assessment_id': 2567098, 'section': 'DynamoDB', 'prompt': {'explanation': '<p>Basically, a database service in which you no longer need to worry about database management tasks such as hardware or software provisioning, setup and configuration is called a&nbsp;fully managed database. This means that AWS<em> fully manages</em> all of the database management tasks and the underlying host server.&nbsp;The main differentiator here is the keyword "<strong>scaling</strong>" in the question. In RDS, you still have to manually scale up your resources and create Read Replicas&nbsp;to improve scalability while in DynamoDB, this is automatically done.&nbsp;</p> <p>DynamoDB is the best option to use in this scenario. It is a fully managed non-relational database service &ndash; you simply create a database table, set your target utilization for Auto Scaling, and let the service handle the rest. You no longer need to worry about database management tasks such as hardware or software provisioning, setup and configuration, software patching, operating a reliable, distributed database cluster, or partitioning data over multiple instances as you scale. DynamoDB also lets you backup and restore all your tables for data archival, helping you meet your corporate and governmental regulatory requirements.</p> <p>Option 1 is incorrect because&nbsp;AWS RDS is just a managed service and not fully managed. This means that you still have to handle the software patching, backups and many other administrative tasks.</p> <p>Option 3 is incorrect because although ElastiCache is fully managed, is not a database service but more of a&nbsp;In-Memory Data Store.</p> <p>Option 4 is incorrect because although Redshift is fully managed, it is not a database service but a&nbsp;Data Warehouse.</p> <p>Option 5 is incorrect because this service is totally managed by you. If you have a&nbsp;MySQL database running on an EBS-backed EC2 instance, AWS does not manage any administrative database task.</p> <p>&nbsp;</p> <p>References:&nbsp;</p> <p><a href="https://aws.amazon.com/dynamodb/">https://aws.amazon.com/dynamodb/</a></p> <p><a href="https://aws.amazon.com/products/databases/">https://aws.amazon.com/products/databases/</a></p>', 'feedbacks': ['', '', '', '', ''], 'relatedLectureIds': '', 'question': 'You are working as a solutions architect for a tech company where you are instructed to build a web architecture using On-Demand EC2 instances and a database in AWS. However, due to budget constraints, the company instructed you to choose a database service in which they no longer need to worry about database management tasks such as hardware or software provisioning, setup, configuration, scaling and backups.<br><br>Which database service in AWS is best to use in this scenario?', 'answers': ['AWS RDS', 'DynamoDB', 'Amazon ElastiCache', 'Redshift', 'A MySQL database running on an EBS-backed EC2 instance']}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are a Solutions Architect for a major TV network. They have a web application running on eight Amazon EC2 instances, consuming about 55% of resources on each instance. You are using Auto Scaling to make sure that eight instances are running at all times. The number of requests that this application processes are consistent and do not experience spikes. Your manager instructed you to ensure high availability of this web application at all times to avoid any loss of revenue. You want the load to be distributed evenly between all instances. You also want to use the same Amazon Machine Image (AMI) for all EC2 instances. How will you be able to achieve this?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180688, 'original_assessment_id': 2567100, 'section': 'ELB', 'prompt': {'explanation': '<p>The best option to take is to deploy four EC2 instances in one Availability Zone and four in another availability zone in the same region behind an Amazon Elastic Load Balancer. In this way, if one availability zone goes down, there is still another available zone that can accomodate traffic.</p><p>Option 1 is incorrect because this architecture is not highly available. If that Availability Zone goes down, then your web application will be unreachable.</p><p>Options 2 and 4 are incorrect because the ELB is designed to only run in one region and not across multiple regions.&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/elasticloadbalancing/">https://aws.amazon.com/elasticloadbalancing/</a></p>', 'answers': ['Deploy eight EC2 instances in one Availability Zone behind an Amazon Elastic Load Balancer.', 'Deploy four EC2 instances in one region and four in another region behind an Amazon Elastic Load Balancer.', 'Deploy four EC2 instances in one Availability Zone and four in another availability zone in the same region behind an Amazon Elastic Load Balancer.', 'Deploy two EC2 instances in four regions behind an Amazon Elastic Load Balancer.'], 'question': 'You are a Solutions Architect for a major TV network. They have a web application running on eight Amazon EC2 instances, consuming about 55% of resources on each instance. You are using Auto Scaling to make sure that eight instances are running at all times. The number of requests that this application processes are consistent and do not experience spikes. Your manager instructed you to ensure high availability of this web application at all times to avoid any loss of revenue. You want the load to be distributed evenly between all instances. You also want to use the same Amazon Machine Image (AMI) for all EC2 instances. <br /><br />How will you be able to achieve this?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': "Your IT Manager instructed you to set up a bastion host n the cheapest, most secure way, and that you should be the only person that can access it via SSH. Which of the following steps would satisfy your IT Manager's request?", '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180690, 'original_assessment_id': 2567102, 'section': 'EC2', 'prompt': {'explanation': '<p>A&nbsp;<em>bastion host is</em>&nbsp;a server whose purpose is to provide access to a private network from an external network, such as the Internet. Because of its exposure to potential attack, a&nbsp;<em>bastion host</em>&nbsp;must minimize the chances of penetration.</p><p>To create a bastion host, you can create a new EC2 instance which should only have a security group from a particular IP address for maximum security. Since the cost is also considered in the question, you should choose a small instance for your host. By default,&nbsp;t2.micro instance is used by AWS but you can change these settings during deployment.</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/quickstart/latest/linux-bastion/architecture.html">https://docs.aws.amazon.com/quickstart/latest/linux-bastion/architecture.html</a></p><p><a href="https://aws.amazon.com/blogs/security/how-to-record-ssh-sessions-established-through-a-bastion-host/">https://aws.amazon.com/blogs/security/how-to-record-ssh-sessions-established-through-a-bastion-host/</a></p><p>&nbsp;</p>', 'answers': ['Setup a small EC2 instance and a security group which only allows access on port 22 via your IP address', 'Setup a large EC2 instance and a security group which only allows access on port 22 via your IP address', 'Setup a large EC2 instance and a security group which only allows access on port 22', 'Setup a small EC2 instance and a security group which only allows access on port 22'], 'question': "Your IT Manager instructed you to set up a bastion host n the cheapest, most secure way, and that you should be the only person that can access it via SSH. <br /><br />Which of the following steps would satisfy your IT Manager's request?"}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multi-select', 'question_plain': 'In Amazon EC2, you can manage your instances from the moment you launch them up to their termination. You can flexibly control your computing costs by changing the EC2 instance state. Select the following states in the EC2 Instance Lifecycle in which you are not billed. (Choose 4)', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180692, 'original_assessment_id': 2567104, 'section': 'EC2', 'prompt': {'explanation': '<p>By working with Amazon EC2 to manage your instances from the moment you launch them through their termination, you ensure that your customers have the best possible experience with the applications or sites that you host on your instances.</p> <p>Below are the valid EC2 lifecycle instance states. Take note that you are only billed if your EC2 instance is on&nbsp;<strong><code>running</code></strong>&nbsp;state. In addition, there is no "starting-up" state, which is why Options 3 and 4 are incorrect.</p> <p style="padding-left: 30px;"><strong><code>pending</code></strong>&nbsp;-&nbsp;The instance is preparing to enter the running state. An instance enters the pending state when it launches for the first time, or when it is restarted after being in the stopped state.</p> <p style="padding-left: 30px;"><strong><code>running</code></strong> - The instance is running and ready for use.</p> <p style="padding-left: 30px;"><strong><code>stopping</code></strong> - The instance is preparing to be stopped.<br /><br /><strong><code>stopped</code></strong> - The instance is shut down and cannot be used. The instance can be restarted at any time.</p> <p style="padding-left: 30px;"><strong><code>shutting-down</code></strong>&nbsp;- The instance is preparing to be terminated.</p> <p style="padding-left: 30px;"><strong><code>terminated</code></strong>&nbsp;- The instance has been permanently deleted and cannot be restarted.<br />&nbsp;</p> <p><strong>Reference:</strong></p> <p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>In Amazon EC2, you can manage your instances from the moment you launch them up to their termination. You can flexibly control your computing costs by changing the EC2 instance state. Select the following states in the EC2 Instance Lifecycle in which you are not billed. (Choose 4)</p>', 'answers': ['<p><code>pending</code> </p>', '<p><code>stopping</code> </p>', '<p><code>running</code> </p>', '<p><code>starting-up</code> </p>', '<p><code>shutting-down</code> </p>', '<p><code>stopped</code> </p>']}, 'related_lectures': [], 'correct_response': ['a', 'b', 'e', 'f'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are a new Solutions Architect in your department and you have created 7 CloudFormation templates. Each template has been defined for a specific purpose. What determines the cost of using these new CloudFormation templates?', '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180694, 'original_assessment_id': 2567106, 'section': 'Cloudformation', 'prompt': {'explanation': '<p>There is no additional charge for AWS CloudFormation. You pay for AWS resources (such as Amazon EC2 instances, Elastic Load Balancing load balancers, etc.) created using AWS CloudFormation in the same manner as if you created them manually. You only pay for what you use, as you use it; there are no minimum fees and no required upfront commitments.&nbsp;</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/cloudformation/pricing/ ">https://aws.amazon.com/cloudformation/pricing/ </a></p><p>&nbsp;</p>', 'answers': ['$2.50 per template per month', 'The length of time it takes to build the architecture with CloudFormation', 'It depends on the region where you will deploy.', 'CloudFormation templates are free but you are charged for the underlying resources it builds.'], 'question': 'You are a new Solutions Architect in your department and you have created 7 CloudFormation templates. Each template has been defined for a specific purpose. <br /><br />What determines the cost of using these new CloudFormation templates?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:26:54Z'}, {'assessment_type': 'multiple-choice', 'question_plain': "You are working for a large financial firm and you are instructed to set up a Linux bastion host. It will allow access to the Amazon EC2 instances running in their VPC. For security purposes, only the clients connecting from the corporate external public IP address 175.45.116.100 should have SSH access to the host. Which is the best option that can meet the customer's requirement?", '_class': 'assessment', 'created': '2018-11-21T07:26:54Z', 'id': 6180696, 'original_assessment_id': 2567108, 'section': 'EC2', 'prompt': {'explanation': '<p>The SSH protocol uses TCP and port 22. Hence, Options 2 and 3 are incorrect.</p><p>A bastion host is a special purpose computer on a network specifically designed and configured to withstand attacks. The computer generally hosts a single application, for example a proxy server, and all other services are removed or limited to reduce the threat to the computer.&nbsp;</p><p>When setting up a bastion host in AWS, you should only allow&nbsp;the individual IP of the client and not the entire network. Therefore, in the&nbsp;<strong>Source,&nbsp;</strong>&nbsp;the proper CIDR notation should be used. The <strong>/32</strong> denotes one IP address and the <strong>/0</strong> refers to the entire network. That is why Option 4 is incorrect as it allowed the entire network instead of a single IP.&nbsp;</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html</a></p>', 'answers': ['Security Group Inbound Rule: Protocol – TCP. Port Range – 22, Source 175.45.116.100/32', 'Security Group Inbound Rule: Protocol – UDP, Port Range – 22, Source 175.45.116.100/32', 'Network ACL Inbound Rule: Protocol – UDP, Port Range – 22, Source 175.45.116.100/32', 'Network ACL Inbound Rule: Protocol – TCP, Port Range-22, Source 175.45.116.100/0'], 'question': "You are working for a large financial firm and you are instructed to set up a Linux bastion host. It will allow access to the Amazon EC2 instances running in their VPC. For security purposes, only the clients connecting from the corporate external public IP address 175.45.116.100 should have SSH access to the host. <br /><br />Which is the best option that can meet the customer's requirement?"}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:26:54Z'}], 'previous': None, 'next': None}, 'title': 'AWS Certified Solutions Architect Associate Practice Test 3'}, {'type': 'practice-test', 'quiz_data': {'count': 65, 'results': [{'assessment_type': 'multiple-choice', 'question_plain': 'A data analytics company has been building its new generation big data and analytics platform on their AWS cloud infrastructure. They need a storage service that provides the scale and performance that their big data applications require such as high throughput to compute nodes coupled with read-after-write consistency and low-latency file operations. In addition, their data needs to be stored redundantly across multiple AZs and allows concurrent connections from multiple EC2 instances hosted on multiple AZs.   Which of the following AWS storage service will you use to meet this requirement?', '_class': 'assessment', 'created': '2018-11-21T07:29:07Z', 'id': 6180716, 'original_assessment_id': 2567118, 'section': '', 'prompt': {'explanation': '<p>In this question, you should take note of the two keywords/phrases: "file operation" and "allows concurrent connections from multiple EC2 instances". There are various AWS storage options that you can choose but whenever these criteria shows up, always consider using EFS instead of using EBS Volumes which is mainly used as a "block" storage and can only have one connection to one EC2 instance at a time.</p> <p>Amazon EFS is a fully-managed service that makes it easy to set up and scale file storage in the Amazon Cloud. With a few clicks in the AWS Management Console, you can create file systems that are accessible to Amazon EC2 instances via a file system interface (using standard operating system file I/O APIs) and supports full file system access semantics (such as strong consistency and file locking).</p> <p>Amazon EFS file systems can automatically scale from gigabytes to petabytes of data without needing to provision storage. Tens, hundreds, or even thousands of Amazon EC2 instances can access an Amazon EFS file system at the same time, and Amazon EFS provides consistent performance to each Amazon EC2 instance. Amazon EFS is designed to be highly durable and highly available.</p> <p>&nbsp;</p> <p><strong>References:</strong></p> <p><a href="https://docs.aws.amazon.com/efs/latest/ug/performance.html">https://docs.aws.amazon.com/efs/latest/ug/performance.html</a></p> <p><a href="https://aws.amazon.com/efs/faq/">https://aws.amazon.com/efs/faq/</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>A data analytics company has been building its new generation big data and analytics platform on their AWS cloud infrastructure. They need a storage service that provides the scale and performance that their big data applications require such as high throughput to compute nodes coupled with read-after-write consistency and low-latency file operations. In addition, their data needs to be stored redundantly across multiple AZs and allows concurrent connections from multiple EC2 instances hosted on multiple AZs.   </p><p>Which of the following AWS storage service will you use to meet this requirement?</p>', 'answers': ['<p>EFS</p>', '<p>EBS</p>', '<p>S3</p>', '<p>Glacier</p>', '<p>DynamoDB</p>', '<p>RDS</p>']}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:29:07Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are employed by a large electronics company that uses Amazon Simple Storage Service. For reporting purposes, they want to track and log every request access to their S3 buckets including the requester, bucket name, request time, request action, response status, and error code information. They also use this information for their internal security and access audits. Which is the best solution among the following options that can satisfy the company requirement?', '_class': 'assessment', 'created': '2018-11-21T07:29:07Z', 'id': 6180718, 'original_assessment_id': 2567120, 'section': 'S3', 'prompt': {'explanation': '<p>For this scenario, you can use CloudTrail and the Server Access Logging feature of Amazon S3. However, the question mentioned that it needs a detailed information about every access request sent to the S3 bucket such as requestor, bucket name, request time, request action, response status, and error code information. Cloudtrail can only log the API calls and provides less information compared with the Server Access Logging feature in S3. Hence, the correct answer is Option 2.</p> <p>Option 3 is incorrect because this action&nbsp;refers to AWS billing and not for logging.</p> <p>Option 4 is incorrect because we are looking for a logging solution and not event notification.</p> <p>&nbsp;</p> <p><strong>References:&nbsp;</strong></p> <p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/cloudtrail-logging.html">https://docs.aws.amazon.com/AmazonS3/latest/dev/cloudtrail-logging.html</a></p> <p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/ServerLogs.html">https://docs.aws.amazon.com/AmazonS3/latest/dev/ServerLogs.html</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': 'You are employed by a large electronics company that uses Amazon Simple Storage Service. For reporting purposes, they want to track and log every request access to their S3 buckets including the requester, bucket name, request time, request action, response status, and error code information. They also use this information for their internal security and access audits. <br><br>Which is the best solution among the following options that can satisfy the company requirement?', 'answers': ['Enable AWS CloudTrail to audit all Amazon S3 bucket access.', 'Enable server access logging for all required Amazon S3 buckets.', 'Enable the Requester Pays option to track access via AWS Billing.', 'Enable Amazon S3 Event Notifications for PUT and POST.']}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:29:07Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a tech company which currently has an on-premise infrastructure. They are currently running low on storage and want to have the ability to extend their storage using AWS cloud. Which AWS service can help you achieve this requirement?', '_class': 'assessment', 'created': '2018-11-21T07:29:07Z', 'id': 6180720, 'original_assessment_id': 2567122, 'section': 'Storage Gateway', 'prompt': {'explanation': '<p>AWS Storage Gateway connects an on-premises software appliance with cloud-based storage to provide seamless integration with data security features between your on-premises IT environment and the AWS storage infrastructure. You can use the service to store data in the AWS Cloud for scalable and cost-effective storage that helps maintain data security.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="http://docs.aws.amazon.com/storagegateway/latest/userguide/WhatIsStorageGateway.html">http://docs.aws.amazon.com/storagegateway/latest/userguide/WhatIsStorageGateway.html</a></p><p>&nbsp;</p>', 'answers': ['Amazon EC2', 'Amazon Storage Gateway', 'Amazon Storage devices', 'Amazon SQS'], 'question': 'You are working for a tech company which currently has an on-premise infrastructure. They are currently running low on storage and want to have the ability to extend their storage using AWS cloud. <br /><br />Which AWS service can help you achieve this requirement?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:29:07Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as a Senior Cloud Systems Administrator in a government agency. Due to budget constraints, you were instructed to decommission and stop the EC2 instances in your VPC that are not being used. There are several EC2-Classic and EC2-VPC instances which are currently running in your VPC.\xa0 \xa0Which of the following is incorrect about Private IP addresses once the instances are stopped?', '_class': 'assessment', 'created': '2018-11-21T07:29:07Z', 'id': 6180722, 'original_assessment_id': 2567124, 'section': 'VPC', 'prompt': {'explanation': '<p>For EC2 instances launched in EC2-Classic, AWS releases the private IPv4 address when the instance is stopped or terminated. If you restart your stopped instance, it receives a new private IPv4 address.</p><p>For EC2 instances launched in a VPC, a private IPv4 address remains associated with the network interface when the instance is stopped and restarted. It is only released when the instance is terminated.</p><br /><p>References:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-instance-addressing.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-instance-addressing.html</a></p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html#lifecycle-differences" target="_blank" rel="noopener">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html#lifecycle-differences</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are working as a Senior Cloud Systems Administrator in a government agency. Due to budget constraints, you were instructed to decommission and stop the EC2 instances in your VPC that are not being used. There are several EC2-Classic and EC2-VPC instances which are currently running in your VPC.\xa0 \xa0</p><p>Which of the following is incorrect about Private IP addresses once the instances are stopped?\xa0 </p>', 'answers': ['<p>In Amazon EC2-Classic, the instance gets new private as well as public IPv4 addresses when you stopped and restarted the instance again.</p>', 'In Amazon VPC, an instance retains its private IP addresses when the instance is stopped.', 'In Amazon VPC, an instance does not retain its private IP addresses when the instance is stopped.', 'In Amazon EC2 classic, the private IP addresses are only returned to Amazon EC2 when the instance is stopped or terminated']}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:29:07Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'The IT Operations team of your company wants to retrieve all of the Public IP addresses assigned to a running EC2 instance via the Instance metadata. Which of the following URLs will you use?', '_class': 'assessment', 'created': '2018-11-21T07:29:07Z', 'id': 6180724, 'original_assessment_id': 2567126, 'section': 'EC2', 'prompt': {'explanation': '<p>http://169.254.169.254/latest/meta-data/ is the URL that you can use to retrieve the Instance Metadata of your EC2 instance, including the public-hostname, public-ipv4, public-keys et cetera.</p><p>This can be helpful when you\'re writing scripts to run from your instance as it enables you to access the local IP address of your instance from the instance metadata to manage a connection to an external application. Remember that you are not billed for HTTP requests used to retrieve instance metadata and user data.</p><p>Resources:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html</a></p>', 'answers': ['http://169.254.169.254/latest/meta-data/public-ipv4', 'http://169.255.169.255/latest/meta-data/public-ipv4', 'http://254.169.254.169/metadata/public-ipv4', 'http://255.169.255.169/latest/public-ipv4'], 'question': 'The IT Operations team of your company wants to retrieve all of the Public IP addresses assigned to a running EC2 instance via the Instance metadata. <br /><br />Which of the following URLs will you use?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:29:07Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as a Solutions Architect for a startup company which has recently migrated its applications to AWS. Due to budget constraints, your manager instructed you to use AWS Trusted Advisor to identify all of the unused and idle AWS resources that should be eliminated to save cost. The AWS Trusted Advisor analyzes your AWS environment and provides best practice recommendations in five categories, which are?', '_class': 'assessment', 'created': '2018-11-21T07:29:07Z', 'id': 6180740, 'original_assessment_id': 2567142, 'section': 'Trusted Advisor', 'prompt': {'explanation': '<p>Remember that the AWS Trusted Advisor analyzes your AWS environment and provides best practice recommendations in these five categories: <strong>C</strong>ost Optimization, <strong>P</strong>erformance, <strong>F</strong>ault Tolerance, <strong>S</strong>ecurity, and <strong>S</strong>ervice Limits. You can use a mnemonic, such as CPFSS, to memorize these five categories.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/premiumsupport/ta-faqs/" target="_blank" rel="noopener">https://aws.amazon.com/premiumsupport/ta-faqs/</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are working as a Solutions Architect for a startup company which has recently migrated its applications to AWS. Due to budget constraints, your manager instructed you to use AWS Trusted Advisor to identify all of the unused and idle AWS resources that should be eliminated to save cost. The AWS Trusted Advisor analyzes your AWS environment and provides best practice recommendations in five categories, which are? </p>', 'answers': ['CPU Optimization, Performance, Fault Tolerance, Security, and Service Limits.', 'Cost Optimization, Performance, Fault Tolerance, Security, and Scaling Limits.', 'Cost Optimization, Performance, Fault Tolerance, Stability, and Service Limits.', 'Cost Optimization, Performance, Fault Tolerance, Security, and Service Limits.']}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:29:07Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'The company you are working for has a set of AWS resources hosted in ap-northeast-1 region. You have been requested by your IT Manager to create a shell script which could create duplicate resources in another region in the event that ap-northeast-1 region fails.Which of the following AWS services could help fulfill this task?', '_class': 'assessment', 'created': '2018-11-21T07:29:07Z', 'id': 6180726, 'original_assessment_id': 2567128, 'section': 'CloudFormation', 'prompt': {'explanation': '<p>AWS CloudFormation is a service that helps you model and set up your Amazon Web Services resources so that you can spend less time managing those resources and more time focusing on your applications that run in AWS.</p><p>You can create a template that describes all the AWS resources that you want (like Amazon EC2 instances or Amazon RDS DB instances), and AWS CloudFormation takes care of provisioning and configuring those resources for you. With this, you can deploy an exact copy of your AWS architecture, along with all of the AWS resources which are hosted in one region to another.</p><p>&nbsp;</p><br /><p>References:</p><p>&nbsp;<a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html</a></p><p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>The company you are working for has a set of AWS resources hosted in ap-northeast-1 region. You have been requested by your IT Manager to create a shell script which could create duplicate resources in another region in the event that ap-northeast-1 region fails.<br><br>Which of the following AWS services could help fulfill this task?</p>', 'answers': ['AWS Elastic Beanstalk', 'AWS SQS', '<p>AWS CloudFormation</p>', 'AWS SNS']}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:29:07Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have an Auto Scaling group which is configured to launch new t2.micro EC2 instances when there is a significant load increase in the application. To cope with the demand, you now need to replace those instances with a larger t2.2xlarge instance type. How would you implement this change?', '_class': 'assessment', 'created': '2018-11-21T07:29:07Z', 'id': 6180728, 'original_assessment_id': 2567130, 'section': '', 'prompt': {'explanation': '<p>You can only specify one launch configuration for an Auto Scaling group at a time, and you can\'t modify a launch configuration after you\'ve created it.&nbsp;Therefore, if you want to change the launch configuration for an Auto Scaling group, you must create a launch configuration and then update your Auto Scaling group with the new launch configuration.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/LaunchConfiguration.html">https://docs.aws.amazon.com/autoscaling/ec2/userguide/LaunchConfiguration.html</a></p>', 'answers': ['Just change the instance type to <code>t2.2xlarge</code> in the current launch configuration', 'Create another Auto Scaling Group and attach the new instance type.', 'Create a new launch configuration with the new instance type and update the Auto Scaling Group.', 'Change the instance type of each EC2 instance manually.'], 'question': 'You have an Auto Scaling group which is configured to launch new <code>t2.micro</code> EC2 instances when there is a significant load increase in the application. To cope with the demand, you now need to replace those instances with a larger <code>t2.2xlarge</code> instance type. How would you implement this change?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:29:07Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are planning to host a WordPress website in AWS for your tech startup company. You need to register a custom domain name called “tutorialsdojo.com” hence, you used Route 53. Which of the following is not a function of Route 53?', '_class': 'assessment', 'created': '2018-11-21T07:29:07Z', 'id': 6180730, 'original_assessment_id': 2567132, 'section': 'Route53', 'prompt': {'explanation': '<p>Amazon Route53 has 3 main functions as shown below:</p><ol><li><strong>Register domain names</strong> &ndash; Your website needs a name, such as example.com. Amazon Route53 lets you register a name for your website or web application, known as a domain name.</li><li><strong>Route internet traffic to the resources for your domain</strong> &ndash; When a user opens a web browser and enters your domain name in the address bar, Amazon Route53 helps the Domain Name System (DNS) connect the browser with your website or web application.</li><li><strong>Check the health of your resources</strong> &ndash; Amazon Route53 sends automated requests over the Internet to a resource, such as a web server, to verify that it\'s reachable, available, and functional.</li></ol><p>Option 3 is a feature provided by VPC Peering.<br /><br />Resources:<br /><a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/Welcome.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/Welcome.html</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are planning to host a WordPress website in AWS for your tech startup company. You need to register a custom domain name called “tutorialsdojo.com” hence, you used Route 53. Which of the following is not a function of Route 53?</p>', 'answers': ['Route internet traffic to the resources for your domain', 'Domain name registration', 'Provides routing between two Virtual Private Cloud networks privately.', 'Checks the health of your resources.']}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:29:07Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have a set of linux servers running on multiple On-Demand EC2 Instances. The Audit team wants to collect and process the application log files generated from these servers for their report.  Which of the following services is the best to use in this case?', '_class': 'assessment', 'created': '2018-11-21T07:29:07Z', 'id': 6180732, 'original_assessment_id': 2567134, 'section': 'EMR', 'prompt': {'explanation': '<p>Amazon EMR is a managed cluster platform that simplifies running big data frameworks, such as Apache Hadoop and Apache Spark, on AWS to process and analyze vast amounts of data. By using these frameworks and related open-source projects such as Apache Hive and Apache Pig, you can process data for analytics purposes and business intelligence workloads. Additionally, you can use Amazon EMR to transform and move large amounts of data into and out of other AWS data stores and databases such as Amazon Simple Storage Service (Amazon S3) and Amazon DynamoDB.</p><ul><li>Option 2 is wrong as Amazon Glacier is used for data archive only.</li><br /><li>Option 3 is wrong as an EC2 instance is not a recommended storage service. In addition, Amazon EC2 does not have a built-in data processing engine to process large amounts of data.</li><br /><li>Option 4 is wrong as Amazon RedShift&nbsp;is mainly used as a data warehouse service.</li></ul><br /><p>References:</p><p><a href="http://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-what-is-emr.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-what-is-emr.html</a></p>', 'answers': ['Amazon S3 for storing the application log files and Amazon Elastic MapReduce for processing the log files.', 'Amazon Glacier for storing the application log files and Spot EC2 Instances for processing them.', 'A single On-Demand Amazon EC2 instance for both storing and processing the log files', 'Amazon RedShift to store the logs and Amazon Lambda for running custom log analysis scripts'], 'question': 'You have a set of linux servers running on multiple On-Demand EC2 Instances. The Audit team wants to collect and process the application log files generated from these servers for their report.  <br /><br />Which of the following services is the best to use in this case?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:29:07Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are making an estimate of how much your company will pay for all of the AWS resources that they are using. Which of the following will incur a cost? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:29:07Z', 'id': 6180734, 'original_assessment_id': 2567136, 'section': 'EC2', 'prompt': {'explanation': '<p>Billing commences when Amazon EC2 initiates the boot sequence of an AMI instance. Billing ends when the instance terminates, which could occur through a web services command, by running "shutdown -h", or through instance failure. When you stop an instance, AWS shuts it down but don\'t charge hourly usage for a stopped instance or data transfer fees, but AWS does charge for the storage of any Amazon EBS volumes. Hence, options 1 and 3 are the right answers and conversely, options 2 and 6 are incorrect as there is no charge for a terminated EC2 instance&nbsp;that you have shut down.</p><p>Option 4 is incorrect because there are no additional charges for creating and using the VPC itself. Usage charges for other Amazon Web Services, including Amazon EC2, still apply at published rates for those resources, including data transfer charges.</p><p>Option 5 is incorrect due to the fact that Amazon stores the data sets at no charge to the community and, as with all AWS services, you pay only for the compute and storage you use for your own applications.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/cloudtrail/">https://aws.amazon.com/cloudtrail/</a></p><p><a href="https://aws.amazon.com/vpc/faqs">https://aws.amazon.com/vpc/faqs</a></p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-public-data-sets.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-public-data-sets.html</a></p><p>&nbsp;</p><p>&nbsp;</p>', 'answers': ['A running EC2 Instance', 'A stopped EC2 Instance', 'EBS Volumes attached to stopped EC2 Instances', 'Using an Amazon VPC', 'Public Data Set', 'A terminated EC2 Instance'], 'question': 'You are making an estimate of how much your company will pay for all of the AWS resources that they are using. Which of the following will incur a cost? (Choose 2)'}, 'related_lectures': [], 'correct_response': ['a', 'c'], 'updated': '2018-11-21T07:29:07Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A financial company instructed you to automate the recurring tasks in your department such as patch management, infrastructure selection, and data synchronization to improve their current processes. You need to have a service which can coordinate multiple AWS services into serverless workflows.\xa0 \xa0Which of the following is the most cost-effective service to use in this scenario?', '_class': 'assessment', 'created': '2018-11-21T07:29:07Z', 'id': 6180736, 'original_assessment_id': 2567138, 'section': 'Step Functions', 'prompt': {'explanation': '<p>AWS Step Functions provides serverless orchestration for modern applications. Orchestration centrally manages a workflow by breaking it into multiple steps, adding flow logic, and tracking the inputs and outputs between the steps. As your applications execute, Step Functions maintains application state, tracking exactly which workflow step your application is in, and stores an event log of data that is passed between application components. That means that if networks fail or components hang, your application can pick up right where it left off.</p> <p>Application development is faster and more intuitive with Step Functions, because you can define and manage the workflow of your application independently from its business logic. Making changes to one does not affect the other. You can easily update and modify workflows in one place, without having to struggle with managing, monitoring and maintaining multiple point-to-point integrations. Step Functions frees your functions and containers from excess code, so your applications are faster to write, more resilient, and easier to maintain.</p> <p>Option 1 is incorrect because SWF is a fully-managed state tracker and task coordinator service. It does not provide serverless orchestration to multiple AWS resources.</p> <p>Option 2 is incorrect because although Lambda is used for serverless computing, it does not provide a direct way to coordinate multiple AWS services into serverless workflows.</p> <p>Option 4 is incorrect because AWS Batch is primarily used to efficiently run hundreds of thousands of batch computing jobs in AWS.</p> <p><strong>Reference: </strong></p> <p><a href="https://aws.amazon.com/step-functions/features/">https://aws.amazon.com/step-functions/features/</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>A financial company instructed you to automate the recurring tasks in your department such as patch management, infrastructure selection, and data synchronization to improve their current processes. You need to have a service which can coordinate multiple AWS services into serverless workflows.\xa0 \xa0</p><p>Which of the following is the most cost-effective service to use in this scenario?</p>', 'answers': ['<p>SWF</p>', '<p>AWS Lambda</p>', '<p>AWS Step Functions</p>', '<p>AWS Batch</p>']}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:29:07Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'The game development company that you are working for has an Amazon VPC with a public subnet. It has 4 EC2 instances that are deployed in the public subnet. These 4 instances can successfully communicate with other hosts on the Internet. You launch a fifth instance in the same public subnet, using the same AMI and security group configuration that you used for the others. However, this new instance cannot be accessed from the internet unlike the other instance. What should you do to enable access to the fifth instance over the Internet?', '_class': 'assessment', 'created': '2018-11-21T07:29:07Z', 'id': 6180738, 'original_assessment_id': 2567140, 'section': 'EIP', 'prompt': {'explanation': '<p>An&nbsp;<em>Elastic IP address</em>&nbsp;is a static IPv4 address designed for dynamic cloud computing. An Elastic IP address is associated with your AWS account. With an Elastic IP address, you can mask the failure of an instance or software by rapidly remapping the address to another instance in your account.</p> <p>An Elastic IP address is a public IPv4 address, which is reachable from the Internet. If your instance does not have a public IPv4 address, you can associate an Elastic IP address with your instance to enable communication with the Internet; for example, to connect to your instance from your local computer.</p> <p>Option 1 is incorrect because it is already mentioned that your instances are in a public subnet. You only have to configure a NAT instance when your instances are on a private subnet.</p> <p>Option 2 is the correct answer because you need to either add a public address or add an EIP for this EC2 instance for it to be able to access the internet.</p> <p>Option 3 is incorrect because the public IP address has to be configured in the Elastic Network Interface (ENI) of the EC2 instance and not on its Operating System (OS).</p> <p>Option 4 is incorrect because if the routing table was wrong then you would have an issue with the other 4 instances.</p> <p>&nbsp;</p> <p>References:&nbsp;</p> <p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': 'The game development company that you are working for has an Amazon VPC with a public subnet. It has 4 EC2 instances that are deployed in the public subnet. These 4 instances can successfully communicate with other hosts on the Internet. You launch a fifth instance in the same public subnet, using the same AMI and security group configuration that you used for the others. However, this new instance cannot be accessed from the internet unlike the other instance. <br><br>What should you do to enable access to the fifth instance over the Internet?', 'answers': ['Deploy a NAT instance into the public subnet.', '<p>Assign an Elastic IP address to the fifth\xa0instance.</p>', '<p>Configure a publicly routable IP Address in the host OS of the fifth instance.</p>', 'Modify the routing table for the public subnet.']}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:29:07Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'What is the base URL for all requests for instance metadata in EC2?', '_class': 'assessment', 'created': '2018-11-21T07:29:07Z', 'id': 6180742, 'original_assessment_id': 2567144, 'section': 'EC2', 'prompt': {'explanation': '<p>http://169.254.169.254/latest/meta-data/ is the URL that you can use to retrieve the Instance Metadata of your EC2 instance, including the public-hostname, public-ipv4, public-keys, et cetera.&nbsp;</p><p>This can be helpful when you\'re writing scripts to run from your instance as it enables you to access the local IP address of your instance from the instance metadata to manage a connection to an external application. Remember that you are not billed for HTTP requests used to retrieve instance metadata and user data.</p><p>&nbsp;</p><p>Resources:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html</a></p><p>&nbsp;</p>', 'answers': ['http://254.169.169.254/latest/', 'http://169.169.254.254/latest/', 'http://127.0.0.1/latest/', 'http://169.254.169.254/latest/'], 'question': 'What is the base URL for all requests for instance metadata in EC2?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:29:07Z'}, {'assessment_type': 'multi-select', 'question_plain': "A technology company is building a new cryptocurrency trading platform that allows buying and selling of Bitcoin, Ethereum, XRP, Ripple and many others. You were hired as a Cloud Engineer to build the required infrastructure needed for this new trading platform. On your first week at work, you started to create CloudFormation YAML scripts that defines all of the needed AWS resources for the application. Your manager was shocked that you haven't created the EC2 instances, S3 buckets and other AWS resources straight away. He does not understand the text-based scripts that you have done and was disappointed that you are just slacking off at your job.  In this scenario, what are the benefits of using the Amazon CloudFormation service that you should tell your manager to clarify his concerns? (Choose 3)", '_class': 'assessment', 'created': '2018-11-21T07:29:07Z', 'id': 6180744, 'original_assessment_id': 2567146, 'section': 'CloudFormation', 'prompt': {'explanation': '<p>The correct answers are:</p> <ul> <li>-Provides version control for your entire AWS infrastructure</li> <li>-Allows you to model your entire infrastructure in a text file</li> <li>-Using CloudFormation itself is free but not including the AWS resources that have been created.</li> </ul> <p>AWS CloudFormation provides a common language for you to describe and provision all the infrastructure resources in your cloud environment. CloudFormation allows you to use a simple text file to model and provision, in an automated and secure manner, all the resources needed for your applications across all regions and accounts. This file serves as the single source of truth for your cloud environment. AWS CloudFormation is available at no additional charge, and you pay only for the AWS resources needed to run your applications.</p> <p>&nbsp;</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/cloudformation/">https://aws.amazon.com/cloudformation/</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'relatedLectureIds': '', 'question': "<p>A technology company is building a new cryptocurrency trading platform that allows buying and selling of Bitcoin, Ethereum, XRP, Ripple and many others. You were hired as a Cloud Engineer to build the required infrastructure needed for this new trading platform. On your first week at work, you started to create CloudFormation YAML scripts that defines all of the needed AWS resources for the application. Your manager was shocked that you haven't created the EC2 instances, S3 buckets and other AWS resources straight away. He does not understand the text-based scripts that you have done and was disappointed that you are just slacking off at your job.  </p><p>In this scenario, what are the benefits of using the Amazon CloudFormation service that you should tell your manager to clarify his concerns? (Choose 3)</p>", 'answers': ['<p>Provides highly durable and scalable data storage</p>', 'A storage location for the code of your application', 'Provides version control for your entire AWS infrastructure', 'Allows you to model your entire infrastructure in a text file', 'Using CloudFormation itself is free but not including the AWS resources that have been created.', '<p>Delivers static content to users across the globe much faster</p>']}, 'related_lectures': [], 'correct_response': ['c', 'd', 'e'], 'updated': '2018-11-21T07:29:07Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have a web application hosted in AWS cloud where the application logs are sent to Amazon CloudWatch. Lately, the web application has recently been encountering some errors which can be resolved simply by restarting the instance. What will you do to automatically restart the EC2 instances whenever the same application error occurs?', '_class': 'assessment', 'created': '2018-11-21T07:29:07Z', 'id': 6180746, 'original_assessment_id': 2567148, 'section': 'CloudWatch', 'prompt': {'explanation': '<p>In this scenario, you can&nbsp;look at the&nbsp;existing CloudWatch logs for keywords related to the application error to create a custom metric. Then, create a CloudWatch alarm for that custom metric which invokes an action to restart the EC2 instance.&nbsp;</p><p>You can create alarms that automatically stop, terminate, reboot, or recover your EC2 instances using Amazon CloudWatch alarm actions.&nbsp;You can use the stop or terminate actions to help you save money when you no longer need an instance to be running. You can use the reboot and recover actions to automatically reboot those instances or recover them onto new hardware if a system impairment occurs.</p><p>Option 2 is incorrect because you can\'t create an alarm in Amazon SNS.</p><p>Options 3 and 4 are incorrect because Flow Logs are used in VPC and not on specific EC2 instance.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/UsingAlarmActions.html">https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/UsingAlarmActions.html</a></p>', 'answers': ['First, look at the existing CloudWatch logs for keywords related to the application error to create a custom metric. Then, create a CloudWatch alarm for that custom metric which invokes an action to restart the EC2 instance.', 'First, look at the existing CloudWatch logs for keywords related to the application error to create a custom metric. Then, create an alarm in Amazon SNS for that custom metric which invokes an action to restart the EC2 instance.', 'First, look at the existing Flow logs for keywords related to the application error to create a custom metric. Then, create a CloudWatch alarm for that custom metric which invokes an action to restart the EC2 instance.', 'First, look at the existing Flow logs for keywords related to the application error to create a custom metric. Then, create a CloudWatch alarm for that custom metric which calls a Lambda function that invokes an action to restart the EC2 instance.'], 'question': 'You have a web application hosted in AWS cloud where the application logs are sent to Amazon CloudWatch. Lately, the web application has recently been encountering some errors which can be resolved simply by restarting the instance. <br /><br />What will you do to automatically restart the EC2 instances whenever the same application error occurs?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:29:07Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A real-time data analytics application is using AWS Lambda to process data and store results in JSON format to an S3 bucket. To speed up the existing workflow, you have to use a service where you can run sophisticated Big Data analytics on your data without moving them into a separate analytics system.\xa0 \xa0Which of the following group of services can you use to meet this requirement?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180748, 'original_assessment_id': 2567150, 'section': 'Redshift Spectrum', 'prompt': {'explanation': '<p>Amazon S3 allows you to run sophisticated Big Data analytics on your data without moving the data into a separate analytics system. In AWS, there is a suite of tools that make analyzing and processing large amounts of data in the cloud faster, including ways to optimize and integrate existing workflows with Amazon S3:</p> <p><strong>1. S3 Select </strong></p> <p>Amazon S3 Select is designed to help analyze and process data within an object in Amazon S3 buckets, faster and cheaper. It works by providing the ability to retrieve a subset of data from an object in Amazon S3 using simple SQL expressions. Your applications no longer have to use compute resources to scan and filter the data from an object, potentially increasing query performance by up to 400%, and reducing query costs as much as 80%. You simply change your application to use SELECT instead of GET to take advantage of S3 Select.</p> <p><strong>2. Amazon Athena </strong></p> <p>Amazon Athena is an interactive query service that makes it easy to analyze data in Amazon S3 using standard SQL expressions. Athena is serverless, so there is no infrastructure to manage, and you pay only for the queries you run. Athena is easy to use. Simply point to your data in Amazon S3, define the schema, and start querying using standard SQL expressions. Most results are delivered within seconds. With Athena, there&rsquo;s no need for complex ETL jobs to prepare your data for analysis. This makes it easy for anyone with SQL skills to quickly analyze large-scale datasets.</p> <p><strong>3. Amazon Redshift Spectrum </strong></p> <p>Amazon Redshift also includes Redshift Spectrum, allowing you to directly run SQL queries against exabytes of unstructured data in Amazon S3. No loading or transformation is required, and you can use open data formats, including Avro, CSV, Grok, ORC, Parquet, RCFile, RegexSerDe, SequenceFile, TextFile, and TSV. Redshift Spectrum automatically scales query compute capacity based on the data being retrieved, so queries against Amazon S3 run fast, regardless of data set size.</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/s3/features/#Query_in_Place">https://aws.amazon.com/s3/features/#Query_in_Place</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>A real-time data analytics application is using AWS Lambda to process data and store results in JSON format to an S3 bucket. To speed up the existing workflow, you have to use a service where you can run sophisticated Big Data analytics on your data without moving them into a separate analytics system.\xa0 \xa0</p><p>Which of the following group of services can you use to meet this requirement?\xa0 </p>', 'answers': ['<p>S3 Select, Amazon Neptune, DynamoDB DAX\xa0 </p>', '<p>Amazon X-Ray, Amazon Neptune, DynamoDB\xa0 </p>', '<p>Amazon Glue, Glacier Select, Amazon Redshift\xa0 </p>', '<p>S3 Select, Amazon Athena, Amazon Redshift Spectrum\xa0 </p>']}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': "You have a web application hosted in an On-Demand EC2 instance in your VPC. You are creating a shell script that needs the instance's public and private IP addresses. What is the best way to get the instance's associated IP addresses which your shell script can use?", '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180750, 'original_assessment_id': 2567152, 'section': 'EC2', 'prompt': {'explanation': '<p>Instance metadata is data about your EC2 instance that you can use to configure or manage the running instance.&nbsp;Because your instance metadata is available from your running instance, you do not need to use the Amazon EC2 console or the AWS CLI. This can be helpful when you\'re writing scripts to run from your instance. For example, you can access the local IP address of your instance from instance metadata to manage a connection to an external application.</p><p>To view the private IPv4 address, public IPv4 address, and all other categories of instance metadata from within a running instance, use the following URL:</p><pre><code>http://169.254.169.254/latest/meta-data/</code></pre><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html</a></p>', 'answers': ['By using IAM.', 'By using a cloud watch metric.', 'By using a Curl or Get Command to get the latest metadata information from http://169.254.169.254/latest/meta-data/', 'By using a Curl or Get Command to get the latest user data information from http://169.254.169.254/latest/user-data/'], 'question': "You have a web application hosted in an On-Demand EC2 instance in your VPC. You are creating a shell script that needs the instance's public and private IP addresses. <br /><br />What is the best way to get the instance's associated IP addresses which your shell script can use?"}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are the technical lead of the Cloud Infrastructure team in your company and you were consulted by a software developer regarding the required AWS resources of the web application that he is building. He knows that an Instance Store only provides ephemeral storage where the data is automatically deleted when the instance is terminated. To ensure that the data of his web application persists, the app should be launched in an EC2 instance that has a durable, block-level storage volume attached. He knows that they need to use an EBS volume, but they are not sure on what type they need to use.  In this scenario, which of the following is true about Amazon EBS volume types and their respective usage? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180752, 'original_assessment_id': 2567154, 'section': 'EC2', 'prompt': {'explanation': '<p>Amazon EBS provides three volume types to best meet the needs of your workloads: General Purpose (SSD), Provisioned IOPS (SSD), and Magnetic.</p> <p>General Purpose (SSD) is the new, SSD-backed, general purpose EBS volume type that we recommend as the default choice for customers. General Purpose (SSD) volumes are suitable for a broad range of workloads, including small to medium sized databases, development and test environments, and boot volumes.</p> <p>Provisioned IOPS (SSD) volumes offer storage with consistent and low-latency performance, and are designed for I/O intensive applications such as large relational or NoSQL databases. Magnetic volumes provide the lowest cost per gigabyte of all EBS volume types.</p> <p>Magnetic volumes are ideal for workloads where data is accessed infrequently, and applications where the lowest storage cost is important.</p> <p>&nbsp;</p> <p><strong>Reference:&nbsp;&nbsp;</strong></p> <p><a href="https://aws.amazon.com/ec2/instance-types/">https://aws.amazon.com/ec2/instance-types/</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are the technical lead of the Cloud Infrastructure team in your company and you were consulted by a software developer regarding the required AWS resources of the web application that he is building. He knows that an Instance Store only provides ephemeral storage where the data is automatically deleted when the instance is terminated. To ensure that the data of his web application persists, the app should be launched in an EC2 instance that has a durable, block-level storage volume attached. He knows that they need to use an EBS volume, but they are not sure on what type they need to use.  </p><p>In this scenario, which of the following is true about Amazon EBS volume types and their respective usage? (Choose 3)</p>', 'answers': ['<p>General Purpose volumes are suitable for a broad range of workloads, including small to medium sized databases, development and test environments, and boot volumes. </p>', '<p>Provisioned IOPS volumes offer storage with consistent and low-latency performance, and are designed for I/O intensive applications such as large relational or NoSQL databases. </p>', '<p>Magnetic volumes provide the lowest cost per gigabyte of all EBS volume types and are ideal for workloads where data is accessed infrequently, and applications where the lowest storage cost is important.</p>', '<p>Reduced Redundancy Storage volumes offer consistent and low-latency performance, and are designed for I/O intensive applications such as large relational or NoSQL databases. </p>', '<p>Single root I/O virtualization (SR-IOV) volumes are suitable for a broad range of workloads, including small to medium sized databases, development and test environments, and boot volumes. </p>', '<p>Spot volumes provide the lowest cost per gigabyte of all EBS volume types and are ideal for workloads where data is accessed infrequently, and applications where the lowest storage cost is important.</p>']}, 'related_lectures': [], 'correct_response': ['a', 'b', 'c'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'What is required when you need to specify a resource unambiguously across all of AWS, such as in IAM policies, Amazon Relational Database Service (Amazon RDS) tags, and API calls?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180754, 'original_assessment_id': 2567156, 'section': 'VPC', 'prompt': {'explanation': '<p>Amazon Resource Names (ARNs) uniquely identify AWS resources. We require an ARN when you need to specify a resource unambiguously across all of AWS, such as in IAM policies, Amazon Relational Database Service (Amazon RDS) tags, and API calls.</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html</a></p>', 'answers': ['Amazon Resource Normalization', 'Amazon Resource Nullification', 'Amazon Resource Name', 'Amazon Resource Namespace'], 'question': 'What is required when you need to specify a resource unambiguously across all of AWS, such as in IAM policies, Amazon Relational Database Service (Amazon RDS) tags, and API calls?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are a Solutions Architect for a large London-based software company. You are assigned to improve the performance and current processes of supporting the AWS resources in your VPC. Upon checking, you noticed that the Operations team does not have an automated way to monitor and resolve issues with their on-demand EC2 instances.What can be used to automatically monitor your EC2 instances and notify the Operations team for any incidents?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180756, 'original_assessment_id': 2567158, 'section': 'CloudWatch', 'prompt': {'explanation': '<p>Amazon CloudWatch is a monitoring service for AWS cloud resources and the applications you run on AWS. You can use Amazon CloudWatch to collect and track metrics, collect and monitor log files, and set alarms.</p><p>Amazon CloudWatch can monitor AWS resources such as Amazon EC2 instances, Amazon DynamoDB tables, and Amazon RDS DB instances, as well as custom metrics generated by your applications and services, and any log files your applications generate. You can use Amazon CloudWatch to gain system-wide visibility into resource utilization, application performance, and operational health. You can use these insights to react and keep your application running smoothly.</p><p>Option 1 is incorrect as CloudTrail is mainly used for logging and not for monitoring.</p><p>Options 3 and 4 are incorrect as SWF and SQS are used for creating distributed application with decoupled components and not for monitoring.</p><p>Option 5 is incorrect as Amazon Kinesis is used to collect and process large streams of data records in real time.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/cloudwatch/faqs/">https://aws.amazon.com/cloudwatch/faqs/</a></p><p>&nbsp;</p>', 'answers': ['AWS Cloudtrail', 'AWS Cloudwatch', 'AWS SWF', 'AWS SQS', 'AWS Kinesis'], 'question': 'You are a Solutions Architect for a large London-based software company. You are assigned to improve the performance and current processes of supporting the AWS resources in your VPC. Upon checking, you noticed that the Operations team does not have an automated way to monitor and resolve issues with their on-demand EC2 instances.<br /><br />What can be used to automatically monitor your EC2 instances and notify the Operations team for any incidents?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are responsible for running a global news website hosted in a fleet of EC2 Instances. Lately, the load on the website has increased which resulted to slower response time for the site visitors. This issue impacts the revenue of the company as some readers tend to leave the site when it does not load after 10 seconds. Which of the below services in AWS can be used to solve this problem? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180758, 'original_assessment_id': 2567160, 'section': 'CloudFront', 'prompt': {'explanation': '<p>The global news website has a problem with latency considering that there are a lot of readers of the site from all parts of the globe. In this scenario, you can use a&nbsp;content delivery network (CDN) which is a geographically distributed group of servers which work together to provide fast delivery of Internet content. And since this is a news website, most of its data are read-only, which can be cached to improve the read throughput and avoid the repetitive requests from the server.</p><p>In AWS, Amazon CloudFront is the global content delivery network (CDN) service that you can use and for web caching,&nbsp;Amazon ElastiCache is the suitable service. Hence, the answers here are options 1 and 3.</p><p>Option 2 is incorrect as&nbsp;AWS Storage Gateway is used for storage.</p><p>Option 4 is incorrect as this would be costly and totally unnecessary considering that you can use Amazon Cloudfront and ElastiCache to improve the performance of the website.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/elasticache/">https://aws.amazon.com/elasticache/</a></p><p><a href="http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html">http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html</a></p><p>&nbsp;</p>', 'answers': ['Use AWS Cloudfront with website as the custom origin.', 'For better read throughput, use AWS Storage Gateway to distribute the content across multiple regions.', "Use Amazon ElastiCache for the website's in-memory data store or cache.", 'Deploy the website to all regions in different VPCs for faster processing.'], 'question': 'You are responsible for running a global news website hosted in a fleet of EC2 Instances. Lately, the load on the website has increased which resulted to slower response time for the site visitors. This issue impacts the revenue of the company as some readers tend to leave the site when it does not load after 10 seconds. <br /><br />Which of the below services in AWS can be used to solve this problem? (Choose 2)'}, 'related_lectures': [], 'correct_response': ['a', 'c'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are creating a Provisioned IOPS volume in AWS. The size of the volume is 10 GiB.Which of the following is the correct value that should be put for the IOPS of the volume?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180760, 'original_assessment_id': 2567162, 'section': 'EBS', 'prompt': {'explanation': '<p>50:1 is the maximum ratio of provisioned IOPS to requested volume size in Gibibyte (GiB).</p><p>So for instance, a 10 GiB volume can be provisioned with up to 500 IOPS. Any volume 640 GiB in size or greater allows provisioning up to the 32,000 IOPS maximum (50 &times; 640 GiB = 32,000).</p><p>&nbsp;</p><p><br />Resources:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': 'You are creating a Provisioned IOPS volume in AWS. The size of the volume is 10 GiB.<br><br>Which of the following is the correct value that should be put for the IOPS of the volume?', 'answers': ['400', '500', '600', '800']}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'In Amazon CloudTrail, where does it store all of the logs that it creates?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180774, 'original_assessment_id': 2567176, 'section': 'CloudTrail', 'prompt': {'explanation': '<p>CloudTrail is enabled on your AWS account when you create it. When activity occurs in your AWS account, that activity is recorded in a CloudTrail event. You can easily view events in the CloudTrail console by going to&nbsp;<strong>Event history</strong>.</p><p>Event history allows you to view, search, and download the past 90 days of supported activity in your AWS account. In addition, you can create a CloudTrail trail to further archive, analyze, and respond to changes in your AWS resources. A trail is a configuration that enables delivery of events to an Amazon S3 bucket that you specify. You can also deliver and analyze events in a trail with Amazon CloudWatch Logs and Amazon CloudWatch Events. You can create a trail with the CloudTrail console, the AWS CLI, or the CloudTrail API.</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/awscloudtrail/latest/userguide/how-cloudtrail-works.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/awscloudtrail/latest/userguide/how-cloudtrail-works.html</a></p><p><a href="https://aws.amazon.com/cloudtrail/" target="_blank" rel="noopener">https://aws.amazon.com/cloudtrail/</a></p><p>&nbsp;</p>', 'answers': ['DynamoDB', 'A RDS instance', 'Amazon Redshift', 'Amazon S3'], 'question': 'In Amazon CloudTrail, where does it store all of the logs that it creates?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are planning to build a highly available and secure architecture in AWS where you are using a fleet of EC2 instances. For security purposes, you want to ensure that you can control what type of traffic goes in and out of your instances. In AWS, what acts as a firewall that controls the traffic allowed to reach one or more instances?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180762, 'original_assessment_id': 2567164, 'section': 'Security', 'prompt': {'explanation': '<p>A&nbsp;<em>security group</em>&nbsp;acts as a virtual firewall for your instance to control inbound and outbound traffic. When you launch an instance in a VPC, you can assign up to five security groups to the instance. Security groups act at the instance level, not the subnet level. Therefore, each instance in a subnet in your VPC could be assigned to a different set of security groups. If you don\'t specify a particular group at launch time, the instance is automatically assigned to the default security group for the VPC.</p><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html</a></p><p>&nbsp;</p>', 'answers': ['Security group', 'ACL', 'IAM', 'Private IP Addresses', 'EBS'], 'question': 'You are planning to build a highly available and secure architecture in AWS where you are using a fleet of EC2 instances. For security purposes, you want to ensure that you can control what type of traffic goes in and out of your instances. <br /><br />In AWS, what acts as a firewall that controls the traffic allowed to reach one or more instances?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a major financial firm in Wall Street where you are tasked to design an application architecture for their online trading platform which should have high availability and fault tolerance. The application is using an Amazon S3 bucket located in the us-east-1 region to store large amounts of intraday financial data. To avoid any costly service disruptions, what will you do to ensure that the stored financial data in the S3 bucket would not be affected even if there is an outage in one of the Availability Zones or a regional service failure in us-east-1?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180764, 'original_assessment_id': 2567166, 'section': 'S3', 'prompt': {'explanation': '<p>In this scenario, you need to enable Cross-Region Replication to ensure that your S3 bucket would not be affected even if there is an outage in one of the Availability Zones or a regional service failure in us-east-1. When you upload your data in S3, your objects are redundantly stored on multiple devices across multiple facilities within the region only, where you created the bucket. Hence, if there is an outage on the entire region, your S3 bucket will be unavailable if you do not enable Cross-Region Replication, which should make your data available to another region.</p><p>Note that an Availability Zone (AZ) is more related with Amazon EC2 instances rather than Amazon S3 so if there is any outage in the AZ, the S3 bucket is usually not affected but only the EC2 instances deployed on that zone.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/s3/faqs/">https://aws.amazon.com/s3/faqs/</a></p><p>&nbsp;</p>', 'answers': ['Copy the S3 bucket to an EBS-backed EC2 instance.', 'Create a Lifecycle Policy to regularly backup the S3 bucket to Amazon Glacier.', 'Use AWS Storage Gateway to keep a backup of the data.', 'Do nothing since the S3 bucket can withstand an outage in one of the Availability Zones and even regional service failures.', 'Enable Cross-Region Replication.'], 'question': 'You are working for a major financial firm in Wall Street where you are tasked to design an application architecture for their online trading platform which should have high availability and fault tolerance. The application is using an Amazon S3 bucket located in the us-east-1 region to store large amounts of intraday financial data. <br /><br />To avoid any costly service disruptions, what will you do to ensure that the stored financial data in the S3 bucket would not be affected even if there is an outage in one of the Availability Zones or a regional service failure in us-east-1?'}, 'related_lectures': [], 'correct_response': ['e'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A popular augmented reality (AR) mobile game is heavily using a RESTful API which is hosted in AWS. The API uses Amazon API Gateway and a DynamoDB table with a preconfigured read and write capacity. Based on your systems monitoring, the DynamoDB table begins to throttle requests during high peak loads which causes the slow performance of the game.\xa0 Which of the following can you do to improve the performance of your app?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180766, 'original_assessment_id': 2567168, 'section': 'DynamoDB Auto Scaling', 'prompt': {'explanation': '<p>DynamoDB auto scaling uses the AWS Application Auto Scaling service to dynamically adjust provisioned throughput capacity on your behalf, in response to actual traffic patterns. This enables a table or a global secondary index to increase its provisioned read and write capacity to handle sudden increases in traffic, without throttling. When the workload decreases, Application Auto Scaling decreases the throughput so that you don\'t pay for unused provisioned capacity.</p> <p>Option 3 is the best answer. DynamoDB Auto Scaling uses the AWS Application Auto Scaling service to dynamically adjust provisioned throughput capacity on your behalf.</p> <p>Option 1 is incorrect because an Application Load Balancer is not suitable to be used with DynamoDB and in addition, this will not increase the throughput of your DynamoDB table.</p> <p>Option 2 is incorrect because you usually put EC2 instances on an Auto Scaling Group, and not a DynamoDB table.</p> <p>Option 4 is incorrect because this is not a design principle for high throughput DynamoDB table. Using SQS is for handling queuing and polling the request. This will not increase the throughput of DynamoDB which is required in this situation.</p> <p><strong>Reference: </strong></p> <p><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AutoScaling.html">https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AutoScaling.html</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>A popular augmented reality (AR) mobile game is heavily using a RESTful API which is hosted in AWS. The API uses Amazon API Gateway and a DynamoDB table with a preconfigured read and write capacity. Based on your systems monitoring, the DynamoDB table begins to throttle requests during high peak loads which causes the slow performance of the game.\xa0 </p><p>Which of the following can you do to improve the performance of your app?\xa0 </p>', 'answers': ['<p>Integrate an Application Load Balancer with your DynamoDB table.\xa0 </p>', '<p>Add the DynamoDB table to an Auto Scaling Group.\xa0 </p>', '<p>Use DynamoDB Auto Scaling\xa0 </p>', '<p>Create an SQS queue in front of the DynamoDB table.\xa0 </p>']}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'What type of monitoring for Amazon EBS volumes is free and available automatically in 5-minute periods?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180802, 'original_assessment_id': 2567206, 'section': 'EC2', 'prompt': {'explanation': '<p>CloudWatch metrics are statistical data that you can use to view, analyze, and set alarms on the operational behavior of your volumes. We have 2 types: Basic and Detailed. First, Basic is available automatically in 5-minute periods at no charge. This includes data for the root device volumes for EBS-backed instances. Detailed type automatically sends one-minute metrics to CloudWatch.</p><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-volume-status.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-volume-status.html</a></p><p>&nbsp;</p>', 'answers': ['Basic', 'Enterprise', 'Business', 'Detailed'], 'question': 'What type of monitoring for Amazon EBS volumes is free and available automatically in 5-minute periods?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'An online payment website is deployed in AWS as a distributed system of EC2 instances and a scalable SQS queue. Amazon SQS is a message queue service used by distributed applications to exchange messages through a polling model, and can be used to decouple sending and receiving components. \n\nWhich of the following is true regarding SQS message?', '_class': 'assessment', 'created': '2018-11-21T07:29:07Z', 'id': 6180708, 'original_assessment_id': 2567110, 'section': 'SQS', 'prompt': {'explanation': '<div> <p>In Amazon SQS, the standard queues provide at-least-once delivery, which means that each message is delivered at least once.</p> <p>FIFO queues provide exactly-once processing, which means that each message is delivered once and remains available until a consumer processes it and deletes it. Duplicates are not introduced into the queue.</p> <p>Amazon SQS messages can contain up to 256 KB of text data, including XML, JSON, and unformatted text.&nbsp;</p> </div> <div class="aws-text-box section"> <div class="  "> <p>You can configure the Amazon SQS message retention period to a value from 1 minute to 14 days. The default is 4 days. Once the message retention limit is reached, your messages are automatically deleted.</p> </div> </div> <div class="aws-text-box section">&nbsp;</div> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/sqs/faqs/">https://aws.amazon.com/sqs/faqs/</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>An online payment website is deployed in AWS as a distributed system of EC2 instances and a scalable SQS queue. Amazon SQS is a message queue service used by distributed applications to exchange messages through a polling model, and can be used to decouple sending and receiving components. </p>\n\n<p>Which of the following is true regarding SQS message?</p>', 'answers': ['SQS messages are guaranteed to be delivered at least once.', 'SQS messages must be less than 16 KB in size.', 'SQS messages must be in XML format.', 'SQS messages can live in the queue up to 30 days.']}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:29:07Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are a Solutions Architect working for a large multinational investment bank. They have a web application that requires a minimum of 4 EC2 instances to run to ensure that it can cater to its users across the globe. You are instructed to ensure fault tolerance of this system. Which of the following is the best option?', '_class': 'assessment', 'created': '2018-11-21T07:29:07Z', 'id': 6180710, 'original_assessment_id': 2567112, 'section': 'Highly Available Network Design', 'prompt': {'explanation': '<p>Fault Tolerance is the ability of a system to remain in operation even if some of the components used to build the system fail. In AWS, this means that in the event of server fault or system failures, the number of running EC2 instances should not fall below the minimum number of instances required by the system for it to work properly. So if the the application requires a minimum of 4 instances, there should be at least 4 instances running in case there is an outage in one of the Availability Zones or if there are server issues.&nbsp;</p> <p>One of the differences between Fault Tolerance&nbsp;and High Availability is that, the former refers to the minimum number of running instances. For example, you have a system that requires a minimum of 4 running instances and currently has 6 running instances deployed in two Availability Zones. There was a component failure in one of the Availability Zones which knocks out 3 instances. In this case, the system can still be regarded as Highly Available since there are still instances running that can accomodate the requests. However, it is not Fault Tolerant since the required minimum of four instances have not been met.</p> <p>As such, Option 1 is the correct answer because even if there was an outage in one of the Availability Zones, the system still satisfies the requirement of a minimum of 4 running instances.&nbsp;</p> <p>Option 2 is incorrect because if one Availability Zone went out, there will only be 2 running instances available.</p> <p>Option 3&nbsp;is incorrect because if the Availability Zone went out, there will be no running instance available to accommodate the request.</p> <p>Option 4&nbsp;is incorrect because if one Availability Zone went out, there will only be 3 instances available to accommodate the request.</p> <p>&nbsp;</p> <p><strong>References:</strong></p> <p><a href="https://media.amazonwebservices.com/AWS_Building_Fault_Tolerant_Applications.pdf">https://media.amazonwebservices.com/AWS_Building_Fault_Tolerant_Applications.pdf</a></p> <p><a href="https://media.amazonwebservices.com/architecturecenter/AWS_ac_ra_ftha_04.pdf">https://media.amazonwebservices.com/architecturecenter/AWS_ac_ra_ftha_04.pdf</a>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': 'You are a Solutions Architect working for a large multinational investment bank. They have a web application that requires a minimum of 4 EC2 instances to run to ensure that it can cater to its users across the globe. You are instructed to ensure fault tolerance of this system. <br><br>Which of the following is the best option?', 'answers': ['Deploy an Auto Scaling group with 2 instances in each of 3 Availability Zones behind an Application Load Balancer.', 'Deploy an Auto Scaling group with 2 instances in each of 2 Availability Zones behind an Application Load Balancer.', 'Deploy  an Auto Scaling group with 4 instances in one Availability Zone behind an Application Load Balancer.', 'Deploy an Auto Scaling group with 1 instance in each of 4 Availability Zones behind an Application Load Balancer.']}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:29:07Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are a Cloud Migration Engineer in a media company which uses EC2, ELB, and S3 for its video-sharing portal for filmmakers. They are using a standard S3 storage class to store all high-quality videos that are frequently accessed only during the first three months of posting. What should you do if the company needs to automatically transfer or archive media data from an S3 bucket to Glacier?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180788, 'original_assessment_id': 2567192, 'section': '', 'prompt': {'explanation': '<p>You can create a lifecycle policy in S3 to automatically transfer your data to Glacier.</p><p>Lifecycle configuration enables you to specify the lifecycle management of objects in a bucket. The configuration is a set of one or more rules, where each rule defines an action for Amazon S3 to apply to a group of objects.</p><p>These actions can be classified as follows:</p><ul><li><strong>Transition actions</strong>&nbsp;&ndash; In which you define when objects transition to another storage class. For example, you may choose to transition objects to the STANDARD_IA (IA, for infrequent access) storage class 30 days after creation, or archive objects to the GLACIER storage class one year after creation.</li><li><strong>Expiration actions</strong>&nbsp;&ndash; In which you specify when the objects expire. Then Amazon S3 deletes the expired objects on your behalf.</li></ul><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html">https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are a Cloud Migration Engineer in a media company which uses EC2, ELB, and S3 for its video-sharing portal for filmmakers. They are using a standard S3 storage class to store all high-quality videos that are frequently accessed only during the first three months of posting. What should you do if the company needs to automatically transfer or archive media data from an S3 bucket to Glacier?</p>', 'answers': ['Use a custom shell script that transfers data from the S3 bucket to Glacier', 'Use Lifecycle Policies', 'Use AWS SQS', 'Use AWS SWF']}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are working as a  Solutions Architect for a major supermarket store chain. They have an e-commerce application which is running in eu-east-2 region that strictly requires six EC2 instances running at all times. In that region, there are 3 Availability Zones (AZ) - eu-east-2a, eu-east-2b, and eu-east-2c that you can use. Which of the following deployments provide 100% fault tolerance if any single AZ in the region becomes unavailable? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:29:07Z', 'id': 6180712, 'original_assessment_id': 2567114, 'section': 'Highly Available Network Design', 'prompt': {'feedbacks': ['', '', '', '', '', ''], 'explanation': '<p>Fault Tolerance is the ability of a system to remain in operation even if some of the components used to build the system fail. In AWS, this means that in the event of server fault or system failures, the number of running EC2 instance should not fall below the minimum number of instances required by the system for it to work properly. So if the the application requires a minimum of 4 instances, there should be at least 4 instances running in case there is an outage in one of the Availability Zones or server issues.&nbsp;</p> <p><img src="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/images/tutorial_as_elb_architecture.png" alt="" width="471" height="399" /></p> <p>In this scenario, you have to simulate a situation where one Availability Zone became unavailable for each option and check whether it still has 6 running instances. Hence, the correct answers are Options 4 and 5 because even if there is an outage in one of the Availability Zones, there are still 6 running instances:</p> <ol> <li>eu-east-2a with six EC2 instances, eu-east-2b with six EC2 instances, and eu-east-2c with no EC2 instances</li> <li>eu-east-2a with three EC2 instances, eu-east-2b with three EC2 instances, and eu-east-2c with three EC2 instances</li> </ol> <p><strong>Reference:</strong></p> </div> <p><a href="https://media.amazonwebservices.com/AWS_Building_Fault_Tolerant_Applications.pdf">https://media.amazonwebservices.com/AWS_Building_Fault_Tolerant_Applications.pdf</a></p>', 'relatedLectureIds': '', 'answers': ['<p>eu-east-2a with two EC2 instances, eu-east-2b with four EC2 instances, and eu-east-2c with two EC2 instances</p>', 'eu-east-2a with two EC2 instances, eu-east-2b with two EC2 instances, and eu-east-2c with two EC2 instances', 'eu-east-2a with four EC2 instances, eu-east-2b with two EC2 instances, and eu-east-2c with two EC2 instances', 'eu-east-2a with six EC2 instances, eu-east-2b with six EC2 instances, and eu-east-2c with no EC2 instances', 'eu-east-2a with three EC2 instances, eu-east-2b with three EC2 instances, and eu-east-2c with three EC2 instances', '<p>eu-east-2a with twelve EC2 instances, eu-east-2b with three EC2 instances, and eu-east-2c with two EC2 instances</p>'], 'question': 'You are working as a  Solutions Architect for a major supermarket store chain. They have an e-commerce application which is running in eu-east-2 region that strictly requires six EC2 instances running at all times. In that region, there are 3 Availability Zones (AZ) - eu-east-2a, eu-east-2b, and eu-east-2c that you can use. <br><br>Which of the following deployments provide 100% fault tolerance if any single AZ in the region becomes unavailable? (Choose 2)'}, 'related_lectures': [], 'correct_response': ['d', 'e'], 'updated': '2018-11-21T07:29:12Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are mentoring a junior DevOps engineer on how to properly set up a cloud architecture in AWS using EC2, EBS, S3 and CloudFormation. The junior engineer asked you about the security features of AWS and the services that can be used to safeguard the architecture. He specifically asked which feature in AWS acts as a firewall that controls the traffic allowed to reach one or more EC2 instances. \n\nWhich of the following items is the correct answer to his question?', '_class': 'assessment', 'created': '2018-11-21T07:29:07Z', 'id': 6180714, 'original_assessment_id': 2567116, 'section': 'VPC', 'prompt': {'explanation': '<p>Option 1 is the correct answer. A <strong><em>security group</em></strong> acts as a virtual firewall that controls the traffic for one or more instances. When you launch an instance, you associate one or more security groups with the instance. You add rules to each security group that allow traffic to or from its associated instances.</p> <p>You can modify the rules for a security group at any time; the new rules are automatically applied to all instances that are associated with the security group.</p> <p>Option 2 is incorrect because NACL (Network Access Control List) acts as a firewall for associated subnets, controlling both inbound and outbound traffic at the subnet level and not on the instance level.</p> <p>The following diagram illustrates the layers of security provided by security groups and network ACLs:</p> <p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://udemy-images.s3.amazonaws.com/redactor/raw/2018-11-12_22-36-16-254993281d899a46691e16f4ecb6848c.png" /></p> <p>Option 3 is incorrect as IAM is mainly used to enable you to manage access to AWS services and resources securely.&nbsp;</p> <p>Option 4 is incorrect because the scenario has nothing to do with Private IP Addresses.</p> <p><strong>References:</strong></p> <p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-network-security.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-network-security.html</a></p> <p><a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Security.html#VPC_Security_Comparison">https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Security.html#VPC_Security_Comparison</a></p> <p><a href="https://aws.amazon.com/iam/">https://aws.amazon.com/iam/</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are mentoring a junior DevOps engineer on how to properly set up a cloud architecture in AWS using EC2, EBS, S3 and CloudFormation. The junior engineer asked you about the security features of AWS and the services that can be used to safeguard the architecture. He specifically asked which feature in AWS acts as a firewall that controls the traffic allowed to reach one or more EC2 instances. </p>\n\n<p>Which of the following items is the correct answer to his question?</p>', 'answers': ['Security group', 'NACL', 'IAM', 'Private IP Addresses']}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:29:53Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A Fortune 500 company which has numerous offices and customers around the globe has hired you as their Principal Architect. You have staff and customers that upload gigabytes to terabytes of data to a centralized S3 bucket from the regional data centers, across continents, all over the world on a regular basis. At the end of the financial year, there are thousands of data being uploaded to the central S3 bucket which is in ap-southeast-2 (Sydney) region and a lot of employees are starting to complain about the slow upload times. You were instructed by the CTO to resolve this issue as soon as possible to avoid any delays in processing their global end of financial year (EOFY) reports.    Which feature in Amazon S3 enables fast, easy, and secure transfer of your files over long distances between your client and your Amazon S3 bucket?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180768, 'original_assessment_id': 2567170, 'section': 'S3', 'prompt': {'explanation': '<p>Amazon S3 Transfer Acceleration enables fast, easy, and secure transfer of files over long distances between your client and your Amazon S3 bucket. Transfer Acceleration leverages Amazon CloudFront\'s globally distributed AWS Edge Locations. As data arrives at an AWS Edge Location, data is routed to your Amazon S3 bucket over an optimized network path.</p> <p>&nbsp;</p> <p><strong>Reference:&nbsp;</strong></p> <p><a href="https://aws.amazon.com/s3/faqs/">https://aws.amazon.com/s3/faqs/</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>A Fortune 500 company which has numerous offices and customers around the globe has hired you as their Principal Architect. You have staff and customers that upload gigabytes to terabytes of data to a centralized S3 bucket from the regional data centers, across continents, all over the world on a regular basis. At the end of the financial year, there are thousands of data being uploaded to the central S3 bucket which is in ap-southeast-2 (Sydney) region and a lot of employees are starting to complain about the slow upload times. You were instructed by the CTO to resolve this issue as soon as possible to avoid any delays in processing their global end of financial year (EOFY) reports.    </p><p>Which feature in Amazon S3 enables fast, easy, and secure transfer of your files over long distances between your client and your Amazon S3 bucket?</p>', 'answers': ['Reduced Redundancy Storage (RRS)', 'Cross-Region Replication', 'Transfer Acceleration', 'Multipart Upload', '<p>Enhanced Networking</p>', '<p>Pre-signed URLs</p>']}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You were promoted to a Senior Solutions Architect in a Casino &amp; Gambling Chain which has multiple operations globally. Your initial project is to launch an online training portal for the new hires which allows them to view the training materials applicable for their roles. You were advised that the architecture you will set up for the online portal will also be used on other VPCs owned by the company. Hence, you are looking for a solution that will allow you to use a simple text to model and automatically provision all the AWS resources needed for the portal.\xa0 \xa0Which service can you use to satisfy the requirements?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180770, 'original_assessment_id': 2567172, 'section': '', 'prompt': {'explanation': '<p>AWS CloudFormation provides a common language for you to describe and provision all the infrastructure resources in your cloud environment. CloudFormation allows you to use a simple text file to model and provision, in an automated and secure manner, all the resources needed for your applications across all regions and accounts. This file serves as the single source of truth for your cloud environment. AWS CloudFormation is available at no additional charge, and you pay only for the AWS resources needed to run your applications.</p><p>&nbsp;</p><p>Resources:</p><p><a href="https://aws.amazon.com/cloudformation/">https://aws.amazon.com/cloudformation/</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You were promoted to a Senior Solutions Architect in a Casino &amp; Gambling Chain which has multiple operations globally. Your initial project is to launch an online training portal for the new hires which allows them to view the training materials applicable for their roles. You were advised that the architecture you will set up for the online portal will also be used on other VPCs owned by the company. Hence, you are looking for a solution that will allow you to use a simple text to model and automatically provision all the AWS resources needed for the portal.\xa0 \xa0</p><p>Which service can you use to satisfy the requirements? </p>', 'answers': ['Amazon Simple Workflow Service', 'AWS Elastic Beanstalk', 'AWS CloudFormation', 'AWS OpsWorks', '<p>AWS Managed Services</p>', '<p>Amazon API Gateway</p>']}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have a web-based order processing system which is currently using a queue in Amazon SQS. The support team noticed that there are a lot of cases where an order was processed twice. This issue has caused a lot of trouble in your processing and made your customers very unhappy. Your IT Manager has asked you to ensure that this issue does not happen again. What can you do to prevent this from happening again in the future?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180772, 'original_assessment_id': 2567174, 'section': 'SWF', 'prompt': {'explanation': '<p>The main issue here is that the order management system produces duplicate orders at times. Since the company is using SQS, there is a possibility that a message can have a duplicate in case an EC2 instance failed to delete the already processed message.&nbsp;To prevent this issue from happening, you have to use Amazon Simple Workflow service instead of SQS.</p> <p>For standard queues, the visibility timeout isn\'t a guarantee against receiving a message twice. Hence, Option 2 is incorrect. To avoid duplicate SQS messages, it is better to design your applications to be&nbsp;<em>idempotent</em>&nbsp;(they should not be affected adversely when processing the same message more than once).</p> <p>Amazon SWF helps developers build, run, and scale background jobs that have parallel or sequential steps. You can think of Amazon SWF as a fully-managed state tracker and task coordinator in the Cloud. If your app\'s steps take more than 500 milliseconds to complete, you need to track the state of processing, and you need to recover or retry if a task fails.</p> <p>&nbsp;</p> <p><strong>References:&nbsp;</strong></p> <p><a href="https://aws.amazon.com/swf/">https://aws.amazon.com/swf/</a></p> <p><a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html">https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': 'You have a web-based order processing system which is currently using a queue in Amazon SQS. The support team noticed that there are a lot of cases where an order was processed twice. This issue has caused a lot of trouble in your processing and made your customers very unhappy. Your IT Manager has asked you to ensure that this issue does not happen again. <br><br>What can you do to prevent this from happening again in the future?', 'answers': ['Alter the retention period in Amazon SQS.', 'Alter the visibility timeout of SQS.', 'Replace Amazon SQS and instead, use Amazon Simple Workflow service.', 'Change the message size in SQS.']}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as a Junior Solutions Architect where you are responsible in enhancing the availability and durability of the database instances in your VPC.\xa0 Your company has a Multi-AZ RDS instance in the ap-northeast-1 region. If a storage volume on the primary instance fails in a Multi-AZ deployment, Amazon RDS automatically initiates a failover to the up-to-date standby instance.\xa0 \xa0In case of a failover, which record in Route 53 is changed?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180776, 'original_assessment_id': 2567178, 'section': 'RDS', 'prompt': {'explanation': '<p>Failover is automatically handled by Amazon RDS so that you can resume database operations as quickly as possible without administrative intervention. When failing over, Amazon RDS simply flips the canonical name record (CNAME) in Route53 for your DB instance to point at the standby, which in turn is promoted to become the new primary.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/rds/faqs/">https://aws.amazon.com/rds/faqs/</a></p><p>&nbsp;</p>', 'feedbacks': ['', '', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are working as a Junior Solutions Architect where you are responsible in enhancing the availability and durability of the database instances in your VPC.\xa0 Your company has a Multi-AZ RDS instance in the ap-northeast-1 region. If a storage volume on the primary instance fails in a Multi-AZ deployment, Amazon RDS automatically initiates a failover to the up-to-date standby instance.\xa0 \xa0</p><p>In case of a failover, which record in Route 53 is changed?</p>', 'answers': ['<p>CAA</p>', 'CNAME', 'TXT', 'MX', '<p>A</p>', '<p>NS</p>']}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are working as an AWS Cloud Engineer in the Infrastructure department of a government agency where you are handling their public transportation planning app and website. Being knowledgeable with AWS best practices, you know that redundancy is a must to ensure the reliability of the cloud architecture in case of infrastructure issues.\xa0 \xa0Which AWS services should you use to ensure a fault-tolerant and highly available architecture? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180778, 'original_assessment_id': 2567182, 'section': 'Highly Available Network Design', 'prompt': {'explanation': '<p>EC2 instances placed in different Availability Zones are both logically and physically separated, and they provide an easy-to-use model for deploying your application across data centers for both high availability and reliability.&nbsp;</p> <p>Elastic Load Balancers (ELB) allow you to spread load across multiple Availability Zones and Amazon EC2 Auto Scaling groups for redundancy and decoupling of services. It&nbsp;provides high availability such that if one of its Availability Zones failed, it can direct the request to another healthy Availability Zone to avoid any down time.</p> <p><strong>References:</strong></p> <p><a href="https://d0.awsstatic.com/whitepapers/aws-web-hosting-best-practices.pdf">https://d0.awsstatic.com/whitepapers/aws-web-hosting-best-practices.pdf</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are working as an AWS Cloud Engineer in the Infrastructure department of a government agency where you are handling their public transportation planning app and website. Being knowledgeable with AWS best practices, you know that redundancy is a must to ensure the reliability of the cloud architecture in case of infrastructure issues.\xa0 \xa0</p><p>Which AWS services should you use to ensure a fault-tolerant and highly available architecture? (Choose 2)\xa0 </p>', 'answers': ['Amazon DynamoDB', 'Amazon Elastic Compute Cloud (EC2)', 'Amazon Elastic Load Balancing', 'Amazon Simple Notification Service (SNS)', 'Amazon Simple Storage Service (S3)', '<p>Amazon Certificate Manager </p>']}, 'related_lectures': [], 'correct_response': ['b', 'c'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have a fleet of Amazon EC2 Linux instances created in your Auto Scaling group. You have a custom shell script that needs to be deployed to all of your EC2 instances. Which AWS feature allows you to accomplish this?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180780, 'original_assessment_id': 2567184, 'section': 'EC2', 'prompt': {'explanation': '<p>For this scenario, you can use the <code>User data</code> to add the custom shell script.</p><p>When you launch an instance in Amazon EC2, you have the option of passing <code>User data</code>  to the instance, which can be used to perform common automated configuration tasks and even run scripts after the instance starts. You can pass two types of <code>User data</code> to Amazon EC2: shell scripts and cloud-init directives. You can also pass this data into the launch wizard as plain text, as a file (this is useful for launching instances using the command line tools), or as base64-encoded text (for API calls).</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/user-data.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/user-data.html</a></p><p>&nbsp;</p>', 'answers': ['User data', 'EC2Config service', 'Instance Metadata', 'AWS Config'], 'question': 'You have a fleet of Amazon EC2 Linux instances created in your Auto Scaling group. You have a custom shell script that needs to be deployed to all of your EC2 instances. <br /><br />Which AWS feature allows you to accomplish this?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are managing a global news website which is deployed to AWS and is using MySQL RDS. The website has millions of viewers from all over the world which means that the website has read-heavy database workloads. In this scenario, which of the following is the best option to use to increase the read throughput on the MySQL database?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180782, 'original_assessment_id': 2567186, 'section': 'RDS', 'prompt': {'explanation': '<div><p>Amazon RDS Read Replicas provide enhanced performance and durability for database (DB) instances. This feature makes it easy to elastically scale out beyond the capacity constraints of a single DB instance for read-heavy database workloads. You can create one or more replicas of a given source DB Instance and serve high-volume application read traffic from multiple copies of your data, thereby increasing aggregate read throughput. Read replicas can also be promoted when needed to become standalone DB instances. Read replicas are available in Amazon RDS for MySQL, MariaDB, and PostgreSQL as well as Amazon Aurora.</p><p>Option 1 is incorrect because the Multi-AZ deployments feature is mainly used to achieve high availability and failover support for your database.</p><p>Option 2 is incorrect because a Standby replica is used in&nbsp;Multi-AZ deployments and hence, it is not a solution to&nbsp;reduce read-heavy database workloads.</p><p>Option 4 is incorrect because although an SQS queue can effectively manage the requests, it won\'t be able to entirely improve the read-throughput of the database by itself.</p><p>&nbsp;</p></div><p>References:</p><p><a href="https://aws.amazon.com/rds/details/read-replicas/">https://aws.amazon.com/rds/details/read-replicas/</a></p><p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are managing a global news website which is deployed to AWS and is using MySQL RDS. The website has millions of viewers from all over the world which means that the website has read-heavy database workloads. <br><br>In this scenario, which of the following is the best option to use to increase the read throughput on the MySQL database?</p>', 'answers': ['Enable Multi-AZ deployments', 'Enable Amazon RDS Standby Replicas', 'Enable Amazon RDS Read Replicas', 'Use SQS to queue up the requests']}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are a Big Data Engineer who is assigned to handle the online enrollment system database of a prestigious university, which is hosted in RDS. You are required to monitor the database metrics in Amazon CloudWatch to ensure the availability of the enrollment system. What are the basic monitoring metrics Amazon CloudWatch provides for Amazon RDS DB instances? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180784, 'original_assessment_id': 2567188, 'section': 'CloudWatch', 'prompt': {'explanation': '<p>CloudWatch provides a lot of metrics for the Amazon RDS database instance. Please check the&nbsp;Amazon RDS Metrics table from the reference link below for the complete list. Here are some of the metrics available:</p><ul><li>-The amount of available random access memory.</li><li>-The average number of disk I/O operations per second during the polling period.</li><li>-The percentage of CPU utilization</li></ul><p>&nbsp;</p><p>Option 4 is incorrect as this is a metric provided by Enhanced Monitoring.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/rds-metricscollected.html">https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/rds-metricscollected.html</a></p><p><a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Monitoring.OS.html#USER_Monitoring.OS.CloudWatchLogs">https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Monitoring.OS.html#USER_Monitoring.OS.CloudWatchLogs</a></p><p>&nbsp;</p>', 'feedbacks': ['', '', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are a Big Data Engineer who is assigned to handle the online enrollment system database of a prestigious university, which is hosted in RDS. You are required to monitor the database metrics in Amazon CloudWatch to ensure the availability of the enrollment system. </p><p>What are the basic monitoring metrics Amazon CloudWatch provides for Amazon RDS DB instances? (Choose 3)</p>', 'answers': ['The amount of available random access memory.', 'The average number of disk I/O operations per second during the polling period.', 'The percentage of CPU utilization.', 'RDS child processes.', '<p>The maximum amount of throughput </p>', '<p>RDS triggers</p>']}, 'related_lectures': [], 'correct_response': ['a', 'b', 'c'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are a Solutions Architect working for a large multi-national bank in the Asia-Pacific region. You designed an application architecture that is deployed to AWS, which has four Reserved EC2 instances. To be able to securely and easily manage these instances, you created a bastion host in your VPC. When your CTO found out, he was concerned and asked you about what you have done.How will you describe what a bastion host is to your boss?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180786, 'original_assessment_id': 2567190, 'section': 'VPC', 'prompt': {'explanation': '<p>A bastion host is basically an EC2 instance in the public subnet of your VPC and is typically accessed using SSH or RDP,&nbsp;which are used as a jump server to other EC2 instances and other AWS resources within other subnets.&nbsp;A bastion is a special purpose server instance that is designed to be the primary access point from the Internet and acts as a proxy to your other EC2 instances which are preferably deployed in a private subnet.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/blogs/security/controlling-network-access-to-ec2-instances-using-a-bastion-server/" target="_blank" rel="noopener">https://aws.amazon.com/blogs/security/controlling-network-access-to-ec2-instances-using-a-bastion-server/</a></p>', 'answers': ['A bastion host is an EC2 instance in a private subnet of your VPC and is typically accessed using SSH or RDP. Once remote connectivity has been established with the bastion host, it then acts as a ‘jump’ server that allows you to use SSH or RDP to log into other EC2 instances deployed in public subnets.', 'A bastion host is an EC2 instance in a public subnet of your VPC and is typically accessed using SSH or RDP. Once remote connectivity has been established with the bastion host, it then acts as a ‘jump’ server, allowing you to use HTTPS to log into other EC2 instances deployed in private subnets.', 'A bastion host is an EC2 instance in a public subnet of your VPC and is typically accessed using SSH or RDP. Once remote connectivity has been established with a bastion host, it then acts as a ‘jump’ server, allowing you to use SSH or RDP to log into other EC2 instances deployed in private subnets.', "A bastion host is an EC2 instance in a private subnet of your VPC and is typically accessed using SSH or RDP. Once remote connectivity has been established with the bastion host, it then acts as a 'jump' server,  allowing you to use HTTPS to log into other EC2 instances deployed in public subnets."], 'question': 'You are a Solutions Architect working for a large multi-national bank in the Asia-Pacific region. You designed an application architecture that is deployed to AWS, which has four Reserved EC2 instances. To be able to securely and easily manage these instances, you created a bastion host in your VPC. When your CTO found out, he was concerned and asked you about what you have done.<br /><br />How will you describe what a bastion host is to your boss?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'What is the difference between an Availability Zone and an Edge location?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180790, 'original_assessment_id': 2567194, 'section': 'EC2', 'prompt': {'explanation': '<p>The correct answer is option 3: An Availability Zone is an Amazon resource within an AWS region while an Edge location is used to deliver cached content to the closest location to reduce latency.</p><p>Amazon EC2 is hosted in multiple locations world-wide. These locations are composed of regions and Availability Zones. Each&nbsp;<em>region</em>&nbsp;is a separate geographic area. Each region has multiple, isolated locations known as&nbsp;<strong>Availability Zones</strong>.</p><p>Edge locations are used by the Amazon CloudFront service. It delivers your content through a worldwide network of data centers called <strong>edge locations</strong>.&nbsp;</p><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html</a></p><p><a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html">https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html</a></p><p>&nbsp;</p><p>&nbsp;</p>', 'answers': ['Edge locations are used as central control stations for your AWS resources deployed on all regions.', 'An edge location is used as a link when building load balancing between regions', 'An Availability Zone is an Amazon resource within an AWS region while an Edge location is used to deliver cached content to the closest location to reduce latency.', 'An availability zone is a grouping of AWS resources in a specific region while an edge location is a specific resource within the AWS region'], 'question': 'What is the difference between an Availability Zone and an Edge location?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are a Software Architect of an oil and gas company. You are designing a web application architecture utilizing EC2 instances with Elastic Load Balancing. In this scenario, what items do you need to consider in order to determine the instance size required for your application? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180792, 'original_assessment_id': 2567196, 'section': 'EC2', 'prompt': {'explanation': '<p>Amazon EC2 provides a wide selection of instance types optimized to fit different use cases. Instance types comprise varying combinations of CPU, memory, storage, and networking capacity and give you the flexibility to choose the appropriate mix of resources for your applications. Each instance type includes one or more instance sizes, allowing you to scale your resources to the requirements of your target workload.</p><p>Hence, in this scenario, you have to consider the required CPU utilization, I/O operations, and the minimum memory requirements of your web application in order to determine which type of instance is most suitable.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/ec2/instance-types/">https://aws.amazon.com/ec2/instance-types/</a></p><p>&nbsp;</p><p>&nbsp;</p>', 'answers': ['Consider the required I/O operations of your web application.', 'Consider the minimum memory requirements of your web application.', 'Consider where the client intends to serve most of the traffic.', "Consider the peak expected usage for a client's application.", 'Consider if the application requires a container service such as Docker or Kubernetes.'], 'question': 'You are a Software Architect of an oil and gas company. You are designing a web application architecture utilizing EC2 instances with Elastic Load Balancing. In this scenario, what items do you need to consider in order to determine the instance size required for your application? (Choose 2)'}, 'related_lectures': [], 'correct_response': ['a', 'b'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a large media company that has a single 3-TB volume storage on their on-premises network that is used to hold their digital footages, films, and other files. The storage is growing at 500 GB a year and must be presented as a single logical volume. The company is becoming increasingly constrained with their local storage capacity and wants an off-site backup of this data, while maintaining low-latency access to their frequently accessed data. Which AWS Storage Gateway configuration meets the customer requirements?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180794, 'original_assessment_id': 2567198, 'section': 'Storage Gateway', 'prompt': {'explanation': '<p>In Cached volumes, you store your data in Amazon Simple Storage Service (Amazon S3) and retain a copy of frequently accessed data subsets locally. Cached volumes offer substantial cost savings on primary storage and minimize the need to scale your storage on-premises. You also retain low-latency access to your frequently accessed data.</p><p>&nbsp;</p><p>Resources:</p><p><a href="http://docs.aws.amazon.com/storagegateway/latest/userguide/storage-gateway-cached-concepts.html">http://docs.aws.amazon.com/storagegateway/latest/userguide/storage-gateway-cached-concepts.html</a></p><p>&nbsp;</p>', 'answers': ['AWS Storage Gateway - Cached volumes with snapshots scheduled to Amazon S3', 'AWS Storage Gateway - Stored volumes with snapshots scheduled to Amazon S3', 'AWS Storage Gateway - Virtual Tape Library with snapshots to Amazon S3', 'AWS Storage Gateway - Virtual Tape Library with snapshots to Amazon Glacier'], 'question': 'You are working for a large media company that has a single 3-TB volume storage on their on-premises network that is used to hold their digital footages, films, and other files. The storage is growing at 500 GB a year and must be presented as a single logical volume. The company is becoming increasingly constrained with their local storage capacity and wants an off-site backup of this data, while maintaining low-latency access to their frequently accessed data. <br /><br />Which AWS Storage Gateway configuration meets the customer requirements?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a large global media company with multiple office locations all around the world. You are instructed to build a system to distribute training videos to all employees. Using CloudFront, what method would be used to serve content that is stored in S3, but not publicly accessible from S3 directly?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180796, 'original_assessment_id': 2567200, 'section': 'CloudFront', 'prompt': {'feedbacks': ['', '', '', ''], 'explanation': '<p>When you create or update a distribution in Cloudfront, you can add an origin access identity (OAI) and automatically update the bucket policy to give the origin access identity&nbsp;permission to access your bucket. Alternatively, you can choose to manually change the bucket policy or change ACLs, which control permissions on individual objects in your bucket.</p><p>You can update the Amazon S3 bucket policy using either the AWS Management Console or the Amazon S3 API:</p><ul><li>-Grant the CloudFront origin access identity the applicable permissions on the bucket.</li><li>-Deny access to anyone that you don\'t want to have access using Amazon S3 URLs.</li></ul><br /><p>Resources:</p><p><a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-restricting-access-to-s3.html#private-content-granting-permissions-to-oai">https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-restricting-access-to-s3.html#private-content-granting-permissions-to-oai</a></p>', 'relatedLectureIds': '', 'answers': ['Create an Origin Access Identity (OAI) for CloudFront and grant access to the objects in your S3 bucket to that OAI.', 'Create an Identity and Access Management (IAM) user for CloudFront and grant access to the objects in your S3 bucket to that IAM user.', '<p>Create an S3 bucket policy that lists the CloudFront distribution ID as the principal and the target bucket as the Amazon Resource Name (ARN).</p>', 'Add the CloudFront account security group.'], 'question': 'You are working for a large global media company with multiple office locations all around the world. You are instructed to build a system to distribute training videos to all employees. Using CloudFront, what method would be used to serve content that is stored in S3, but not publicly accessible from S3 directly?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:31:11Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Which AWS service can mitigate Distributed Denial of Service (DDoS) attacks from hitting your back-end EC2 instances?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180814, 'original_assessment_id': 2567218, 'section': 'CloudFront', 'prompt': {'explanation': '<p>Amazon CloudFront is a content delivery network (CDN) service that can be used to deliver your entire website, including static, dynamic, streaming, and interactive content. Persistent TCP connections and variable time-to-live (TTL) can be used to accelerate delivery of content, even if it cannot be cached at an edge location.</p><p>This allows you to use Amazon CloudFront to protect your web application, even if you are not serving static content. Amazon CloudFront only accepts well-formed connections to prevent many common DDoS attacks like SYN floods and UDP reflection attacks from reaching your origin. DDoS attacks are geographically isolated close to the source, which prevents the traffic from affecting other locations. These capabilities can greatly improve your ability to continue serving traffic to end users during larger DDoS attacks. You can use Amazon CloudFront to protect an origin on AWS or elsewhere on the Internet.</p><p>&nbsp;</p><p>Resources:</p><p><a href="https://d0.awsstatic.com/whitepapers/DDoS_White_Paper_June2015.pdf">https://d0.awsstatic.com/whitepapers/DDoS_White_Paper_June2015.pdf</a></p>', 'answers': ['CloudWatch', 'CloudFront', 'CloudTrail', 'Kinesis'], 'question': 'Which AWS service can mitigate Distributed Denial of Service (DDoS) attacks from hitting your back-end EC2 instances? '}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Your company wants to host a static website on Amazon S3 using a bucket named "tutorialsdojo" in the Asia Pacific (Sydney) region. What website URL will be assigned to the S3 bucket?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180798, 'original_assessment_id': 2567202, 'section': 'S3', 'prompt': {'explanation': '<p>To host a static website, you configure an Amazon S3 bucket for website hosting, and then upload your website content to the bucket. The website is then available at the AWS Region-specific website endpoint of the bucket, which is in one of the following formats:</p><p style="padding-left: 30px;"><em><strong>&lt;bucket-name&gt;</strong></em>.s3-website-<em><strong>&lt;AWS-region&gt;</strong></em>.amazonaws.com</p><p>Hence, the correct answer is option A:</p><p style="padding-left: 30px;"><a href="http://tutorialsdojo.s3-website-ap-southeast-2.amazonaws.com" target="_blank" rel="noopener">tutorialsdojo.s3-website-ap-southeast-2.amazonaws.com</a></p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html">https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html</a></p><p>&nbsp;</p>', 'answers': ['tutorialsdojo.s3-website-ap-southeast-2.amazonaws.com', 'ap-southeast-2.s3-website-tutorialsdojo.amazonaws.com', 'tutorialsdojo.s3-website-ap-southeast-2.amazon.aws.com', 'ap-southeast-2.s3-website-tutorialsdojo.amazon.aws.com'], 'question': 'Your company wants to host a static website on Amazon S3 using a bucket named "tutorialsdojo" in the Asia Pacific (Sydney) region. What website URL will be assigned to the S3 bucket?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'An application is using a RESTful API hosted in AWS which uses Amazon API Gateway and AWS Lambda. There is a requirement to trace and analyze user requests as they travel through your Amazon API Gateway APIs to the underlying services.\xa0 Which of the following is the most suitable service to use to meet this requirement?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180800, 'original_assessment_id': 2567204, 'section': 'AWS X-Ray', 'prompt': {'feedbacks': ['', '', '', ''], 'explanation': '<p>You can use&nbsp;<a href="https://docs.aws.amazon.com/xray/latest/devguide/xray-services-apigateway.html" target="_blank" rel="noopener">AWS X-Ray</a>&nbsp;to trace and analyze user requests as they travel through your Amazon API Gateway APIs to the underlying services. API Gateway supports AWS X-Ray tracing for all API Gateway endpoint types: regional, edge-optimized, and private. You can use AWS X-Ray with Amazon API Gateway in all regions where X-Ray is available.</p> <p>X-Ray gives you an end-to-end view of an entire request, so you can analyze latencies in your APIs and their backend services. You can use an X-Ray service map to view the latency of an entire request and that of the downstream services that are integrated with X-Ray. And you can configure sampling rules to tell X-Ray which requests to record, at what sampling rates, according to criteria that you specify. If you call an API Gateway API from a service that\'s already being traced, API Gateway passes the trace through, even if X-Ray tracing is not enabled on the API.</p> <p>You can enable X-Ray for an API stage by using the API Gateway management console, or by using the API Gateway API or CLI.</p> <p>&nbsp;</p> <p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://docs.aws.amazon.com/apigateway/latest/developerguide/images/apigateway-xray-traceview-1.png" alt="" width="750" height="326" /></p> <p>&nbsp;</p> <p>Option 1 is incorrect because VPC Flow Logs&nbsp;is a feature that enables you to capture information about the IP traffic going to and from network interfaces in your entire VPC. Although it can capture some details about the incoming user requests, it is still better to use AWS X-Ray as it provides a better way to debug and analyze your microservices applications with request tracing so you can find the root cause of your issues and performance.</p> <p>Option 2 is incorrect because CloudWatch is a monitoring and management service. It does not have the capability&nbsp;to trace and analyze user requests as they travel through your Amazon API Gateway APIs.</p> <p>Option 3 is incorrect because CloudTrail is primarily used for&nbsp;API logging of all of your AWS resources.</p> <p><strong>Reference:</strong></p> <p><a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-xray.html">https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-xray.html</a></p> <p>&nbsp;</p>', 'relatedLectureIds': '', 'answers': ['<p>VPC Flow Logs</p>', '<p>CloudWatch</p>', '<p>CloudTrail</p>', '<p>AWS X-Ray</p>'], 'question': '<p>An application is using a RESTful API hosted in AWS which uses Amazon API Gateway and AWS Lambda. There is a requirement to trace and analyze user requests as they travel through your Amazon API Gateway APIs to the underlying services.\xa0 </p><p>Which of the following is the most suitable service to use to meet this requirement?</p>'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:33:11Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are using an On-Demand EC2 instance to host a legacy web application that uses an Amazon Instance Store-Backed AMI. The web application should be decommissioned as soon as possible and hence, you need to terminate the EC2 instance. When the instance is terminated, what happens to the data on the root volume?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180804, 'original_assessment_id': 2567208, 'section': 'AMI', 'prompt': {'explanation': '<p>AMIs are categorized as either&nbsp;<em>backed by Amazon EBS</em>&nbsp;or&nbsp;<em>backed by instance store</em>. The former means that the root device for an instance launched from the AMI is an Amazon EBS volume created from an Amazon EBS snapshot. The latter means that the root device for an instance launched from the AMI is an instance store volume created from a template stored in Amazon S3.</p><p>Option 4 is the correct answer because the data on instance store volumes persist only during the life of the instance which means that if the instance is terminated, the data will be automatically deleted.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ComponentsAMIs.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ComponentsAMIs.html</a></p><p>&nbsp;</p>', 'answers': ['Data is automatically saved as an EBS snapshot.', 'Data is automatically saved as an EBS volume.', 'Data is unavailable until the instance is restarted.', 'Data is automatically deleted.'], 'question': 'You are using an On-Demand EC2 instance to host a legacy web application that uses an Amazon Instance Store-Backed AMI. The web application should be decommissioned as soon as possible and hence, you need to terminate the EC2 instance. <br /><br />When the instance is terminated, what happens to the data on the root volume?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a large bank that is developing a web application that receives large amounts of object data. They are using the data to generate a report for their stockbrokers to use on a daily basis. Unfortunately, a recent financial crisis has left the bank short on cash and cannot afford to purchase expensive storage hardware. They had resorted to use AWS instead. Which is the best service to use in order to store a virtually unlimited amount of object data without any effort to scale when demand unexpectedly increases?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180806, 'original_assessment_id': 2567210, 'section': 'S3', 'prompt': {'explanation': '<p>In this scenario, you can use Amazon S3 and Amazon Glacier as a storage service. And since we are looking for the best option, we have to consider that the object data being stored by the bank is used on a daily basis as well. Hence, Amazon S3 is the better choice as it provides&nbsp;frequent access to your object data.&nbsp;</p> <p>Amazon S3 is a durable, secure, simple, and fast storage service designed to make web-scale computing easier for developers. Use Amazon S3 if you need low latency or frequent access to your data. Use Amazon Glacier if low storage cost is paramount, and you do not require millisecond access to your data.</p> <p>&nbsp;</p> <p>&nbsp;Resources:</p> <p><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/Welcome.html">http://docs.aws.amazon.com/AmazonS3/latest/dev/Welcome.html</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are working for a large bank that is developing a web application that receives large amounts of object data. They are using the data to generate a report for their stockbrokers to use on a daily basis. Unfortunately, a recent financial crisis has left the bank short on cash and cannot afford to purchase expensive storage hardware. They had resorted to use AWS instead. <br><br>Which is the best service to use in order to store a virtually unlimited amount of object data without any effort to scale when demand unexpectedly increases?</p>', 'answers': ['Amazon S3', 'Amazon Glacier', 'Amazon Import/Export', 'Amazon EC2', 'DynamoDB']}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'To save cost, a company decided to change their third-party data analytics tool to a cheaper solution. They sent a full data export on a CSV file which contains all of their analytics information. You then save the CSV file to an S3 bucket for storage. Your manager asked you to do some validation on the provided data export.\xa0 In this scenario, what is the most cost-effective and easiest way to analyze export data using a standard SQL?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180808, 'original_assessment_id': 2567212, 'section': 'Athena', 'prompt': {'explanation': '<p>Amazon Athena is an interactive query service that makes it easy to analyze data directly in Amazon Simple Storage Service (Amazon S3) using standard SQL. With a few actions in the AWS Management Console, you can point Athena at your data stored in Amazon S3 and begin using standard SQL to run ad-hoc queries and get results in seconds.</p> <p>Athena is serverless, so there is no infrastructure to set up or manage, and you pay only for the queries you run. Athena scales automatically&mdash;executing queries in parallel&mdash;so results are fast, even with large datasets and complex queries.</p> <p>Athena helps you analyze unstructured, semi-structured, and structured data stored in Amazon S3. Examples include CSV, JSON, or columnar data formats such as Apache Parquet and Apache ORC. You can use Athena to run ad-hoc queries using ANSI SQL, without the need to aggregate or load the data into Athena.</p> <p>Hence, the most cost-effective and appropriate answer in this scenario is Option 3: Using AWS Athena.&nbsp;</p> <p>Options 1, 2 and 4 are all incorrect because it is not necessary to set up a database to be able to analyze the CSV export file.&nbsp;You can use a cost-effective option (AWS Athena), which is a serverless service&nbsp;that enables you to pay only for the queries you run.&nbsp;</p> <p>&nbsp;</p> <p><strong>Reference:&nbsp;</strong></p> <p><a href="https://docs.aws.amazon.com/athena/latest/ug/what-is.html">https://docs.aws.amazon.com/athena/latest/ug/what-is.html</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>To save cost, a company decided to change their third-party data analytics tool to a cheaper solution. They sent a full data export on a CSV file which contains all of their analytics information. You then save the CSV file to an S3 bucket for storage. Your manager asked you to do some validation on the provided data export.\xa0 </p><p>In this scenario, what is the most cost-effective and easiest way to analyze export data using a standard SQL?</p>', 'answers': ['<p>Create a migration tool to load the CSV export file from S3 to a DynamoDB instance. Once the data has been loaded, run queries using DynamoDB.</p>', '<p>Use mysqldump client utility to load the CSV export file from S3 to a MySQL RDS instance. Run some SQL queries once the data has been loaded to complete your validation.</p>', '<p>To be able to run SQL queries, use AWS Athena to analyze the export data file in S3.</p>', '<p>Use a migration tool to load the CSV export file from S3 to a database which is designed for online analytic processing (OLAP) such as AWS RedShift. Run some queries once the data has been loaded to complete your validation.</p>']}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have a prototype web application that uses one Spot EC2 instance. What will happen to the instance by default if it gets interrupted by Amazon EC2 for capacity requirements?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180810, 'original_assessment_id': 2567214, 'section': 'EC2', 'prompt': {'explanation': '<div><p>The main differences are that:</p><ol><li>Spot instances typically offer a significant discount off the On-Demand prices</li><li>Your instances can be interrupted by Amazon EC2 for capacity requirements with a 2-minute notification</li><li>Spot prices adjust gradually based on long term supply and demand for spare EC2 capacity.</li></ol><p>You can choose to have your Spot instances terminated, stopped, or hibernated upon interruption. Stop and hibernate options are available for persistent Spot requests and Spot Fleets with the <strong>maintain</strong>&nbsp;option enabled. By default, your instances are terminated hence, option 1 is the correct answer.</p><p>&nbsp;</p></div><p>References:</p><p><a href="https://aws.amazon.com/ec2/faqs/">https://aws.amazon.com/ec2/faqs/</a></p><p>&nbsp;</p>', 'answers': ['The instance will be terminated', 'The instance will be stopped', 'The instance will be restarted', 'This is not possible as only On-Demand instances can be interrupted by Amazon EC2'], 'question': 'You have a prototype web application that uses one Spot EC2 instance. What will happen to the instance by default if it gets interrupted by Amazon EC2 for capacity requirements?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are planning to reduce the amount of data that Amazon S3 transfers to your servers in order to lower your operating costs as well as to lower the latency of retrieving the data. To accomplish this, you need to use simple structured query language (SQL) statements to filter the contents of Amazon S3 objects and retrieve just the subset of data that you need.\xa0 \xa0Which of the following services will help you accomplish this requirement?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180812, 'original_assessment_id': 2567216, 'section': 'S3 Select', 'prompt': {'explanation': '<p>With Amazon S3 Select, you can use simple structured query language (SQL) statements to filter the contents of Amazon S3 objects and retrieve just the subset of data that you need. By using Amazon S3 Select to filter this data, you can reduce the amount of data that Amazon S3 transfers, which reduces the cost and latency to retrieve this data.</p> <p>Amazon S3 Select works on objects stored in CSV, JSON, or Apache Parquet format. It also works with objects that are compressed with GZIP or BZIP2 (for CSV and JSON objects only), and server-side encrypted objects. You can specify the format of the results as either CSV or JSON, and you can determine how the records in the result are delimited.</p> <p><strong>Reference: </strong></p> <p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/selecting-content-from-objects.html">https://docs.aws.amazon.com/AmazonS3/latest/dev/selecting-content-from-objects.html</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are planning to reduce the amount of data that Amazon S3 transfers to your servers in order to lower your operating costs as well as to lower the latency of retrieving the data. To accomplish this, you need to use simple structured query language (SQL) statements to filter the contents of Amazon S3 objects and retrieve just the subset of data that you need.\xa0 \xa0</p><p>Which of the following services will help you accomplish this requirement?</p>', 'answers': ['<p>RDS</p>', '<p>Redshift Spectrum</p>', '<p>S3 Select</p>', '<p>AWS Step Functions</p>']}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A tech company is currently using Amazon Simple Workflow (SWF) service with a default configuration for their order processing system. The system works fine but you noticed that some of the orders seem to be stuck for almost 4 weeks. What could be the possible reason for this?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180816, 'original_assessment_id': 2567220, 'section': 'SWF', 'prompt': {'explanation': '<p>By default, each workflow execution can run for a maximum of 1 year in Amazon SWF. This means that it is possible that in your workflow, there are some tasks which require manual action that renders it idle. As a result, some orders get stuck for almost 4 weeks.</p><p>Amazon SWF does not take any special action if a workflow execution is idle for an extended period of time. Idle executions are subject to the timeouts that you configure. For example, if you have set the maximum duration for an execution to be 1 day, then an idle execution will be timed out if it exceeds the 1 day limit. Idle executions are also subject to the Amazon SWF limit on how long an execution can run (1 year).</p><p>Options 2 and 3 are incorrect as the maximum execution time is 1 year.</p><p>Option 4 is incorrect as there is no problem with SWF and you can\'t manually restart this service.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/swf/">https://aws.amazon.com/swf/</a></p>', 'answers': ['It is because SWF is waiting human input from an activity task.', 'The workflow has exceeded SWF’s 15-day maximum workflow execution time.', 'The workflow has exceeded SWF’s 14-day maximum workflow execution time.', 'SWF should be restarted.'], 'question': 'A tech company is currently using Amazon Simple Workflow (SWF) service with a default configuration for their order processing system. The system works fine but you noticed that some of the orders seem to be stuck for almost 4 weeks. <br /><br />What could be the possible reason for this?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You had recently set up a CloudWatch Alarm that performs status checks on your EBS volume. However, you noticed that the volume check has a status of insufficient-data. What does this status mean?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180818, 'original_assessment_id': 2567222, 'section': 'CloudWatch', 'prompt': {'feedbacks': ['', '', '', ''], 'explanation': '<p>Volume status checks are automated tests that run every 5 minutes and return a pass or fail status.</p><p>If all checks pass, the status of the volume is&nbsp;<strong><code>ok</code></strong>.</p><p>If a check fails, the status of the volume is&nbsp;<strong><code>impaired</code></strong>.</p><p>If the status is&nbsp;<strong><code>insufficient-data</code></strong>, the checks may still be in progress on the volume.</p><p>You can view the results of volume status checks to identify any impaired volumes and take any necessary actions.</p><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-volume-status.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-volume-status.html</a></p>', 'relatedLectureIds': '', 'answers': ['All EBS Volume checks have failed.', 'The EBS Volume has been abruptly stopped.', 'All EBS Volume checks have been completed.', 'The check on the EBS volume is still in progress.'], 'question': '<p>You had recently set up a CloudWatch Alarm that performs status checks on your EBS volume. However, you noticed that the volume check has a status of <code>insufficient-data</code>. What does this status mean?</p>'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:34:35Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Which AWS service should you use if you have a web application that needs to collect, process, and analyze data in real-time?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180820, 'original_assessment_id': 2567224, 'section': 'Kinesis', 'prompt': {'explanation': '<p>Amazon Kinesis makes it easy to collect, process, and analyze real-time, streaming data so you can get timely insights and react quickly to new information. Amazon Kinesis offers key capabilities to cost-effectively process streaming data at any scale, along with the flexibility to choose the tools that best suit the requirements of your application. With Amazon Kinesis, you can ingest real-time data such as video, audio, application logs, website clickstreams, and IoT telemetry data for machine learning, analytics, and other applications. Amazon Kinesis enables you to process and analyze data as it arrives and respond instantly instead of having to wait until all your data is collected before the processing can begin.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/kinesis/">https://aws.amazon.com/kinesis/</a>&nbsp;</p>', 'answers': ['Kinesis', 'DynamoDB', 'Elastic MapReduce', 'Redshift'], 'question': 'Which AWS service should you use if you have a web application that needs to collect, process, and analyze data in real-time?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are working for a media company and you need to configure an Amazon S3 bucket to serve static assets for your public-facing web application. Which methods ensure that all of the objects uploaded to the S3 bucket can be read publicly all over the Internet? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180822, 'original_assessment_id': 2567226, 'section': 'S3', 'prompt': {'explanation': '<p>By default, all Amazon S3 resources such as buckets, objects, and related subresources&nbsp;are private which means that only the AWS account holder (resource owner) that created it has access to the resource.&nbsp;The resource owner can optionally grant access permissions to others by writing an access policy.&nbsp;In S3, you also set the permissions of the object during upload to make it public.</p><p>Amazon S3 offers access policy options broadly categorized as resource-based policies and user policies. Access policies you attach to your resources (buckets and objects) are referred to as resource-based policies.</p><p>For example, bucket policies and access control lists (ACLs) are resource-based policies. You can also attach access policies to users in your account. These are called user policies. You may choose to use resource-based policies, user policies, or some combination of these to manage permissions to your Amazon S3 resources.</p><p>Option 2 is incorrect as you can only use ACLs to grant basic read/write permissions to AWS accounts and not for public access over the Internet.&nbsp;</p><p>Option 4 is incorrect. Although with IAM, you can create a user, group, or role that has certain permissions to the S3 bucket, it does not control the individual objects that are hosted in the bucket.</p><p>Option 5 is incorrect because by default, all the S3 resources are private, so only the AWS account that created the resources can access them.</p><p>References:</p><p><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/s3-access-control.html">http://docs.aws.amazon.com/AmazonS3/latest/dev/s3-access-control.html</a></p><p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html">https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html</a></p>', 'answers': ['In S3, set the permissions of the object to public read during upload.', 'Configure the ACL of the S3 bucket to set all objects to be publicly readable.', 'Configure the S3 bucket policy to set all objects to public read.', 'Create an IAM role to set the objects inside the S3 bucket to public read.', 'Do nothing. Amazon S3 objects are already public by default.'], 'question': 'You are working for a media company and you need to configure an Amazon S3 bucket to serve static assets for your public-facing web application. Which methods ensure that all of the objects uploaded to the S3 bucket can be read publicly all over the Internet? (Choose 2)'}, 'related_lectures': [], 'correct_response': ['a', 'c'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Which technique can you use to integrate AWS Identity and Access Management with an on-premise Lightweight Directory Access Protocol (LDAP) directory service?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180824, 'original_assessment_id': 2567228, 'section': 'STS', 'prompt': {'explanation': '<p>In this scenario, you can develop an on-premise custom identity broker application and use STS to issue short-lived AWS credentials.</p><p>The application verifies that employees are signed into the existing LDAP server of the company. The identity broker application then obtains temporary security credentials for the employees through the use of the Simple Token Service. This will allow the employees access to AWS.&nbsp;</p><p>Refer to the diagram and links below for reference.</p><p>&nbsp;</p><p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://media.amazonwebservices.com/blog/iam_identity_federation_flow_4.png" alt="" width="329" height="410" /></p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_common-scenarios_federated-users.html">https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_common-scenarios_federated-users.html</a></p><p><a href="https://aws.amazon.com/blogs/aws/aws-identity-and-access-management-now-with-identity-federation/">https://aws.amazon.com/blogs/aws/aws-identity-and-access-management-now-with-identity-federation/</a></p><p>&nbsp;</p>', 'answers': ['Use an IAM policy that references the LDAP identifiers and AWS credentials.', 'Use SAML (Security Assertion Markup Language) to enable single sign-on between AWS and LDAP.', 'Develop an on-premise custom identity broker application and use STS to issue short-lived AWS credentials.', 'Use IAM roles to rotate the IAM credentials whenever LDAP credentials are updated.', 'Use the LDAP credentials to restrict a group of users from launching specific EC2 instance types.'], 'question': 'Which technique can you use to integrate AWS Identity and Access Management with an on-premise Lightweight Directory Access Protocol (LDAP) directory service?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'In AWS, which of the following is true regarding public subnets of a VPC?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180826, 'original_assessment_id': 2567230, 'section': 'Networking', 'prompt': {'explanation': '<p>A subnet that\'s associated with a route table that has a route to an Internet gateway is known as a <strong>public</strong> subnet. Conversely, a subnet which does not have a route to an Internet gateway is called a <strong>private</strong> subnet.</p> <p><strong>Reference:&nbsp;</strong></p> <p><a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario1.html">https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario1.html</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': 'In AWS, which of the following is true regarding public subnets of a VPC?', 'answers': ['It is a subnet associated with a route table that has a route to an Internet gateway ', 'It is a subnet connected to an Network Address Translation(NAT) instance.', 'It is a subnet provisioned in IAM that can be configured by any IAM user.', 'It is a subnet with EC2 instances which are using public datasets']}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:35:56Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You launched an EC2 instance in your newly created VPC. You have noticed that the generated instance does not have an associated DNS hostname. Which of the following options could be a valid reason for this issue?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180828, 'original_assessment_id': 2567232, 'section': 'VPC', 'prompt': {'explanation': '<p>When you launch an EC2 instance into a default VPC, AWS provides it with public and private DNS hostnames that correspond to the public IPv4 and private IPv4 addresses for the instance.</p><p>However, when you launch an instance into a non-default VPC, AWS provides the instance with a private DNS hostname only. New instances will only be provided with public DNS hostname depending on these two DNS attributes: the&nbsp;<strong>DNS resolution</strong> and <strong>DNS hostnames</strong>, that you have specified for your VPC, and if your instance has a public IPv4 address.</p><p>In this case, the new EC2 instance does not automatically get a DNS hostname because the <strong>DNS resolution</strong> and <strong>DNS hostnames</strong> attributes are disabled in the newly created VPC.&nbsp;</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-dns.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-dns.html</a></p><p><a href="https://aws.amazon.com/vpc/" target="_blank" rel="noopener">https://aws.amazon.com/vpc/</a></p>', 'answers': ['The newly created VPC has an invalid CIDR block.', 'Amazon Route53 is not enabled.', 'The DNS resolution and DNS hostname of the VPC configuration should be enabled.', 'The security group of the EC2 instance needs to be modified.'], 'question': 'You launched an EC2 instance in your newly created VPC. You have noticed that the generated instance does not have an associated DNS hostname. <br /><br />Which of the following options could be a valid reason for this issue?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have a distributed application in AWS that periodically processes large volumes of data across multiple instances. You designed the application to recover gracefully from any instance failures. You are required to launch the application in the most cost-effective way. Which type of EC2 instance will meet your requirements?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180830, 'original_assessment_id': 2567234, 'section': 'EC2', 'prompt': {'explanation': '<p>You require an EC2 instance that is the most cost-effective among other types. In addition, the application it will host is designed to gracefully recover in case of instance failures.&nbsp;</p><p>In terms of cost-effectiveness, Spot and Reserved instances&nbsp;are the top options. And since the application can gracefully recover from instance failures, the Spot instance is the best option for this case as it is the cheapest type of EC2 instance. Remember that&nbsp;when you use Spot Instances, there will be interruptions. Amazon EC2 can interrupt your Spot Instance when the Spot price exceeds your maximum price, when the demand for Spot Instances rise, or when the supply of Spot Instances decreases.</p><p>References:&nbsp;</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/how-spot-instances-work.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/how-spot-instances-work.html</a></p>', 'answers': ['Spot Instances', 'Reserved instances', 'Dedicated instances', 'On-Demand instances'], 'question': 'You have a distributed application in AWS that periodically processes large volumes of data across multiple instances. You designed the application to recover gracefully from any instance failures. You are required to launch the application in the most cost-effective way. <br /><br />Which type of EC2 instance will meet your requirements?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a large insurance firm that has a requirement to store miscellaneous data in AWS that are not frequently accessed. If data recovery time is not an issue, which of the following is the best and most cost-efficient solution that will fulfill this requirement?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180832, 'original_assessment_id': 2567236, 'section': 'Storage Gateway', 'prompt': {'explanation': '<p>In this scenario, the valid answers are options 2 and 3 as both the Amazon S3 Standard - Infrequently Accessed and Amazon Glacier provide low-cost storage compared to the other options. However, since the data recovery time is not an issue, then the best answer is Amazon Glacier as it has the lowest price among all the storage options.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/s3/pricing/">https://aws.amazon.com/s3/pricing/</a></p><p><a href="https://aws.amazon.com/glacier/">https://aws.amazon.com/glacier/</a></p><p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': '<p>You are working for a large insurance firm that has a requirement to store miscellaneous data in AWS that are not frequently accessed. If data recovery time is not an issue, which of the following is the best and most cost-efficient solution that will fulfill this requirement?\xa0 </p>', 'answers': ['Amazon S3 - Standard', 'Amazon S3 Standard - Infrequent Access', 'Amazon Glacier', 'Amazon S3 - Reduced Redundancy Storage']}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'What is the frequency of metric updates when you are using Amazon CloudWatch’s Free Tier?', '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180834, 'original_assessment_id': 2567238, 'section': 'CloudWatch', 'prompt': {'explanation': '<p>There are two types of monitoring in AWS CloudWatch: Basic and Detailed, where the former is provided for free and the latter one is paid.</p><p>The Basic Monitoring is a free option that runs at five-minute frequency for Amazon EC2, EBS volumes, ELBs, and Amazon RDS DB instances while Detailed Monitoring runs at 1-minute frequency.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/cloudwatch/pricing/">https://aws.amazon.com/cloudwatch/pricing/</a></p><p>&nbsp;</p>', 'answers': ['5 minutes', '500 milliseconds', '30 seconds', '1 minute'], 'question': 'What is the frequency of metric updates when you are using Amazon CloudWatch’s Free Tier?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:29:08Z'}, {'assessment_type': 'multiple-choice', 'question_plain': "A tech startup company has recently received a Series A round of funding to continue building their mobile forex trading application. You are hired to set up their cloud architecture in AWS and to implement a highly available, fault tolerant system. For their database, they are using DynamoDB and for authentication, they have chosen to use Cognito. Since the mobile application contains confidential financial transactions, there is a requirement to add a second authentication method that doesn't rely solely on user name and password.   How can you implement this in AWS?", '_class': 'assessment', 'created': '2018-11-21T07:29:08Z', 'id': 6180836, 'original_assessment_id': 4114046, 'section': 'Cognito', 'prompt': {'explanation': '<p>You can add multi-factor authentication (MFA) to a user pool to protect the identity of your users. MFA adds a second authentication method that doesn\'t rely solely on user name and password. You can choose to use SMS text messages, or time-based one-time (TOTP) passwords as second factors in signing in your users. You can also use adaptive authentication with its risk-based model to predict when you might need another authentication factor. It\'s part of the user pool advanced security features, which also include protections against compromised credentials.</p> <p>&nbsp;</p> <p><strong>Reference:</strong></p> <p><a href="https://docs.aws.amazon.com/cognito/latest/developerguide/managing-security.html">https://docs.aws.amazon.com/cognito/latest/developerguide/managing-security.html</a></p>', 'feedbacks': ['', '', '', ''], 'relatedLectureIds': '', 'question': "<p>A tech startup company has recently received a Series A round of funding to continue building their mobile forex trading application. You are hired to set up their cloud architecture in AWS and to implement a highly available, fault tolerant system. For their database, they are using DynamoDB and for authentication, they have chosen to use Cognito. Since the mobile application contains confidential financial transactions, there is a requirement to add a second authentication method that doesn't rely solely on user name and password.   </p><p>How can you implement this in AWS?</p>", 'answers': ['<p>Add multi-factor authentication (MFA) to a user pool in Cognito to protect the identity of your users.</p>', '<p>Add a new IAM policy to a user pool in Cognito.</p>', '<p>Integrate Cognito with Amazon SNS Mobile Push to allow additional authentication via SMS.</p>', '<p>Develop a custom application that integrates with Cognito that implements a second layer of authentication.</p>']}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:29:08Z'}], 'previous': None, 'next': None}, 'title': 'AWS Certified Solutions Architect Associate Practice Test 4'}, {'type': 'practice-test', 'quiz_data': {'count': 65, 'results': [{'assessment_type': 'multiple-choice', 'question_plain': 'You are designing an online banking application which needs to have a distributed session data management. Currently, the application is hosted on an Auto Scaling group of On-Demand EC2 instances across multiple Availability Zones with a Classic Load Balancer that distributes the load. Which of the following options should you do to satisfy the given requirement?', '_class': 'assessment', 'created': '2018-11-21T07:39:33Z', 'id': 6180890, 'original_assessment_id': 2567244, 'section': 'ElastiCache', 'prompt': {'explanation': '<p>You can manage HTTP session data from the web servers using an In-Memory Key/Value store such as Redis and Memcached.&nbsp;Redis is an open source, in-memory data structure store used as a database, cache, and message broker. Memcached is an in-memory key-value store for small arbitrary data (strings, objects) from results of database calls, API calls, or page rendering.</p> <p>In AWS, you can use Amazon ElastiCache which offers fully managed Redis and Memcached service to manage and store session data for your web applications.</p> <p>&nbsp;</p> <p><strong>References:</strong></p> <p><a href="https://aws.amazon.com/caching/session-management/">https://aws.amazon.com/caching/session-management/</a></p> <p><a href="https://aws.amazon.com/elasticache/">https://aws.amazon.com/elasticache/</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p>Set up an AWS Systems Manager Session Manager</p>', '<p>Enable the sticky session feature in the Classic Load Balancer</p>', '<p>Use Amazon ElastiCache</p>', '<p>Use the <code>GetSessionToken</code> action in AWS STS for session management</p>'], 'relatedLectureIds': '', 'question': '<p>You are designing an online banking application which needs to have a distributed session data management. Currently, the application is hosted on an Auto Scaling group of On-Demand EC2 instances across multiple Availability Zones with a Classic Load Balancer that distributes the load. </p><p>Which of the following options should you do to satisfy the given requirement?</p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:39:33Z'}, {'assessment_type': 'multi-select', 'question_plain': 'A financial analytics application that collects, processes and analyzes stock data in real-time is using Kinesis Data Streams. The producers continually push data to Kinesis Data Streams while the consumers process the data in real time. In Amazon Kinesis, where can the consumers store their results? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:39:33Z', 'id': 6180910, 'original_assessment_id': 2567264, 'section': 'Kinesis', 'prompt': {'feedbacks': ['', '', '', '', '', ''], 'explanation': '<p>In Amazon Kinesis, the producers continually push data to Kinesis Data Streams and the consumers process the data in real time. Consumers (<em>such as a custom application running on Amazon EC2, or an Amazon Kinesis Data Firehose delivery stream</em>) can store their results using an AWS service such as Amazon DynamoDB, Amazon Redshift, or Amazon S3.</p> <p>Hence, Options 1, 2 and 3 are the correct answers. The following diagram illustrates the high-level architecture of Kinesis Data Streams:</p> <p>&nbsp;</p> <p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://docs.aws.amazon.com/streams/latest/dev/images/architecture.png" width="500" height="215" /></p> <p>&nbsp;</p> <p>Option&nbsp;4 is incorrect because AWS Glue&nbsp;is not a storage service. It is a fully managed extract, transform, and load (ETL) service that makes it easy for customers to prepare and load their data for analytics.</p> <p>Option 5 is incorrect because Amazon Athena&nbsp;is just an interactive query service that makes it easy to analyze data in Amazon S3 using standard SQL. It is not a storage service where you can store the results processed by the consumers.</p> <p>Option 6 is incorrect because, like&nbsp;Amazon Athena, Glacier Select is not a storage service.&nbsp;It is primarily used run queries directly on data stored in Amazon Glacier, retrieving only the data you need out of your archives to use for analytics.</p> <p><strong>Reference:</strong>&nbsp;</p> <p><a href="http://docs.aws.amazon.com/streams/latest/dev/key-concepts.html">http://docs.aws.amazon.com/streams/latest/dev/key-concepts.html</a></p>', 'relatedLectureIds': '', 'answers': ['Amazon S3', 'DynamoDB', 'Amazon Redshift', '<p>AWS Glue</p>', '<p>Amazon Athena</p>', '<p>Glacier Select</p>'], 'question': '<p>A financial analytics application that collects, processes and analyzes stock data in real-time is using Kinesis Data Streams. The producers continually push data to Kinesis Data Streams while the consumers process the data in real time. In Amazon Kinesis, where can the consumers store their results? (Choose 3)</p>'}, 'related_lectures': [], 'correct_response': ['a', 'b', 'c'], 'updated': '2018-11-21T07:39:36Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'An application which uses multiple EBS volumes could not cope with the growing storage requirements needed to store their data. Your IT Manager has instructed you to set up an S3 bucket as a replacement for their EBS volumes.\xa0 \xa0Which of the following options is correct regarding the naming convention for the S3 bucket?', '_class': 'assessment', 'created': '2018-11-21T07:39:33Z', 'id': 6180892, 'original_assessment_id': 2567246, 'section': 'S3', 'prompt': {'explanation': '<p>The correct answer is:&nbsp;A bucket name must be unique across all existing bucket names in Amazon S3.</p> <p>A bucket is owned by the AWS account that created it. By default, you can create up to 100 buckets in each of your AWS accounts. There is no limit to the number of objects that can be stored in a bucket and no difference in performance whether you use many buckets or just a few. You can store all of your objects in a single bucket, or you can organize them across several buckets.</p> <p>The rules for DNS-compliant bucket names are as follows:</p> <ul> <li>Bucket names must be at least 3 and no more than 63 characters long.</li> <li>Bucket names must be a series of one or more labels. Adjacent labels are separated by a single period (.). Bucket names can contain lowercase letters, numbers, and hyphens. Each label must start and end with a lowercase letter or a number.</li> <li>Bucket names must not be formatted as an IP address (for example, 192.168.5.4).</li> <li>When using virtual hosted-style buckets with SSL, the SSL wildcard certificate only matches buckets that do not contain periods. To work around this, use HTTP or write your own certificate verification logic. We recommend that you do not use periods (".") in bucket names.</li> </ul> <p>&nbsp;</p> <p><strong>Reference:&nbsp;</strong></p> <p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html">https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['A bucket name must be unique across all existing bucket names in Amazon S3.', 'By default, an S3 bucket is not owned by the AWS account that created it', 'Bucket names must be at least 5 and no more than 63 characters long.', 'Bucket names can be formatted as an IP address such as 192.168.5.4'], 'relatedLectureIds': '', 'question': '<p>An application which uses multiple EBS volumes could not cope with the growing storage requirements needed to store their data. Your IT Manager has instructed you to set up an S3 bucket as a replacement for their EBS volumes.\xa0 \xa0</p><p>Which of the following options is correct regarding the naming convention for the S3 bucket?</p>'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:39:33Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are a Solutions Architect working for a major investment bank in London. Your IT Manager instructed you to prepare a migration plan of your on-premise application architecture to AWS. During your design process, you considered the current security of your on-premise application. Which among the following does AWS provide for you as part of the shared responsibility model? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:39:33Z', 'id': 6180894, 'original_assessment_id': 2567248, 'section': 'AWS Shared Responsibility Model', 'prompt': {'explanation': '<p>Security and Compliance is a shared responsibility between AWS and the customer. This shared model can help relieve the customer&rsquo;s operational burden as AWS operates, manages, and controls the components from the host operating system and virtualization layer down to the physical security of the facilities in which the service operates. The customer assumes responsibility and management of the guest operating system (including updates and security patches), other associated application software as well as the configuration of the AWS provided security group firewall.</p><p>Customers should carefully consider the services they choose as their responsibilities vary depending on the services used, the integration of those services into their IT environment, and applicable laws and regulations. The nature of this shared responsibility also provides the flexibility and customer control that permits the deployment. As shown in the chart below, this differentiation of responsibility is commonly referred to as Security &ldquo;of&rdquo; the Cloud versus Security &ldquo;in&rdquo; the Cloud.</p><p>Refer to this diagram for a better understanding of the shared responsibility model.</p><p><img src="https://d1.awsstatic.com/security-center/NewSharedResponsibilityModel.749924fb27d7c6de5cd59376dbaab323f86ce5dd.png" width="570" height="291" /></p><p>&nbsp;</p><p>Resources:</p><p><a href="https://aws.amazon.com/compliance/shared-responsibility-model/">https://aws.amazon.com/compliance/shared-responsibility-model/</a>&nbsp;</p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['EC2 Instance security', 'Physical network infrastructure', 'User access to the AWS environment via IAM', 'Virtualization infrastructure', '<p>Operating System (OS) patching for Spot and On-Demand EC2 instances</p>', '<p>Operating System (OS) patching for Reserved EC2 instances</p>'], 'relatedLectureIds': '', 'question': 'You are a Solutions Architect working for a major investment bank in London. Your IT Manager instructed you to prepare a migration plan of your on-premise application architecture to AWS. During your design process, you considered the current security of your on-premise application. <br><br>Which among the following does AWS provide for you as part of the shared responsibility model? (Choose 2)'}, 'related_lectures': [], 'correct_response': ['b', 'd'], 'updated': '2018-11-21T07:39:33Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'What is a configuration management service offered by AWS that provides managed instances of Chef and Puppet?', '_class': 'assessment', 'created': '2018-11-21T07:39:33Z', 'id': 6180896, 'original_assessment_id': 2567250, 'section': 'OpsWorks', 'prompt': {'explanation': '<p>AWS OpsWorks is a configuration management service that provides managed instances of Chef and Puppet. Chef and Puppet are automation platforms that allow you to use code to automate the configurations of your servers. OpsWorks lets you use Chef and Puppet to automate how servers are configured, deployed, and managed across your Amazon EC2 instances or on-premises compute environments.</p><p>&nbsp;</p><p>Resources:</p><p><a href="https://aws.amazon.com/opsworks/">https://aws.amazon.com/opsworks/</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['AWS OpsWorks', 'AWS Elastic Beanstalk', 'AWS CloudFormation', 'AWS SNS'], 'relatedLectureIds': '', 'question': 'What is a configuration management service offered by AWS that provides managed instances of Chef and Puppet?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:39:33Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a data analytics startup that collects clickstream data and stores them in an S3 bucket. You need to launch an AWS Lambda function to trigger your ETL jobs to run as soon as new data becomes available in Amazon S3.\xa0 \xa0Which of the following services can you use as an extract, transform, and load (ETL) service in this scenario?', '_class': 'assessment', 'created': '2018-11-21T07:39:33Z', 'id': 6180900, 'original_assessment_id': 2567254, 'section': 'Glue', 'prompt': {'explanation': '<p>AWS Glue is a fully managed extract, transform, and load (ETL) service that makes it easy for customers to prepare and load their data for analytics. You can create and run an ETL job with a few clicks in the AWS Management Console. You simply point AWS Glue to your data stored on AWS, and AWS Glue discovers your data and stores the associated metadata (e.g. table definition and schema) in the AWS Glue Data Catalog. Once cataloged, your data is immediately searchable, queryable, and available for ETL. AWS Glue generates the code to execute your data transformations and data loading processes.</p> <p><strong>Reference: </strong></p> <p><a href="https://aws.amazon.com/glue/">https://aws.amazon.com/glue/</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p>S3 Select</p>', '<p>Redshift Spectrum</p>', '<p>AWS Step Functions</p>', '<p>AWS Glue</p>'], 'relatedLectureIds': '', 'question': '<p>You are working for a data analytics startup that collects clickstream data and stores them in an S3 bucket. You need to launch an AWS Lambda function to trigger your ETL jobs to run as soon as new data becomes available in Amazon S3.\xa0 \xa0</p><p>Which of the following services can you use as an extract, transform, and load (ETL) service in this scenario?</p>'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:39:33Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as a Solutions Architect for a large financial company. They have a web application hosted in their on-premise infrastructure which they want to migrate to AWS cloud. Your manager had instructed you to ensure that there is no down time while the migration process is on-going. In order to achieve this, your team had decided to divert 50% of the traffic to the new application in AWS and the other 50% to the application hosted in their on-premise infrastructure. Once the migration is over and that the application works with no issues, a full diversion to the AWS will be implemented. Which of the following steps will you do to satisfy this requirement?', '_class': 'assessment', 'created': '2018-11-21T07:39:33Z', 'id': 6180902, 'original_assessment_id': 2567256, 'section': 'Route53', 'prompt': {'explanation': '<p>To divert 50% of the traffic to the new application in AWS and the other 50% to the application, you can use Route53 with Weighted routing policy. This will divert the traffic between the on-premise and AWS-hosted application accordingly.</p><p>Weighted routing lets you associate multiple resources with a single domain name (tutorialsdojo.com) or subdomain name (learn.tutorialsdojo.com) and choose how much traffic is routed to each resource. This can be useful for a variety of purposes, including load balancing and testing new versions of software. You can set a specific percentage of how much traffic will be allocated to the resource by specifying the weights.</p><p>For example, if you want to send a tiny portion of your traffic to one resource and the rest to another resource, you might specify weights of 1 and 255. The resource with a weight of 1 gets 1/256th of the traffic (1/1+255), and the other resource gets 255/256ths (255/1+255).</p><p>You can gradually change the balance by changing the weights. If you want to stop sending traffic to a resource, you can change the weight for that record to 0.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html">http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p>Use a Network Load balancer to divert the traffic between the on-premise and AWS hosted application.\xa0 </p>', 'Use an Application Elastic Load balancer to divert and proportion the traffic between the on-premise and AWS-hosted application.', 'Use Route53 with Failover routing policy to divert and proportion the traffic between the on-premise and AWS-hosted application.', 'Use Route53 with Weighted routing policy to divert the traffic between the on-premise and AWS-hosted application.'], 'relatedLectureIds': '', 'question': '<p>You are working as a Solutions Architect for a large financial company. They have a web application hosted in their on-premise infrastructure which they want to migrate to AWS cloud. Your manager had instructed you to ensure that there is no down time while the migration process is on-going. In order to achieve this, your team had decided to divert 50% of the traffic to the new application in AWS and the other 50% to the application hosted in their on-premise infrastructure. Once the migration is over and that the application works with no issues, a full diversion to the AWS will be implemented. <br><br>Which of the following steps will you do to satisfy this requirement?</p>'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:39:33Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are looking for a cloud storage for your company with the lowest cost possible. The files to be stored are rarely retrieved, however, the data retrieval time should not exceed 24 hours. What is the best storage option to use in AWS for this scenario?', '_class': 'assessment', 'created': '2018-11-21T07:39:33Z', 'id': 6180904, 'original_assessment_id': 2567258, 'section': 'Glacier', 'prompt': {'explanation': '<p>Amazon Glacier is an extremely low-cost storage service that provides secure, durable, and flexible storage for data backup and archival which is cheaper than Amazon S3.</p><p>The standard retrievals in Glacier allow you to access any of your archives within several hours. Standard retrievals typically complete within 3 &ndash; 5 hours, which is well within the required 24-hour data retrieval time in the scenario.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/glacier/faqs/">https://aws.amazon.com/glacier/faqs/</a></p><p>&nbsp;</p>', 'answers': ['Amazon Glacier', 'Amazon S3 - Reduced Redundancy Storage', 'Amazon S3 Standard - Infrequent Access', 'Amazon S3 Standard'], 'question': 'You are looking for a cloud storage for your company with the lowest cost possible. The files to be stored are rarely retrieved, however, the data retrieval time should not exceed 24 hours. <br /><br />What is the best storage option to use in AWS for this scenario?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:39:33Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are building a prototype for a cryptocurrency news website of a small startup company. The website will be deployed to a Spot EC2 instance and will use Amazon Aurora as its database. You received a Spot Instance at a bid of $0.04/hr and after 90 minutes, the Spot price increases to $0.06/hr and then your instance was terminated by AWS.\xa0 \xa0In this scenario, what would be the total cost of running your Spot Instance?', '_class': 'assessment', 'created': '2018-11-21T07:39:33Z', 'id': 6180898, 'original_assessment_id': 2567252, 'section': 'Billing and Cost Management', 'prompt': {'explanation': '<p>Since the Spot instance has been running for more than an hour, which is past the first instance hour, this means that you will be charged from the time it was launched till the time it was terminated by AWS. The computation for your 90 minute usage would be $0.04 (60 minutes) + $0.02 (30 minutes) = $0.06 hence, option 3 is correct.</p> <p>If your Spot instance is terminated or stopped by Amazon EC2 in the first instance hour, <span style="text-decoration: underline;">you will not be charged for that usage</span>. However, if you terminate the instance yourself, you will be charged to the nearest second.</p> <p>If the Spot instance is terminated or stopped by Amazon EC2 in any subsequent hour, you will be charged for your usage to the nearest second. If you are running on Windows and you terminate the instance yourself, you will be charged for an entire hour.</p> <p>&nbsp;</p> <p><strong>Reference:&nbsp;</strong></p> <p><a href="https://aws.amazon.com/ec2/faqs/">https://aws.amazon.com/ec2/faqs/</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['<p>$0.08</p>', '<p>$0.07</p>', '<p>$0.06</p>', '<p>$0.00</p>', '<p>$0.04</p>', '<p>$0.10</p>'], 'relatedLectureIds': '', 'question': '<p>You are building a prototype for a cryptocurrency news website of a small startup company. The website will be deployed to a Spot EC2 instance and will use Amazon Aurora as its database. You received a Spot Instance at a bid of $0.04/hr and after 90 minutes, the Spot price increases to $0.06/hr and then your instance was terminated by AWS.\xa0 \xa0</p><p>In this scenario, what would be the total cost of running your Spot Instance?</p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:39:33Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a multinational telecommunications company. Your IT Manager is willing to consolidate their log streams including the access, application, and security logs in one single system. Once consolidated, the company wants to analyze these logs in real-time based on heuristics. There will be some time in the future that the company needs to validate heuristics, which requires going back to data samples extracted from the last 12 hours.What is the best approach to meet this requirement?', '_class': 'assessment', 'created': '2018-11-21T07:39:33Z', 'id': 6180906, 'original_assessment_id': 2567260, 'section': 'Kinesis', 'prompt': {'explanation': '<p>In this scenario, you need a service that collect, process, and analyze data in real-time hence, the right service to use here is Amazon Kinesis.</p><p>Amazon Kinesis makes it easy to collect, process, and analyze real-time, streaming data so you can get timely insights and react quickly to new information. Amazon Kinesis offers key capabilities to cost-effectively process streaming data at any scale, along with the flexibility to choose the tools that best suit the requirements of your application.</p><p>With Amazon Kinesis, you can ingest real-time data such as video, audio, application logs, website clickstreams, and IoT telemetry data for machine learning, analytics, and other applications. Amazon Kinesis enables you to process and analyze data as it arrives and respond instantly instead of having to wait until all your data is collected before the processing can begin.</p><p>&nbsp;</p><p>Resources:</p><p><a href="https://aws.amazon.com/kinesis/">https://aws.amazon.com/kinesis/</a></p>', 'answers': ['First, setup an Auto Scaling group of EC2 servers then store the logs on Amazon S3 then finally, use EMR to apply heuristics on the logs.', 'First, send all of the log events to Amazon Kinesis then afterwards, develop a client process to apply heuristics on the logs.', 'First, configure Amazon Cloud Trail to receive custom logs and then use EMR to apply heuristics on the logs.', 'First, send all the log events to Amazon SQS then setup an Auto Scaling group of EC2 servers to consume the logs and finally, apply the heuristics.'], 'question': 'You are working for a multinational telecommunications company. Your IT Manager is willing to consolidate their log streams including the access, application, and security logs in one single system. Once consolidated, the company wants to analyze these logs in real-time based on heuristics. There will be some time in the future that the company needs to validate heuristics, which requires going back to data samples extracted from the last 12 hours.<br /><br />What is the best approach to meet this requirement?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:39:33Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are instructed by your manager to come up with a solution to run analytics against all combined log files from the Elastic Load Balancer in your VPC. Which AWS services can be used together to collect logs and process log file analysis in an AWS environment?', '_class': 'assessment', 'created': '2018-11-21T07:39:33Z', 'id': 6180908, 'original_assessment_id': 2567262, 'section': 'EMR', 'prompt': {'explanation': '<p>The best solution for this scenario is to use&nbsp;Amazon S3 for storing ELB log files and then use Amazon EMR for processing the log files in analysis.&nbsp;</p><p>Amazon EMR provides a managed Hadoop framework that makes it easy, fast, and cost-effective to&nbsp;process vast amounts of data across dynamically scalable Amazon EC2 instances. You can also run other popular distributed frameworks such as Apache Spark, HBase, Presto, and Flink in Amazon EMR, and interact with data in other AWS data stores such as Amazon S3 and Amazon DynamoDB.</p><p>Amazon EMR securely and reliably handles a broad set of big data use cases, including log analysis, web indexing, data transformations (ETL), machine learning, financial analysis, scientific simulation, and bioinformatics.</p><p>&nbsp;</p><p>Resources:</p><p><a href="https://aws.amazon.com/emr/">https://aws.amazon.com/emr/</a></p>', 'answers': ['Amazon S3 for storing the ELB log files and EC2 for processing the log files in analysis.', 'Amazon DynamoDB to store the logs and EC2 for running custom log analysis scripts.', 'Amazon S3 for storing ELB log files and Amazon EMR for processing the log files in analysis.', 'Amazon EC2 for storing and processing the log files.'], 'question': 'You are instructed by your manager to come up with a solution to run analytics against all combined log files from the Elastic Load Balancer in your VPC. Which AWS services can be used together to collect logs and process log file analysis in an AWS environment?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:39:33Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are a junior DevOps engineer for a multinational accounting firm. Your team has launched a new VPC for one of their departments and you were instructed to launch a bastion host to provide access to this VPC from an external network such as the Internet.\xa0 \xa0Which of the following is true regarding a bastion host in AWS?', '_class': 'assessment', 'created': '2018-11-21T07:39:33Z', 'id': 6180914, 'original_assessment_id': 2567268, 'section': 'VPC', 'prompt': {'explanation': '<p>They are basically just EC2 instances in the public subnet of your VPC, which are used as a jump server to your AWS resources within other subnets.&nbsp;A bastion is a special purpose server instance that is designed to be the primary access point from the Internet and acts as a proxy to your other EC2 instances</p><br /><p>References:</p><p><a href="https://aws.amazon.com/blogs/security/controlling-network-access-to-ec2-instances-using-a-bastion-server/" target="_blank" rel="noopener">https://aws.amazon.com/blogs/security/controlling-network-access-to-ec2-instances-using-a-bastion-server/</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['A bastion host is an EC2 instance in the public subnet of your VPC,  which is used as a jump server to your AWS resources within other subnets.', 'A bastion host is an EC2 instance in the private subnet of your VPC, which is used as a jump server to your AWS resources within other subnets.', 'A bastion host is an EC2 instance in the public subnet which is used to host database servers.', 'A bastion host is an EC2 instance in the private subnet which is used to host database servers.', '<p>A bastion host is an EC2 instance in the private subnet of your VPC that provides VPN connection.</p>', '<p>A bastion host is an EC2 instance in the private subnet of your VPC that provides a DirectConnect connection to the on-premise network.</p>'], 'relatedLectureIds': '', 'question': '<p>You are a junior DevOps engineer for a multinational accounting firm. Your team has launched a new VPC for one of their departments and you were instructed to launch a bastion host to provide access to this VPC from an external network such as the Internet.\xa0 \xa0</p><p>Which of the following is true regarding a bastion host in AWS?</p>'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:39:33Z'}, {'assessment_type': 'multiple-choice', 'question_plain': "You are implementing a hybrid architecture for your company where you are connecting their Amazon Virtual Private Cloud (VPC) to their on-premise network. Which of the following can be used to create a private connection between the VPC and your company's on-premise network?", '_class': 'assessment', 'created': '2018-11-21T07:39:33Z', 'id': 6180916, 'original_assessment_id': 2567270, 'section': 'VPC', 'prompt': {'explanation': '<p>Direct Connect creates a direct, private connection from your on-premises data center to AWS, letting you establish a 1-gigabit or 10-gigabit dedicated network connection using Ethernet fiber-optic cable.&nbsp;&nbsp;</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/premiumsupport/knowledge-center/connect-vpc/">https://aws.amazon.com/premiumsupport/knowledge-center/connect-vpc/</a></p>', 'answers': ['Direct Connect', 'Route53', 'ClassicLink', 'AWS Direct Link'], 'question': "You are implementing a hybrid architecture for your company where you are connecting their Amazon Virtual Private Cloud (VPC) to their on-premise network. Which of the following can be used to create a private connection between the VPC and your company's on-premise network?"}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:39:33Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Your IT Director instructed you to ensure that all of the AWS resources in your VPC don’t go beyond their service limit. Which of the following services can help in this task?', '_class': 'assessment', 'created': '2018-11-21T07:39:33Z', 'id': 6180918, 'original_assessment_id': 2567272, 'section': 'Trusted Advisor', 'prompt': {'explanation': '<p>Remember that the AWS Trusted Advisor analyzes your AWS environment and provides best practice recommendations in these five categories: <strong>C</strong>ost Optimization, <strong>P</strong>erformance, <strong>F</strong>ault Tolerance, <strong>S</strong>ecurity, and <strong>S</strong>ervice Limits. You can use a mnemonic, such as CPFSS, to memorize these five categories.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/premiumsupport/trustedadvisor/">https://aws.amazon.com/premiumsupport/trustedadvisor/</a></p><p>&nbsp;</p>', 'answers': ['AWS Cloudwatch', 'AWS EC2', 'AWS Trusted Advisor', 'AWS SNS'], 'question': 'Your IT Director instructed you to ensure that all of the AWS resources in your VPC don’t go beyond their service limit. <br /><br />Which of the following services can help in this task?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:39:33Z'}, {'assessment_type': 'multi-select', 'question_plain': 'An online shopping platform is hosted on an Auto Scaling group of On-Demand EC2 instances with a default Auto Scaling termination policy and no instance protection configured. The system is deployed across three Availability Zones in the US West region (us-west-1) with an Application Load Balancer in front to provide high availability and fault tolerance for the shopping platform. The us-west-1a, us-west-1b, and us-west-1c Availability Zones have 10, 8 and 7 running instances respectively. Due to the low number of incoming traffic, the scale-in operation has been triggered.\xa0 \xa0Which of the following will the Auto Scaling group do to determine which instance to terminate first in this scenario? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:39:33Z', 'id': 6180912, 'original_assessment_id': 2567266, 'section': 'Auto Scaling', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>The default termination policy is designed to help ensure that your network architecture spans Availability Zones evenly. With the default termination policy, the behavior of the Auto Scaling group is as follows:</p> <p style="padding-left: 30px;">1. If there are instances in multiple Availability Zones, choose the Availability Zone with the most instances and at least one instance that is not protected from scale in. If there is more than one Availability Zone with this number of instances, choose the Availability Zone with the instances that use the oldest launch configuration.</p> <p style="padding-left: 30px;">2. Determine which unprotected instances in the selected Availability Zone use the oldest launch configuration. If there is one such instance, terminate it.</p> <p style="padding-left: 30px;">3. If there are multiple instances to terminate based on the above criteria, determine which unprotected instances are closest to the next billing hour. (This helps you maximize the use of your EC2 instances and manage your Amazon EC2 usage costs.) If there is one such instance, terminate it.</p> <p style="padding-left: 30px;">4. If there is more than one unprotected instance closest to the next billing hour, choose one of these instances at random.</p> <p>The following flow diagram illustrates how the default termination policy works:</p> <p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://docs.aws.amazon.com/autoscaling/ec2/userguide/images/termination-policy-default-flowchart-diagram.png" /> <br /><br /><strong>Reference:</strong><br /><br /><a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-instance-termination.html#default-termination-policy">https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-instance-termination.html#default-termination-policy</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['<p>Choose the Availability Zone with the most number of instances, which is the us-west-1a Availability Zone in this scenario.</p>', '<p>Choose the Availability Zone with the least number of instances, which is the us-west-1c Availability Zone in this scenario.</p>', '<p>Select the instances with the most recent launch configuration.</p>', '<p>Select the instances with the oldest launch configuration.</p>', '<p>Select the instance that is closest to the next billing hour.</p>', '<p>Select the instance that is farthest to the next billing hour. </p>'], 'question': '<p>An online shopping platform is hosted on an Auto Scaling group of On-Demand EC2 instances with a default Auto Scaling termination policy and no instance protection configured. The system is deployed across three Availability Zones in the US West region (us-west-1) with an Application Load Balancer in front to provide high availability and fault tolerance for the shopping platform. The us-west-1a, us-west-1b, and us-west-1c Availability Zones have 10, 8 and 7 running instances respectively. Due to the low number of incoming traffic, the scale-in operation has been triggered.\xa0 \xa0</p><p>Which of the following will the Auto Scaling group do to determine which instance to terminate first in this scenario? (Choose 3)</p>'}, 'related_lectures': [], 'correct_response': ['a', 'd', 'e'], 'updated': '2018-11-21T07:39:33Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are tasked to choose the most affordable AWS support plan that offers the following: 1.) 24x7 access to customer service, documentation, whitepapers, and support forums. 2.) Access to full set of Trusted Advisor checksWhich type of support plan will you choose?', '_class': 'assessment', 'created': '2018-11-21T07:39:33Z', 'id': 6180920, 'original_assessment_id': 2567274, 'section': 'Billing and Cost Management', 'prompt': {'explanation': '<p>There are 4 types of AWS support plans:</p> <ol> <li>Basic</li> <li>Developer</li> <li>Business</li> <li>Enterprise</li> </ol> <p>All customers receive Basic Support included with your AWS account. All plans, including Basic Support, provide 24x7 access to customer service, AWS documentation, whitepapers, and support forums.&nbsp;</p> <p>Business and Enterprise plans provide access to full set of Trusted Advisor checks. However, the main question here which is the most affordable. Hence, the best answer is the Business plan since it is cheaper than the Enterprise plan.</p> <p>&nbsp;</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/premiumsupport/compare-plans/" target="_blank" rel="noopener">https://aws.amazon.com/premiumsupport/compare-plans/</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['Basic', 'Developer', 'Business', 'Enterprise'], 'relatedLectureIds': '', 'question': '<p>You are tasked to choose the most affordable AWS support plan that offers the following: <br><br>1.) 24x7 access to customer service, documentation, whitepapers, and support forums. <br>2.) Access to full set of Trusted Advisor checks<br><br>Which type of support plan will you choose?</p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:39:33Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are planning to migrate an enterprise application from your on-premise network to AWS cloud. You are looking for managed services in AWS that automatically takes care of the maintenance of the underlying resources such as OS patching and security management.\xa0 \xa0Which AWS services should you use to migrate the application? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:39:33Z', 'id': 6180922, 'original_assessment_id': 2567276, 'section': 'DynamoDB', 'prompt': {'feedbacks': ['', '', '', '', '', ''], 'explanation': '<p>The keyword in the question is <strong>managed</strong> service. This means that AWS will manage the underlying resources for the service. Amazon RDS and DynamoDB are examples of managed services in AWS.</p> <p>Amazon DynamoDB is a fast and flexible NoSQL database service for all applications that need consistent, single-digit millisecond latency at any scale. It is a fully managed cloud database and supports both document and key-value store models.</p> <p>Amazon Relational Database Service (Amazon RDS) is a managed service that makes it easy to set up, operate, and scale a relational database in the cloud. It provides cost-efficient and resizable capacity while managing time-consuming database administration tasks, enabling you to focus on your applications and business.</p> <p>Options 1 and 6 are incorrect because&nbsp;both Elastic Beanstalk and&nbsp;Amazon Elastic MapReduce automatically provision EC2 instances which you still need to manage yourself. Hence, these are not managed services that you can use for this scenario.&nbsp;</p> <p>Option 4 is incorrect because you will still need to manage Amazon EC2 Dedicated Hosts. Take note that EC2 instances are not managed services which means that you are responsible for maintaining the health of the instance and applying the required OS patches.</p> <p>Option 5 is incorrect because Amazon Redshift Spectrum is primarily used to query open file formats in Amazon S3 and data in Redshift in a single query, without the need or delay of loading the S3 data. Although Redshift is a fully-managed service, take note that Amazon Redshift Spectrum is simply a tool and is not applicable in this scenario.</p> <p><strong>References:</strong></p> <p><a href="https://aws.amazon.com/dynamodb/ " target="_blank" rel="noopener">https://aws.amazon.com/dynamodb/ </a></p> <p><a href="https://aws.amazon.com/rds/" target="_blank" rel="noopener">https://aws.amazon.com/rds/</a></p>', 'relatedLectureIds': '', 'answers': ['Elastic Beanstalk', 'RDS', 'DynamoDB', '<p>Amazon EC2 Dedicated Hosts</p>', '<p>Amazon Redshift Spectrum</p>', '<p>Amazon Elastic MapReduce</p>'], 'question': '<p>You are planning to migrate an enterprise application from your on-premise network to AWS cloud. You are looking for managed services in AWS that automatically takes care of the maintenance of the underlying resources such as OS patching and security management.\xa0 \xa0</p><p>Which AWS services should you use to migrate the application? (Choose 2)</p>'}, 'related_lectures': [], 'correct_response': ['b', 'c'], 'updated': '2018-11-21T07:41:26Z'}, {'assessment_type': 'multi-select', 'question_plain': 'An application is hosted on an EC2 instance with multiple EBS Volumes attached and uses Amazon Neptune as its database. To improve data security, you encrypted all of the EBS volumes attached to the instance to protect the confidential data stored in the volumes.\xa0 Which of the following statements are true about encrypted Amazon Elastic Block Store volumes? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:39:33Z', 'id': 6180924, 'original_assessment_id': 2567278, 'section': 'EBS', 'prompt': {'explanation': '<p>Amazon Elastic Block Store (Amazon EBS) provides block level storage volumes for use with EC2 instances. EBS volumes are highly available and reliable storage volumes that can be attached to any running instance that is in the same Availability Zone. EBS volumes that are attached to an EC2 instance are exposed as storage volumes that persist independently from the life of the instance.&nbsp;</p> <p>When you create an encrypted EBS volume and attach it to a supported instance type, the following types of data are encrypted:</p> <ul> <li>Data at rest inside the volume</li> <li>All data moving between the volume and the instance</li> <li>All snapshots created from the volume</li> <li>All volumes created from those snapshots</li> </ul> <p>There is no direct way to encrypt an existing unencrypted volume or to remove encryption from an encrypted volume. However, you can migrate data between encrypted and unencrypted volumes.&nbsp;</p> <p>&nbsp;<img style="display: block; margin-left: auto; margin-right: auto;" src="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/images/architecture_storage.png" alt="" width="639" height="360" /></p> <p>&nbsp;</p> <p><strong>References:</strong></p> <p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonEBS.html ">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonEBS.html </a></p> <p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html</a></p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['All data moving between the volume and the instance are encrypted.', 'Snapshots are automatically encrypted.', 'Snapshots are not automatically encrypted.', 'Existing volumes can be encrypted.', 'Shared volumes can be encrypted.', '<p>The data at rest inside the volume is encrypted.</p>'], 'relatedLectureIds': '', 'question': '<p>An application is hosted on an EC2 instance with multiple EBS Volumes attached and uses Amazon Neptune as its database. To improve data security, you encrypted all of the EBS volumes attached to the instance to protect the confidential data stored in the volumes.\xa0 </p><p>Which of the following statements are true about encrypted Amazon Elastic Block Store volumes? (Choose 3)</p>'}, 'related_lectures': [], 'correct_response': ['a', 'b', 'f'], 'updated': '2018-11-21T07:43:32Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have EC2 instances running on your VPC. You have both UAT and production EC2 instances running. You want to ensure that employees who are responsible for the UAT instances don’t have the access to work on the production instances to minimize security risks.Which of the following would be the best way to achieve this?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180926, 'original_assessment_id': 2567280, 'section': 'EC2', 'prompt': {'explanation': '<p>For this scenario, the best way to achieve this solution is to use a combination of Tags and IAM policies. You can define the tags on the UAT and production EC2 instances and add a condition to the IAM policy which allows access to specific tags.</p><p>Tags enable you to categorize your AWS resources in different ways, for example, by purpose, owner, or environment. This is useful when you have many resources of the same type &mdash; you can quickly identify a specific resource based on the tags you\'ve assigned to it.</p><p>By default, IAM users don\'t have permission to create or modify Amazon EC2 resources, or perform tasks using the Amazon EC2 API. (This means that they also can\'t do so using the Amazon EC2 console or CLI.) To allow IAM users to create or modify resources and perform tasks, you must create IAM policies that grant IAM users permission to use the specific resources and API actions they\'ll need, and then attach those policies to the IAM users or groups that require those permissions.</p><p>&nbsp;</p><p>Resources:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Using_Tags.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Using_Tags.html</a>&nbsp;</p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-policies-for-amazon-ec2.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-policies-for-amazon-ec2.html</a></p>', 'answers': ["Launch the UAT and production EC2 instances in separate VPC's connected by VPC peering.", 'Create an IAM policy with a condition which allows access to only EC2 instances that are used for production or development.', 'Launch the UAT and production instances in different Availability Zones and use Multi Factor Authentication.', 'Define the tags on the UAT and production servers and add a condition to the IAM policy which allows access to specific tags. '], 'question': 'You have EC2 instances running on your VPC. You have both UAT and production EC2 instances running. You want to ensure that employees who are responsible for the UAT instances don’t have the access to work on the production instances to minimize security risks.<br /><br />Which of the following would be the best way to achieve this?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a top IT Consultancy and one of your clients asked you how to properly secure their AWS infrastructure. They have a VPC with two On-Demand EC2 instances with Elastic IP addresses which recently were under SSH brute force attacks over the Internet. Their IT Security team has identified the IP addresses where these attacks originated.\xa0 Which of the following is the quickest way to fix this security vulnerability?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180928, 'original_assessment_id': 2567282, 'section': 'Security', 'prompt': {'explanation': '<p>In this situation, the best thing to do is to block the IP addresses in the Network Access Control List.</p><p>A&nbsp;<em>network access control list (ACL)</em>&nbsp;is an optional layer of security for your VPC that acts as a firewall for controlling traffic in and out of one or more subnets. This means that if you block an IP address in the Network ACL, it would not be able to access your VPC anymore.</p><p>Option 1 is incorrect because if you deploy the EC2 instance in the private subnet without a public or EIP address, it would not be accessible over the Internet, even to you.&nbsp;</p><p>Option 2 is incorrect because removing the Internet Gateway will also make your EC2 instance inaccessible to you as it will cut down the connection to the Internet.</p><p>Option 4 is a valid answer however, the problem is that the hackers may still attack your VPC&nbsp;in case your bastion host is not properly fortified with Network Access Control List and Security Group.</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_ACLs.html">https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_ACLs.html</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['Place the EC2 instances into private subnets', 'Remove the Internet Gateway from the VPC', 'Block the IP addresses in the Network Access Control List', 'Deploy the EC2 instances into private subnets then set up a bastion host'], 'relatedLectureIds': '', 'question': '<p>You are working for a top IT Consultancy and one of your clients asked you how to properly secure their AWS infrastructure. They have a VPC with two On-Demand EC2 instances with Elastic IP addresses which recently were under SSH brute force attacks over the Internet. Their IT Security team has identified the IP addresses where these attacks originated.\xa0 </p><p>Which of the following is the quickest way to fix this security vulnerability?\xa0 </p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are assigned to design a highly available architecture in AWS. You have two target groups with three EC2 instances each, which are added to an Application Load Balancer. In the security group of the EC2 instance, you have verified that the port 80 for HTTP is allowed. However, the instances are still showing out of service. What could be the root cause of this issue?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180930, 'original_assessment_id': 2567284, 'section': 'ELB', 'prompt': {'explanation': '<p>Since the security group is properly configured, the issue may be caused by a wrong&nbsp;health check configuration in the Target Group.&nbsp;</p><p>Your Application Load Balancer periodically sends requests to its registered targets to test their status. These tests are called&nbsp;<em>health checks</em>. Each load balancer node routes requests only to the healthy targets in the enabled Availability Zones for the load balancer. Each load balancer node checks the health of each target, using the health check settings for the target group with which the target is registered. After your target is registered, it must pass one health check to be considered healthy. After each health check is completed, the load balancer node closes the connection that was established for the health check.</p><p>References:&nbsp;</p><p><a href="http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-healthchecks.html">http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-healthchecks.html</a>&nbsp;</p>', 'answers': ['The instances are using the wrong AMI.', 'The health check configuration is not properly defined.', 'The wrong instance type was used for the EC2 instance.', 'The wrong subnet was used in your VPC'], 'question': 'You are assigned to design a highly available architecture in AWS. You have two target groups with three EC2 instances each, which are added to an Application Load Balancer. In the security group of the EC2 instance, you have verified that the port 80 for HTTP is allowed. However, the instances are still showing out of service. <br /><br />What could be the root cause of this issue?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have an existing On-demand EC2 instance and you are planning to create a new EBS volume that will be attached to this instance. The data that will be stored are confidential medical records so you have to make sure that the data is protected. How can you secure the data at rest of the new EBS volume that you will create?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180932, 'original_assessment_id': 2567286, 'section': 'EBS', 'prompt': {'explanation': '<p>You can secure the data at rest by creating an encrypted EBS Volume. The main difference between creating an unencrypted to an encrypted EBS Volume is just one tickbox called "<code>Encryption</code>". You can create an encrypted EBS Volume by ticking the encryption tickbox and attach it to the EC2 instance.</p> <p>Amazon EBS encryption offers a simple encryption solution for your EBS volumes without the need to build, maintain, and secure your own key management infrastructure. When you create an encrypted EBS volume and attach it to a supported instance type, the following types of data are encrypted:</p> <ul> <li>-Data at rest inside the volume</li> <li>-All data moving between the volume and the instance</li> <li>-All snapshots created from the volume</li> <li>-All volumes created from those snapshots</li> </ul><br /> <p>Encryption operations occur on the servers that host EC2 instances, ensuring the security of both data-at-rest and data-in-transit between an instance and its attached EBS storage.</p> <p>&nbsp;</p> <p>Options 1 and 2 are incorrect since you can\'t use the server and client-side encryption of S3 in EBS Volumes.</p> <p>Option 3 is incorrect due to the fact that there is no direct way to encrypt an already existing unencrypted volume that you have created. You can only do it by enabling encryption during the time when you created the EBS Volume.</p> <p>Option 4 is incorrect because you cannot encrypt an EBS Volume using IAM.</p> <p>&nbsp;</p> <p>References:&nbsp;</p> <p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', '', ''], 'answers': ['Encrypt the EBS volume using the S3 server-side encryption service.', 'Encrypt the EBS volume using the S3 client-side encryption service.', 'Create the EBS Volume first and attach it to the instance then enable encryption.', 'In IAM, create a new policy that disallows any read and write access to the EBS volume.', 'Create an encrypted EBS Volume by ticking the encryption tickbox and attach it to the instance.'], 'relatedLectureIds': '', 'question': 'You have an existing On-demand EC2 instance and you are planning to create a new EBS volume that will be attached to this instance. The data that will be stored are confidential medical records so you have to make sure that the data is protected. <br><br>How can you secure the data at rest of the new EBS volume that you will create?'}, 'related_lectures': [], 'correct_response': ['e'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are managing a global news website which has a very high traffic. To improve the performance, you redesigned the application architecture to use a Classic Load Balancer with an Auto Scaling Group in multiple Availability Zones. However, you noticed that one of the Availability Zones is not receiving any traffic. What is the root cause of this issue?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180934, 'original_assessment_id': 2567288, 'section': 'ELB', 'prompt': {'explanation': '<p>In this scenario, one of the Availability Zones is not properly added to the Elastic load balancer. Hence, that&nbsp;Availability Zone is not receiving any traffic.</p><p>You can set up your load balancer in EC2-Classic to distribute incoming requests across EC2 instances in a single Availability Zone or multiple Availability Zones. First, launch EC2 instances in all the Availability Zones that you plan to use. Next, register these instances with your load balancer. Finally, add the Availability Zones to your load balancer. After you add an Availability Zone, the load balancer starts routing requests to the registered instances in that Availability Zone. Note that you can modify the Availability Zones for your load balancer at any time.</p><p>By default, the load balancer routes requests evenly across its Availability Zones. To route requests evenly across the registered instances in the Availability Zones, enable cross-zone load balancing.&nbsp;</p><p>&nbsp;</p><p>Resources:</p><p><a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/enable-disable-az.html">https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/enable-disable-az.html</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['Auto Scaling should be disabled for the load balancer to route the traffic to multiple Availability Zones.', 'By default, you are not allowed to use a load balancer with multiple Availability Zones. You have to send a request form to AWS in order for this to work.', 'The Availability Zone is not properly added to the load balancer which is why it is not receiving any traffic.', 'The Classic Load Balancer is down'], 'relatedLectureIds': '', 'question': 'You are managing a global news website which has a very high traffic. To improve the performance, you redesigned the application architecture to use a Classic Load Balancer with an Auto Scaling Group in multiple Availability Zones. However, you noticed that one of the Availability Zones is not receiving any traffic. What is the root cause of this issue?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A leading media company has recently adopted a hybrid cloud architecture which requires them to migrate their application servers and databases in AWS. One of their applications requires a heterogeneous database migration in which you need to transform your on-premise Oracle database to PostgreSQL in AWS. This entails a schema and code transformation before the proper data migration starts.\xa0 \xa0Which of the following options is the most suitable approach to migrate the database in AWS?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180936, 'original_assessment_id': 2567290, 'section': 'Database Migration Service', 'prompt': {'explanation': '<p>AWS Database Migration Service helps you migrate databases to AWS quickly and securely. The source database remains fully operational during the migration, minimizing downtime to applications that rely on the database. The AWS Database Migration Service can migrate your data to and from most widely used commercial and open-source databases.</p> <p>AWS Database Migration Service can migrate your data to and from most of the widely used commercial and open source databases. It supports homogeneous migrations such as Oracle to Oracle, as well as heterogeneous migrations between different database platforms, such as Oracle to Amazon Aurora. Migrations can be from on-premises databases to Amazon RDS or Amazon EC2, databases running on EC2 to RDS, or vice versa, as well as from one RDS database to another RDS database. It can also move data between SQL, NoSQL, and text based targets.</p> <p>In heterogeneous database migrations the source and target databases engines are different, like in the case of Oracle to Amazon Aurora, Oracle to PostgreSQL, or Microsoft SQL Server to MySQL migrations. In this case, the schema structure, data types, and database code of source and target databases can be quite different, requiring a schema and code transformation before the data migration starts. That makes heterogeneous migrations a two step process. First use the AWS Schema Conversion Tool to convert the source schema and code to match that of the target database, and then use the AWS Database Migration Service to migrate data from the source database to the target database. All the required data type conversions will automatically be done by the AWS Database Migration Service during the migration. The source database can be located in your own premises outside of AWS, running on an Amazon EC2 instance, or it can be an Amazon RDS database. The target can be a database in Amazon EC2 or Amazon RDS.</p> <p>Option 1 is incorrect because Launch templates are primarily used in EC2 to enable you to store launch parameters so that you do not have to specify them every time you launch an instance.</p> <p>Option 3 is incorrect because Amazon Neptune is a fully-managed graph database service and not a suitable service to use to convert the source schema. AWS Batch is not a database migration service and hence, it is not suitable to be used in this scenario. You should use the AWS Schema Conversion Tool and AWS Database Migration Service instead.</p> <p>Option 4 is incorrect because heterogeneous database migration is supported in AWS using the Database Migration Service.</p> <p><strong>References:</strong></p> <p><a href="https://aws.amazon.com/dms/ ">https://aws.amazon.com/dms/ </a></p> <p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-launch-templates.html ">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-launch-templates.html </a></p> <p><a href="https://aws.amazon.com/batch/">https://aws.amazon.com/batch/</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p>Configure a Launch Template that automatically converts the source schema and code to match that of the target database. Then, use the AWS Database Migration Service to migrate data from the source database to the target database.\xa0 </p>', '<p>First, use the AWS Schema Conversion Tool to convert the source schema and code to match that of the target database, and then use the AWS Database Migration Service to migrate data from the source database to the target database.\xa0 </p>', '<p>Use Amazon Neptune to convert the source schema and code to match that of the target database in RDS. Use the AWS Batch to effectively migrate the data from the source database to the target database in a batch process.\xa0 </p>', '<p>Heterogeneous database migration is not supported in AWS. You have to transform your database first to PostgreSQL and then migrate it to RDS.\xa0 </p>'], 'relatedLectureIds': '', 'question': '<p>A leading media company has recently adopted a hybrid cloud architecture which requires them to migrate their application servers and databases in AWS. One of their applications requires a heterogeneous database migration in which you need to transform your on-premise Oracle database to PostgreSQL in AWS. This entails a schema and code transformation before the proper data migration starts.\xa0 \xa0</p><p>Which of the following options is the most suitable approach to migrate the database in AWS?\xa0 </p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You recently launched a fleet of on-demand EC2 instances to host a massively multiplayer online role-playing\xa0game\xa0(MMORPG) server\xa0in your VPC. The EC2 instances are configured with Auto Scaling and\xa0AWS Systems Manager.\xa0What can you use to configure your EC2 instances without having to establish a RDP or SSH connection to each instance?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180938, 'original_assessment_id': 2567292, 'section': 'EC2', 'prompt': {'explanation': '<p>You can use Run Command from the console to configure instances without having to login to each instance.</p><p>AWS Systems Manager Run Command lets you remotely and securely manage the configuration of your managed instances. A&nbsp;<em>managed instance</em>&nbsp;is any Amazon EC2 instance or on-premises machine in your hybrid environment that has been configured for Systems Manager. Run Command enables you to automate common administrative tasks and perform ad hoc configuration changes at scale. You can use Run Command from the AWS console, the AWS Command Line Interface, AWS Tools for Windows PowerShell, or the AWS SDKs. Run Command is offered at no additional cost.</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/execute-remote-commands.html">https://docs.aws.amazon.com/systems-manager/latest/userguide/execute-remote-commands.html</a></p><p>&nbsp;</p><p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'answers': ['AWS Config', 'AWS CodePipeline', '<p>Run Command</p>', 'EC2Config'], 'relatedLectureIds': '', 'question': '<p>You recently launched a fleet of on-demand EC2 instances to host a massively multiplayer online role-playing\xa0game\xa0(MMORPG) server\xa0in your VPC. The EC2 instances are configured with Auto Scaling and\xa0AWS Systems Manager.\xa0What can you use to configure your EC2 instances without having to establish a RDP or SSH connection to each instance?</p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A Dedicated EC2 instance retrieves a message from an SQS queue and begins processing the message. After five minutes, the instance crashes. What happens to the message?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180940, 'original_assessment_id': 2567294, 'section': 'SQS', 'prompt': {'explanation': '<p>When a consumer receives and processes a message from a queue, the message remains in the queue. Amazon SQS doesn\'t automatically delete the message. Because Amazon SQS is a distributed system, there\'s no guarantee that the consumer actually receives the message (for example, due to a connectivity issue, or due to an issue in the consumer application). Thus, the consumer must delete the message from the queue after receiving and processing it.</p><p>Immediately after the message is received, it remains in the queue. To prevent other consumers from processing the message again, Amazon SQS sets a&nbsp;<em>visibility timeout</em>, a period of time during which Amazon SQS prevents other consumers from receiving and processing the message. The default visibility timeout for a message is 30 seconds. The maximum is 12 hours.</p><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html">http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html</a></p><p>&nbsp;</p>', 'answers': ['When the message visibility timeout expires, the message becomes available for processing by other EC2 instances', 'It will remain in the queue and still assigned to same EC2 instances when instances become online within the visibility timeout.', 'The message is deleted and becomes duplicated in the SQS when the EC2 instance comes online.'], 'question': 'A Dedicated EC2 instance retrieves a message from an SQS queue and begins processing the message. After five minutes, the instance crashes. <br /><br />What happens to the message?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are an IT Consultant for a top investment bank which is in the process of building its new Forex trading platform. To ensure high availability and scalability, you designed the trading platform to use an Elastic Load Balancer in front of an Auto Scaling group of On-Demand EC2 instances across multiple Availability Zones. For its database tier, you chose to use a single Amazon Aurora instance to take advantage of its distributed, fault-tolerant and self-healing storage system.\xa0 In the event of system failure on the primary database instance, what happens to Amazon Aurora during the failover?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6181002, 'original_assessment_id': 2567358, 'section': 'Aurora', 'prompt': {'explanation': '<p>Failover is automatically handled by Amazon Aurora so that your applications can resume database operations as quickly as possible without manual administrative intervention.</p> <p>If you have an Amazon Aurora Replica in the same or a different Availability Zone, when failing over, Amazon Aurora flips the canonical name record (CNAME) for your DB Instance to point at the healthy replica, which in turn is promoted to become the new primary. Start-to-finish, failover typically completes within 30 seconds.</p> <p>If you do not have an Amazon Aurora Replica (i.e. single instance), Aurora will first attempt to create a new DB Instance in the same Availability Zone as the original instance. If unable to do so, Aurora will attempt to create a new DB Instance in a different Availability Zone. From start to finish, failover typically completes in under 15 minutes.</p> <p>Hence, the correct answer is Option 2.</p> <p>Options 1 and 3 are incorrect because this will only happen if you are using an Amazon Aurora Replica. In addition, Amazon Aurora flips the canonical name record (CNAME) and not the A record (IP address) of the instance.</p> <p>Option 4 is incorrect because Aurora will first attempt to create a new DB Instance in the same Availability Zone as the original instance. If unable to do so, Aurora will attempt to create a new DB Instance in a different Availability Zone and not the other way around.</p> <p>&nbsp;</p> <p><strong>Reference: </strong></p> <p><a href="https://aws.amazon.com/rds/aurora/faqs/">https://aws.amazon.com/rds/aurora/faqs/</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p>Amazon Aurora flips the canonical name record (CNAME) for your DB Instance to point at the healthy replica, which in turn is promoted to become the new primary.</p>', '<p>Aurora will first attempt to create a new DB Instance in the same Availability Zone as the original instance. If unable to do so, Aurora will attempt to create a new DB Instance in a different Availability Zone.</p>', '<p>Amazon Aurora flips the A record of your DB Instance to point at the healthy replica, which in turn is promoted to become the new primary.</p>', '<p>Aurora will first attempt to create a new DB Instance in a different Availability Zone of the original instance. If unable to do so, Aurora will attempt to create a new DB Instance in the original Availability Zone in which the instance was first launched.</p>'], 'relatedLectureIds': '', 'question': '<p>You are an IT Consultant for a top investment bank which is in the process of building its new Forex trading platform. To ensure high availability and scalability, you designed the trading platform to use an Elastic Load Balancer in front of an Auto Scaling group of On-Demand EC2 instances across multiple Availability Zones. For its database tier, you chose to use a single Amazon Aurora instance to take advantage of its distributed, fault-tolerant and self-healing storage system.\xa0 </p><p>In the event of system failure on the primary database instance, what happens to Amazon Aurora during the failover?</p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have a web application hosted on a fleet of EC2 instances located in two Availability Zones that are all placed behind an Application Load Balancer. As a Solutions Architect, you have to add a health check configuration to ensure your application is highly-available.Which health checks will you implement?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180942, 'original_assessment_id': 2567296, 'section': 'ELB', 'prompt': {'explanation': '<p>The type of ELB that is mentioned here is an Application Elastic Load Balancer. This is used if you want a flexible feature set for your web applications with HTTP and HTTPS traffic. Conversely, it only allows 2 types of health check: HTTP and HTTPS.</p><p>Options 2 and 3 are incorrect as FTP and ICMP health checks are not supported.</p><p>Option 4 is incorrect. A TCP health check is only offered in Network Load Balancer, which is another type of ELB. It is used if you need ultra-high performance and static IP addresses for your application.</p><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-healthchecks.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-healthchecks.html</a></p>', 'answers': ['HTTP or HTTPS health check', 'ICMP health check', 'FTP health check', 'TCP health check'], 'question': 'You have a web application hosted on a fleet of EC2 instances located in two Availability Zones that are all placed behind an Application Load Balancer. As a Solutions Architect, you have to add a health check configuration to ensure your application is highly-available.<br /><br />Which health checks will you implement?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'In a startup company you are working for, you are asked to design a web application that requires a NoSQL database. The startup is still new in the market and it has very limited human resources available who can take care of the database infrastructure. Which Amazon service provides a fully managed and highly available NoSQL service?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180944, 'original_assessment_id': 2567298, 'section': 'DynamoDB', 'prompt': {'explanation': '<p>The term "fully managed" means that Amazon will manage the underlying infrastructure of the service hence, you don\'t need an additional human resource to support or maintain the service. Therefore,&nbsp;Amazon DynamoDB is the right answer. Remember that Amazon RDS is a managed service but not "fully managed" as you still have the option to maintain and configure the underlying server of the database.</p><p>Amazon DynamoDB is a fast and flexible NoSQL database service for all applications that need consistent, single-digit millisecond latency at any scale. It is a fully managed cloud database and supports both document and key-value store models. Its flexible data model, reliable performance, and automatic scaling of throughput capacity makes it a great fit for mobile, web, gaming, ad tech, IoT, and many other applications.</p><p>&nbsp;</p><p>Resources:</p><p><a href="https://aws.amazon.com/dynamodb/">https://aws.amazon.com/dynamodb/</a></p><p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'answers': ['DynamoDB', '<p>Elastic Map Reduce</p>', 'Amazon RDS', 'SimpleDB'], 'relatedLectureIds': '', 'question': 'In a startup company you are working for, you are asked to design a web application that requires a NoSQL database. The startup is still new in the market and it has very limited human resources available who can take care of the database infrastructure. <br><br>Which Amazon service provides a fully managed and highly available NoSQL service?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multi-select', 'question_plain': 'A web application is deployed in an On-Demand EC2 instance in your VPC. There is an issue with the application which requires you to connect to it via an SSH connection. Which of the following is needed in order to access an EC2 instance from the Internet? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6181004, 'original_assessment_id': 2567360, 'section': 'VPC', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['An Internet Gateway (IGW) attached to the VPC.', 'A Private IP address attached to the EC2 instance.', 'A Private Elastic IP address attached to the EC2 instance.', 'A VPN Peering connection.', 'A route entry to the Internet gateway in the Route table of the VPC.', 'A Public IP address attached to the EC2 instance.'], 'explanation': '<p>Options 1, 5, and 6 are the correct answers. In order for you to access your EC2 instance from the Internet, you need to have:&nbsp;</p> <ol> <li>An Internet Gateway (IGW) attached to the VPC.</li> <li>A route entry to the Internet gateway in the Route table of the VPC.</li> <li>A Public IP address attached to the EC2 instance.</li> </ol> <p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://docs.aws.amazon.com/vpc/latest/userguide/images/scenario-1-ipv6-diagram.png" alt="" width="508" height="401" /></p> <p>Option 2 is incorrect as you only use a Private IP inside your VPC.</p> <p>Option 3 is incorrect as an Elastic IP Address is a public IPv4 address, not private. It is reachable from the Internet and is designed for dynamic cloud computing.</p> <p>Option 4 is incorrect as you only use VPC Peering to connect two VPCs.</p> <p><strong>Reference:</strong></p> <p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario1.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario1.html</a></p>', 'question': '<p>A web application is deployed in an On-Demand EC2 instance in your VPC. There is an issue with the application which requires you to connect to it via an SSH connection. Which of the following is needed in order to access an EC2 instance from the Internet? (Choose 3)</p>'}, 'related_lectures': [], 'correct_response': ['a', 'e', 'f'], 'updated': '2018-11-21T07:59:49Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A news company has been using a Hardware Security Module (CloudHSM) for secure key storage. It is only used for generating keys for their On-demand EC2 instances. After a new support staff attempted to log in as the administrator three times using an invalid password, the Hardware Security Module has been zeroized which means that the encryption keys on it have been wiped. Sadly, You did not have a copy of the keys stored anywhere else. How can you obtain a new copy of the keys that you have stored on Hardware Security Module?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180946, 'original_assessment_id': 2567300, 'section': 'CloudHSM', 'prompt': {'explanation': '<p>Amazon does not have access to your keys nor credentials of your&nbsp;Hardware Security Module (HSM) and therefore has no way to recover your keys if you lose your credentials.&nbsp;Amazon strongly recommends that you use two or more HSMs in separate Availability Zones in any production CloudHSM Cluster to avoid loss of cryptographic keys.</p> <p>Refer to the CloudHSM FAQs for reference:&nbsp;</p> <p><strong>Q: Could I lose my keys if a single HSM instance fails?</strong></p> <p>Yes. It is possible to lose keys that were created since the most recent daily backup if the CloudHSM cluster that you are using fails and you are not using two or more HSMs. Amazon strongly recommends that you use two or more HSMs, in separate Availability Zones, in any production CloudHSM Cluster to avoid loss of cryptographic keys.</p> <p><strong>Q: Can Amazon recover my keys if I lose my credentials to my HSM?</strong></p> <p>No. Amazon does not have access to your keys or credentials and therefore has no way to recover your keys if you lose your credentials.</p> <p>&nbsp;</p> <p>References:</p> <p><a href="https://aws.amazon.com/cloudhsm/faqs/">https://aws.amazon.com/cloudhsm/faqs/</a></p> <p><a href="https://d1.awsstatic.com/whitepapers/Security/security-of-aws-cloudhsm-backups.pdf">https://d1.awsstatic.com/whitepapers/Security/security-of-aws-cloudhsm-backups.pdf</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'answers': ['Restore a snapshot of the Hardware Security Module.', 'Contact AWS Support and they will provide you a copy of the keys.', 'The keys are lost permanently if you did not have a copy.', 'Use the Amazon CLI to get a copy of the keys.'], 'relatedLectureIds': '', 'question': 'A news company has been using a Hardware Security Module (CloudHSM) for secure key storage. It is only used for generating keys for their On-demand EC2 instances. After a new support staff attempted to log in as the administrator three times using an invalid password, the Hardware Security Module has been zeroized which means that the encryption keys on it have been wiped. Sadly, You did not have a copy of the keys stored anywhere else. <br><br>How can you obtain a new copy of the keys that you have stored on Hardware Security Module?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You created a new CloudFormation template that creates 4 EC2 instances and are connected to one Elastic Load Balancer (ELB). Which section of the template should you configure to get the Domain Name Server hostname of the ELB upon the creation of the AWS stack?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180948, 'original_assessment_id': 2567302, 'section': 'Cloudformation', 'prompt': {'explanation': '<div><p><strong>Outputs</strong>&nbsp;is an optional section of the CloudFormation template that describes the values that are returned whenever you view your stack\'s properties.&nbsp;</p><p>&nbsp;</p></div><p>References:</p><p><a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.html</a></p><p><a href="https://aws.amazon.com/cloudformation/" target="_blank" rel="noopener">https://aws.amazon.com/cloudformation/</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['Resources', 'Parameters', 'Outputs', 'Mappings'], 'relatedLectureIds': '', 'question': 'You created a new CloudFormation template that creates 4 EC2 instances and are connected to one Elastic Load Balancer (ELB). Which section of the template should you configure to get the Domain Name Server hostname of the ELB upon the creation of the AWS stack?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as an IT Consultant for a large financial firm. They have a requirement to store irreproducible financial documents using Amazon S3. For their quarterly reporting, the files are required to be retrieved after a period of 3 months. There will be some occasions when a surprise audit will be held, which requires access to the archived data that they need to present immediately. What will you do to satisfy this requirement in a cost-effective way?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180950, 'original_assessment_id': 2567304, 'section': 'Storage Gateway', 'prompt': {'explanation': '<p>In this scenario, the requirement is to have a storage option that is&nbsp;cost-effective and has the ability to access or retrieve the archived data within an hour. The cost-effective options are Amazon Glacier and Amazon S3 Standard- Infrequent Access (Standard - IA). However, the former option is not designed for rapid retrieval of data which is required for the surprise audit. Hence, option 4 is wrong and the best answer is option 2:&nbsp;Standard - IA.</p><p>Option 1 is incorrect because the standard storage class is not cost-efficient in this scenario.</p><p>Option 3 is incorrect because the RRS option is not designed to store irreproducible data due to its low durability.</p><p>Amazon S3 Standard - Infrequent Access is an Amazon S3 storage class for data that is accessed less frequently, but requires rapid access when needed. Standard - IA offers the high durability, throughput, and low latency of Amazon S3 Standard, with a low per GB storage price and per GB retrieval fee.</p><p>This combination of low cost and high performance makes Standard - IA ideal for long-term storage, backups, and as a data store for disaster recovery. The Standard - IA storage class is set at the object level and can exist in the same bucket as Standard, allowing you to use lifecycle policies to automatically transition objects between storage classes without any application changes.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/s3/storage-classes/">https://aws.amazon.com/s3/storage-classes/</a></p><p><a href="https://aws.amazon.com/s3/faqs/">https://aws.amazon.com/s3/faqs/</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['Use Amazon S3 Standard', 'Use Amazon S3 Standard - Infrequent Access', 'Use Amazon S3 - Reduced Redundancy Storage (RRS)', 'Use Amazon Glacier'], 'relatedLectureIds': '', 'question': '<p>You are working as an IT Consultant for a large financial firm. They have a requirement to store irreproducible financial documents using Amazon S3. For their quarterly reporting, the files are required to be retrieved after a period of 3 months. There will be some occasions when a surprise audit will be held, which requires access to the archived data that they need to present immediately. <br><br>What will you do to satisfy this requirement in a cost-effective way?</p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'An On-Demand EC2 instance is launched into a VPC subnet with the Network ACL configured to allow all inbound traffic and deny all outbound traffic.\xa0The instance’s security group has an inbound rule to allow SSH from any IP address and does not have any outbound rules.\xa0In this scenario, what are the changes needed to allow SSH connection to the instance?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180952, 'original_assessment_id': 2567306, 'section': 'Security', 'prompt': {'explanation': '<p>In order for you to establish an SSH connection from your home computer to your EC2 instance, you need to do the following:</p> <ul> <li>On the Security Group, add an Inbound Rule to allow SSH traffic to your EC2 instance.&nbsp;</li> <li>On the NACL, add both an Inbound and Outbound Rule to allow SSH traffic to your EC2 instance.&nbsp;</li> </ul> <p>&nbsp;</p> <p>The reason why you have to add both Inbound and Outbound SSH rule is due to the fact that Network ACLs are stateless which means that responses to allow inbound traffic are subject to the rules for outbound traffic (and vice versa). In other words, if you only enabled an Inbound rule in NACL, the traffic can only go in but the SSH response will not go out since there is no Outbound rule.</p> <p>Security groups are stateful&nbsp;which means that if an incoming request is granted, then the outgoing traffic will be automatically granted as well,&nbsp;regardless of the outbound rules.</p> <p>&nbsp;</p> <p>References:&nbsp;</p> <p><a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_ACLs.html">https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_ACLs.html</a></p> <p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/authorizing-access-to-an-instance.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/authorizing-access-to-an-instance.html</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['The outbound security group needs to be modified to allow outbound traffic.', 'The outbound network ACL needs to be modified to allow outbound traffic.', 'No action needed. It can already be accessed from any IP address using SSH.', 'Both the outbound security group and outbound network ACL need to be modified to allow outbound traffic.'], 'relatedLectureIds': '', 'question': '<p>An On-Demand EC2 instance is launched into a VPC subnet with the Network ACL configured to allow all inbound traffic and deny all outbound traffic.\xa0The instance’s security group has an inbound rule to allow SSH from any IP address and does not have any outbound rules.\xa0<br></p><p>In this scenario, what are the changes needed to allow SSH connection to the instance?</p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'In Amazon SQS, what is a period of time during which the SQS queue prevents other consuming components from receiving and processing a message?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6181000, 'original_assessment_id': 2567356, 'section': 'SQS', 'prompt': {'explanation': '<p>The visibility timeout is a period of time during which Amazon SQS prevents other consuming components from receiving and processing a message.&nbsp;</p><p>When a consumer receives and processes a message from a queue, the message remains in the queue. Amazon SQS doesn\'t automatically delete the message. Because Amazon SQS is a distributed system, there\'s no guarantee that the consumer actually receives the message (for example, due to a connectivity issue, or due to an issue in the consumer application). Thus, the consumer must delete the message from the queue after receiving and processing it.</p><p>Immediately after the message is received, it remains in the queue. To prevent other consumers from processing the message again, Amazon SQS sets a&nbsp;<strong><em>visibility timeout</em></strong>, a period of time during which Amazon SQS prevents other consumers from receiving and processing the message. The default visibility timeout for a message is 30 seconds. The maximum is 12 hours.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/sqs/faqs/">https://aws.amazon.com/sqs/faqs/</a></p><p><a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html">https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html</a></p><p>&nbsp;</p>', 'answers': ['Component Timeout', 'Visibility Timeout', 'Processing Timeout', 'Receiving Timeout'], 'question': 'In Amazon SQS, what is a period of time during which the SQS queue prevents other consuming components from receiving and processing a message?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are consulted by a multimedia company that needs to deploy web services to an AWS region which they have not used before. The company currently has an IAM role for their Amazon EC2 instance which permits the instance to access Amazon DynamoDB. They want their EC2 instances in the new region to have the exact same privileges. What should you do to accomplish this?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180954, 'original_assessment_id': 2567308, 'section': 'S3', 'prompt': {'explanation': '<p>In this scenario, the company has an existing IAM role hence you don&rsquo;t need to create a new one. IAM roles are global service that are available to all regions hence, all you have to do is assign the existing IAM role to the instance in the new region.&nbsp;</p><p>Option 1 is incorrect because you don\'t need to create another IAM role - there is already an existing one.</p><p>Option 3 is incorrect as you don\'t need duplicate IAM roles&nbsp;for each region. One IAM role suffices for the instances on two regions.</p><p>Option 4 is incorrect because creating an AMI image does not affect the IAM role of the instance.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html">https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html</a></p>', 'answers': ['In the new Region, create a new IAM role and associated policies then assign it to the new instance.', 'Assign the existing IAM role to instances in the new region.', 'Duplicate the IAM role and associated policies to the new region and attach it to the instances.', 'Create an Amazon Machine Image (AMI) of the instance and copy it to the new region.'], 'question': 'You are consulted by a multimedia company that needs to deploy web services to an AWS region which they have not used before. The company currently has an IAM role for their Amazon EC2 instance which permits the instance to access Amazon DynamoDB. They want their EC2 instances in the new region to have the exact same privileges. <br /><br />What should you do to accomplish this?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A financial company wants to store their data in Amazon S3 but at the same time, they want to store their frequently accessed data locally on their on-premise server. This is due to the fact that they do not have the option to extend their on-premise storage, which is why they are looking for a durable and scalable storage service to use in AWS. What is the best solution for this scenario?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180956, 'original_assessment_id': 2567310, 'section': 'Storage Gateway', 'prompt': {'explanation': '<p>By using&nbsp;Cached volumes, you store your data in Amazon Simple Storage Service (Amazon S3) and retain a copy of frequently accessed data subsets locally in your on-premise network. Cached volumes offer substantial cost savings on primary storage and minimize the need to scale your storage on-premises. You also retain low-latency access to your frequently accessed data. This is the best solution for this scenario.</p><p>&nbsp;</p><p>Option 1 is incorrect because an EC2 instance is not a storage service and it does not provide the required durability and scalability.</p><p>Option 2 is incorrect as storing frequently accessed data on both&nbsp;Elasticache and S3 is not efficient. Moreover, the question explicitly said that the frequently accessed data should be stored locally on their on-premise server and not on AWS.</p><p>Option 4 is incorrect as Amazon Glacier is mainly used for data archiving.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/storagegateway/faqs/ ">https://aws.amazon.com/storagegateway/faqs/ </a></p><p>&nbsp;</p>', 'answers': ['Use a fleet of EC2 instance with EBS volumes to store the commonly used data.', 'Use both Elasticache and S3 for frequently accessed data.', 'Use the Amazon Storage Gateway -  Cached Volumes.', 'Use Amazon Glacier.'], 'question': 'A financial company wants to store their data in Amazon S3 but at the same time, they want to store their frequently accessed data locally on their on-premise server. This is due to the fact that they do not have the option to extend their on-premise storage, which is why they are looking for a durable and scalable storage service to use in AWS. <br /><br />What is the best solution for this scenario?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as a Solutions Architect for a leading technology company where you are instructed to troubleshoot the operational issues of your cloud architecture by logging the AWS API call history of your AWS resources. You need to quickly identify the most recent changes made to resources in your environment, including creation, modification, and deletion of AWS resources. One of the requirements is that the generated log files should be encrypted to avoid any security issues.\xa0 \xa0Which of the following is the most suitable approach to implement the encryption?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180974, 'original_assessment_id': 2567328, 'section': 'CloudTrail', 'prompt': {'explanation': '<p>By default, CloudTrail event log files are encrypted using Amazon S3 server-side encryption (SSE). You can also choose to encrypt your log files with an AWS Key Management Service (AWS KMS) key. You can store your log files in your bucket for as long as you want. You can also define Amazon S3 lifecycle rules to archive or delete log files automatically. If you want notifications about log file delivery and validation, you can set up Amazon SNS notifications.</p> <p>&nbsp;</p> <p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://media.amazonwebservices.com/blog/2014/cloudtrail_flow_9.png" alt="" width="750" height="711" /></p> <p>Option 1 is incorrect because CloudTrail stores the log files to S3 and not in Glacier. Take note that by default,&nbsp;CloudTrail event log files are already encrypted using Amazon S3 server-side encryption (SSE).</p> <p>Option 2 is incorrect because&nbsp;CloudTrail event log files are already encrypted using the Amazon S3 server-side encryption (SSE) which is why you do not have to do this anymore.</p> <p>Option 3 is incorrect because there is no available Server-Side Encryption (SSE) option in the CloudTrail console.</p> <p><strong>References:</strong></p> <p><a href="https://docs.aws.amazon.com/awscloudtrail/latest/userguide/how-cloudtrail-works.html">https://docs.aws.amazon.com/awscloudtrail/latest/userguide/how-cloudtrail-works.html</a></p> <p><a href="https://aws.amazon.com/blogs/aws/category/cloud-trail/">https://aws.amazon.com/blogs/aws/category/cloud-trail/</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p>Use CloudTrail and configure the destination Amazon Glacier archive to use Server-Side Encryption (SSE).</p>', '<p>Use CloudTrail and configure the destination S3 bucket to use Server-Side Encryption (SSE).</p>', '<p>Use CloudTrail and ensure that the Server-Side Encryption (SSE) option is enabled for the trail in the CloudTrail console.</p>', '<p>Use CloudTrail with its default settings</p>'], 'relatedLectureIds': '', 'question': '<p>You are working as a Solutions Architect for a leading technology company where you are instructed to troubleshoot the operational issues of your cloud architecture by logging the AWS API call history of your AWS resources. You need to quickly identify the most recent changes made to resources in your environment, including creation, modification, and deletion of AWS resources. One of the requirements is that the generated log files should be encrypted to avoid any security issues.\xa0 \xa0</p><p>Which of the following is the most suitable approach to implement the encryption?</p>'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:50:10Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are running an EC2 instance store-based instance. You shut it down and then start the instance. You noticed that the data which you have saved earlier is no longer available. What might be the cause of this?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180958, 'original_assessment_id': 2567312, 'section': 'EC2', 'prompt': {'explanation': '<p>An&nbsp;<em>instance store</em>&nbsp;provides temporary block-level storage for your instance. This storage is located on disks that are physically attached to the host computer. Instance store is ideal for temporary storage of information that changes frequently, such as buffers, caches, scratch data, and other temporary content, or for data that is replicated across a fleet of instances, such as a load-balanced pool of web servers.</p><p>An instance store consists of one or more instance store volumes exposed as block devices. The size of an instance store as well as the number of devices available varies by instance type. While an instance store is dedicated to a particular instance, the disk subsystem is shared among instances on a host computer.</p><p>The data in an instance store persists only during the lifetime of its associated instance. If an instance reboots (intentionally or unintentionally), data in the instance store persists. However, data in the instance store is lost under the following circumstances:</p><ul><li>-The underlying disk drive fails</li><li>-The instance stops</li><li>-The instance terminates</li></ul><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html</a></p>', 'answers': ['The volume of the instance was not big enough to handle all of the processing data.', 'The EC2 instance was using EBS backed root volumes, which are ephemeral and only live for the life of the instance.', 'The EC2 instance was using instance store volumes, which are ephemeral and only live for the life of the instance.', 'The instance was hit by a virus that wipes out all data.'], 'question': 'You are running an EC2 instance store-based instance. You shut it down and then start the instance. You noticed that the data which you have saved earlier is no longer available. <br /><br />What might be the cause of this?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are planning to migrate a MySQL database from your on-premise data center to your AWS Cloud. This database will be used by a legacy batch application which has steady-state workloads in the morning but has its peak load at night for the end-of-day processing. You need to choose an EBS volume which can handle a maximum of 450 GB of data and can also be used as the system boot volume for your EC2 instance.\xa0 Which of the following is the most cost-effective storage type to use in this scenario?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180960, 'original_assessment_id': 2567314, 'section': 'EBS', 'prompt': {'explanation': '<p>General Purpose SSD (<code class="code">gp2</code>) volumes offer cost-effective storage that is ideal for a broad range of workloads. These volumes deliver single-digit millisecond latencies and the ability to burst to 3,000 IOPS for extended periods of time. Between a minimum of 100 IOPS (at 33.33 GiB and below) and a maximum of 10,000 IOPS (at 3,334 GiB and above), baseline performance scales linearly at 3 IOPS per GiB of volume size. AWS designs&nbsp;<code class="code">gp2</code>&nbsp;volumes to deliver the provisioned performance 99% of the time. A&nbsp;<code class="code">gp2</code>&nbsp;volume can range in size from 1 GiB to 16 TiB.</p> <p>&nbsp;</p> <p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/images/gp2-burst-bucket.png" alt="" width="226" height="265" /></p> <p>Option 1 is incorrect because Amazon EBS Provisioned IOPS SSD is not the most cost-effective EBS type and is primarily used for critical business applications that require sustained IOPS performance.</p> <p>Option 2 is incorrect because Amazon EBS Throughput Optimized HDD is primarily used for frequently accessed, throughput-intensive workloads. Although it is a low-cost HDD volume, it cannot be used as a system boot volume.</p> <p>Option 4 is incorrect because although Amazon EBS Cold HDD provides the lowest cost HDD volume compared to General Purpose SSD, it cannot be used as a system boot volume.</p> <p><strong>Reference:</strong></p> <p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html#EBSVolumeTypes_gp2">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html#EBSVolumeTypes_gp2</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p>Amazon EBS Provisioned IOPS SSD</p>', '<p>Amazon EBS Throughput Optimized HDD</p>', '<p>Amazon EBS General Purpose SSD</p>', '<p>Amazon EBS Cold HDD</p>'], 'relatedLectureIds': '', 'question': '<p>You are planning to migrate a MySQL database from your on-premise data center to your AWS Cloud. This database will be used by a legacy batch application which has steady-state workloads in the morning but has its peak load at night for the end-of-day processing. You need to choose an EBS volume which can handle a maximum of 450 GB of data and can also be used as the system boot volume for your EC2 instance.\xa0 </p><p>Which of the following is the most cost-effective storage type to use in this scenario?</p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:46:05Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are a working as a Solutions Architect for a fast-growing startup company which just started operations during the past 3 months. They currently have an on-premise Active Directory and 10 computers. To save costs in procuring physical workstations, they decided to deploy virtual desktops for their new employees in a virtual private cloud in AWS. The new cloud infrastructure should leverage on the existing security controls in AWS but can still communicate with their on-premise network.Which set of AWS services will you use to meet these requirements?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180962, 'original_assessment_id': 2567316, 'section': 'Directory Service', 'prompt': {'explanation': '<p>For this scenario, the best choice is Option 2: AWS Directory Services, VPN connection, and Amazon Workspaces. First, you need a&nbsp;VPN connection to connect the VPC and your on-premise network. Second, you need AWS Directory Services to integrate with your on-premise Active Directory and lastly, you need to use Amazon Workspace to create the needed virtual desktops in your VPC.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/directoryservice/">https://aws.amazon.com/directoryservice/</a></p><p><a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpn-connections.html">https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpn-connections.html</a></p><p><a href="https://aws.amazon.com/workspaces/">https://aws.amazon.com/workspaces/</a></p>', 'answers': ['AWS Directory Services, VPN connection, and ClassicLink', 'AWS Directory Services, VPN connection, and Amazon Workspaces', 'AWS Directory Services, VPN connection, and AWS Identity and Access Management', 'AWS Directory Services, VPN connection, and Amazon S3'], 'question': 'You are a working as a Solutions Architect for a fast-growing startup company which just started operations during the past 3 months. They currently have an on-premise Active Directory and 10 computers. To save costs in procuring physical workstations, they decided to deploy virtual desktops for their new employees in a virtual private cloud in AWS. The new cloud infrastructure should leverage on the existing security controls in AWS but can still communicate with their on-premise network.<br /><br />Which set of AWS services will you use to meet these requirements?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multi-select', 'question_plain': 'Which of the following items should be done in order to add an existing EC2 instance to an Auto Scaling group? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180986, 'original_assessment_id': 2567340, 'section': 'Auto Scaling', 'prompt': {'explanation': '<p>Amazon EC2 Auto Scaling provides you with an option to enable automatic scaling for one or more EC2 instances by attaching them to your existing Auto Scaling group. After the instances are attached, they become a part of the Auto Scaling group.</p><p>The instance that you want to attach must meet the following criteria:</p><div><ul><li>-The instance is in the&nbsp;<code>running</code>&nbsp;state.</li><li>-The AMI used to launch the instance must still exist.</li><li>-The instance is not a member of another Auto Scaling group.</li><li>-The instance is in the same Availability Zone as the Auto Scaling group.</li><li>-If the Auto Scaling group has an attached load balancer, the instance and the load balancer must both be in EC2-Classic or the same VPC. If the Auto Scaling group has an attached target group, the instance and the load balancer must both be in the same VPC.</li></ul></div><br /><p>Based on the above criteria, Options 2, 3 and 4 are the correct answers:</p><ul><li>-You have to ensure that the AMI used to launch the instance still exists.</li><li>-You have to ensure that the instance is not a member of another Auto Scaling group.&nbsp;</li><li>-You have to ensure that the instance is in the same Availability Zone as the Auto Scaling group.</li></ul><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="http://docs.aws.amazon.com/autoscaling/latest/userguide/attach-instance-asg.html">http://docs.aws.amazon.com/autoscaling/latest/userguide/attach-instance-asg.html</a></p>', 'answers': ['You must stop the instance first.', 'You have to ensure that the AMI used to launch the instance still exists.', 'You have to ensure that the instance is not a member of another Auto Scaling group.', 'You have to ensure that the instance is in the same Availability Zone as the Auto Scaling group.', 'You have to ensure that the instance is in a different Availability Zone as the Auto Scaling group.', 'You have to ensure that the AMI used to launch the instance no longer exists.'], 'question': 'Which of the following items should be done in order to add an existing EC2 instance to an Auto Scaling group? (Choose 3)'}, 'related_lectures': [], 'correct_response': ['b', 'c', 'd'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a large financial company. In their enterprise application, they want to apply a group of database-specific settings to their Relational Database Instances.\xa0 \xa0Which of the following options can be used to easily apply the settings in one go for all of the Relational database instances?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180964, 'original_assessment_id': 2567318, 'section': 'RDS', 'prompt': {'feedbacks': ['', '', '', ''], 'explanation': '<p>You manage your DB engine configuration through the use of parameters in a DB parameter group. DB parameter groups act as a&nbsp;<em>container</em>&nbsp;for engine configuration values that are applied to one or more DB instances.</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithParamGroups.html">https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithParamGroups.html</a></p><p>&nbsp;</p>', 'relatedLectureIds': '', 'answers': ['Security Groups', 'NACL Groups', 'Parameter Groups', 'IAM Roles'], 'question': '<p>You are working for a large financial company. In their enterprise application, they want to apply a group of database-specific settings to their Relational Database Instances.\xa0 \xa0</p><p>Which of the following options can be used to easily apply the settings in one go for all of the Relational database instances?</p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:47:07Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A client is hosting their company website on a cluster of web servers that are behind a public-facing load balancer. The client also uses Amazon Route53 to manage their public DNS. How should the client configure the DNS zone apex record to point to the load balancer?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180966, 'original_assessment_id': 2567320, 'section': 'Route53', 'prompt': {'explanation': '<p>Route53\'s DNS implementation connects user requests to infrastructure running inside (and outside) of Amazon Web Services (AWS). For example, if you have multiple web servers running on Amazon Elastic Compute Cloud (Amazon EC2) instances behind an Elastic Load Balancing load balancer, Route53 will route all traffic addressed to your website (e.g. www.example.com) to the load balancer DNS name (e.g. elb1234.elb.amazonaws.com).</p><p>Additionally, Route53 supports the alias resource record set, which lets you map your zone apex (e.g. example.com) DNS name to your load balancer DNS name. IP addresses associated with Elastic Load Balancing can change at any time due to scaling or software updates. Route53 responds to each request for an alias resource record set with one IP address for the load balancer.</p><p>&nbsp;</p><p>Resources:</p><p><a href="http://docs.aws.amazon.com/govcloud-us/latest/UserGuide/setting-up-route53-zoneapex-elb.html">http://docs.aws.amazon.com/govcloud-us/latest/UserGuide/setting-up-route53-zoneapex-elb.html</a></p><p>&nbsp;</p>', 'answers': ['Create an A record pointing to the IP address of the load balancer.', 'Create a CNAME record pointing to the load balancer DNS name.', 'Create an alias for CNAME record to the load balancer DNS name.', 'Create an A record aliased to the load balancer DNS name.'], 'question': 'A client is hosting their company website on a cluster of web servers that are behind a public-facing load balancer. The client also uses Amazon Route53 to manage their public DNS. <br /><br />How should the client configure the DNS zone apex record to point to the load balancer?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You recently launched a news website which is expected to be visited by millions of people around the world. You chose to deploy the website in AWS to take advantage of its extensive range of cloud services and global infrastructure. Aside from AWS Region and Availability Zones, which of the following is part of the AWS Global Infrastructure that is used for content distribution?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180968, 'original_assessment_id': 2567322, 'section': 'CloudFront', 'prompt': {'explanation': '<p>An edge location helps deliver high availability, scalability, and performance of your application for all of your customers from anywhere in the world. This is used by other services such as Lambda and&nbsp;Amazon CloudFront.</p> <p>Amazon CloudFront is a web service that gives businesses and web application developers an easy and cost-effective way to distribute content with low latency and high data transfer speeds. CloudFront delivers your files to end-users using a global network of edge locations.</p> <p>Option 2 is incorrect because a bastion host is not part of the AWS Global Infrastructure. It is just a host computer or a "jump server" used to allow SSH access to your EC2 instances from an outside network.</p> <p>Option 3 is incorrect because a&nbsp;hypervisor&nbsp;is just a computer software, firmware or hardware that creates and runs virtual machines. This technology relates to EC2 instances but it is not part of the AWS Global Infrastructure.</p> <p>Option 4 is incorrect because VPC Endpoint is not part of the AWS Global Infrastructure and is just used to privately connect your VPC to other AWS services and endpoint services.</p> <p><strong>References:</strong></p> <p><a href="https://aws.amazon.com/cloudfront/">https://aws.amazon.com/cloudfront/</a></p> <p><a href="https://aws.amazon.com/about-aws/global-infrastructure/">https://aws.amazon.com/about-aws/global-infrastructure/</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'answers': ['Edge Location', 'Bastion Hosts', '<p>Hypervisor</p>', '<p>VPC Endpoint</p>'], 'relatedLectureIds': '', 'question': '<p>You recently launched a news website which is expected to be visited by millions of people around the world. You chose to deploy the website in AWS to take advantage of its extensive range of cloud services and global infrastructure. Aside from AWS Region and Availability Zones, which of the following is part of the AWS Global Infrastructure that is used for content distribution?</p>'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:48:11Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'In AWS Elastic Container Service, which of the following are supported?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180970, 'original_assessment_id': 2567324, 'section': 'ECS', 'prompt': {'explanation': '<p>Amazon ECS is a highly scalable <strong>Docker</strong> container management service and it allows you to run and manage distributed applications that run in Docker containers. Since Docker is only the container technology supported in ECS, Options B, C, and D are wrong choices.</p><p>Option 5 is incorrect as Vagrant is not a container but rather, a tool for building and managing virtual machine environments.</p><p>Resources:</p><p><a href="https://aws.amazon.com/ecs/faqs/" target="_blank" rel="noopener">https://aws.amazon.com/ecs/faqs/</a></p>', 'answers': ['Docker', 'Kubernetes', 'Mesosphere', 'OpenShift', 'Vagrant'], 'question': 'In AWS Elastic Container Service, which of the following are supported?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have a web application running on EC2 instances which processes sensitive financial information. All of the data are stored on an Amazon S3 bucket. The financial information is accessed by users over the Internet. The security team of the company is concerned that the Internet connectivity to Amazon S3 is a security risk. In this scenario, what will you do to resolve this security concern?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180972, 'original_assessment_id': 2567326, 'section': 'VPC', 'prompt': {'explanation': '<p>A VPC endpoint enables you to privately connect your VPC to supported AWS services and VPC endpoint services powered by PrivateLink without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection. Instances in your VPC do not require public IP addresses to communicate with resources in the service. Traffic between your VPC and the other service does not leave the Amazon network</p><p>&nbsp;</p><p>Resources:</p><p><a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-endpoints.html">https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-endpoints.html</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['Change the web architecture to access the financial data through an Internet Gateway. ', 'Change the web architecture to access the financial data through a VPN connection. ', 'Change the web architecture to access the financial data through a NAT Gateway. ', 'Change the web architecture to access the financial data through a VPC endpoint for Amazon S3.'], 'relatedLectureIds': '', 'question': 'You have a web application running on EC2 instances which processes sensitive financial information. All of the data are stored on an Amazon S3 bucket. The financial information is accessed by users over the Internet. The security team of the company is concerned that the Internet connectivity to Amazon S3 is a security risk. In this scenario, what will you do to resolve this security concern?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have an On-Demand EC2 instance with an attached EBS volume. There is a scheduled job that creates a snapshot of this EBS volume every 12 midnight when the instance is not used. One night, there has been a production incident where you need to perform a change on both the instance and on the EBS volume at the same time when the snapshot is currently taking place.Which of the following scenarios are true when it comes to the usage of an EBS volume while the snapshot is in progress?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180976, 'original_assessment_id': 2567330, 'section': 'EBS', 'prompt': {'explanation': '<p>Snapshots occur asynchronously; the point-in-time snapshot is created immediately, but the status of the snapshot is&nbsp;<code>pending</code>&nbsp;until the snapshot is complete (when all of the modified blocks have been transferred to Amazon S3), which can take several hours for large initial snapshots or subsequent snapshots where many blocks have changed.</p><p>While it is completing, an in-progress snapshot is not affected by ongoing reads and writes to the volume hence, you can still use the EBS volume normally.</p><div>When you create an EBS volume based on a snapshot, the new volume begins as an exact replica of the original volume that was used to create the snapshot. The replicated volume loads data lazily in the background so that you can begin using it immediately. If you access data that hasn\'t been loaded yet, the volume immediately downloads the requested data from Amazon S3, and then continues loading the rest of the volume\'s data in the background.</div><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-snapshot.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-snapshot.html</a></p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['The EBS volume can be used while the snapshot is in progress.', 'The EBS volume cannot be detached or attached to an EC2 instance until the snapshot completes', 'The EBS volume can be used in read-only mode while the snapshot is in progress.', 'The EBS volume cannot be used until the snapshot completes.'], 'relatedLectureIds': '', 'question': 'You have an On-Demand EC2 instance with an attached EBS volume. There is a scheduled job that creates a snapshot of this EBS volume every 12 midnight when the instance is not used. One night, there has been a production incident where you need to perform a change on both the instance and on the EBS volume at the same time when the snapshot is currently taking place.<br><br>Which of the following scenarios are true when it comes to the usage of an EBS volume while the snapshot is in progress?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'The start-up company that you are working for has a batch job application that is currently hosted on an EC2 instance. It is set to process messages from a queue created in SQS with default settings. You configured the application to process the messages once a week. After 2 weeks, you noticed that not all messages are being processed by the application. What is the root cause of this issue?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180978, 'original_assessment_id': 2567332, 'section': 'SQS', 'prompt': {'explanation': '<p>Amazon SQS automatically deletes messages that have been in a queue for more than the maximum message retention period. The default message retention period is 4 days. Since the queue is configured to the default settings and the batch job application only processes the messages once a week, the messages that are in the queue for more than 4 days are deleted. This is the root cause of the issue.</p><p>To fix this, you can increase the message retention period to a maximum of 14 days using the&nbsp;<a href="http://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/API_SetQueueAttributes.html" target="_blank" rel="noopener">SetQueueAttributes</a>&nbsp;action.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/sqs/faqs/" target="_blank" rel="noopener">https://aws.amazon.com/sqs/faqs/</a></p><p><a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-message-lifecycle.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-message-lifecycle.html</a></p>', 'answers': ['The batch job application is configured to long polling.', 'Amazon SQS has automatically deleted the messages that have been in a queue for more than the maximum message retention period.', 'The SQS queue is set to short-polling.', 'Missing permissions in SQS.'], 'question': 'The start-up company that you are working for has a batch job application that is currently hosted on an EC2 instance. It is set to process messages from a queue created in SQS with default settings. You configured the application to process the messages once a week. After 2 weeks, you noticed that not all messages are being processed by the application. <br /><br />What is the root cause of this issue?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You just joined a large tech company with an existing Amazon VPC. When reviewing the Auto Scaling events, you noticed that their web application is scaling up and down multiple times within the hour. What design change could you make to optimize cost while preserving elasticity?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180980, 'original_assessment_id': 2567334, 'section': 'EC2', 'prompt': {'explanation': '<p>Since the application is scaling up and down multiple times within the hour, the issue lies on the cooldown period of the Auto Scaling group.</p><p>The cooldown period is a configurable setting for your Auto Scaling group that helps to ensure that it doesn\'t launch or terminate additional instances before the previous scaling activity takes effect. After the Auto Scaling group dynamically scales using a simple scaling policy, it waits for the cooldown period to complete before resuming scaling activities.</p><p>When you manually scale your Auto Scaling group, the default is not to wait for the cooldown period, but you can override the default and honor the cooldown period. If an instance becomes unhealthy, the Auto Scaling group does not wait for the cooldown period to complete before replacing the unhealthy instance.</p><p>&nbsp;</p><p>Resources:</p><p><a href="http://docs.aws.amazon.com/autoscaling/latest/userguide/as-scale-based-on-demand.html">http://docs.aws.amazon.com/autoscaling/latest/userguide/as-scale-based-on-demand.html</a></p><p>&nbsp;</p>', 'feedbacks': ['', '', '', '', ''], 'answers': ['<p>Change the cooldown period of the Auto Scaling group and set the CloudWatch metric to a higher threshold</p>', 'Increase the instance type in the launch configuration', 'Increase the base number of Auto Scaling instances for the Auto Scaling group', 'Add provisioned IOPS to the instances', 'Add EBS Volumes to the instances'], 'relatedLectureIds': '', 'question': 'You just joined a large tech company with an existing Amazon VPC. When reviewing the Auto Scaling events, you noticed that their web application is scaling up and down multiple times within the hour. <br><br>What design change could you make to optimize cost while preserving elasticity?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multi-select', 'question_plain': "A health organization is using a large Dedicated EC2 instance with multiple EBS volumes to host its health records web application. The EBS volumes must be encrypted due to the confidentiality of the data that they are handling and also to comply with the HIPAA (Health Insurance Portability and Accountability Act) standard.\xa0 \xa0In EBS encryption, what service does AWS use to secure the volume's data at rest? (Choose 2)", '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180982, 'original_assessment_id': 2567336, 'section': 'EBS', 'prompt': {'explanation': '<p>Amazon EBS encryption offers seamless encryption of EBS data volumes, boot volumes, and snapshots, eliminating the need to build and maintain a secure key management infrastructure. EBS encryption enables data at rest security by encrypting your data using Amazon-managed keys, or keys you create and manage using the AWS Key Management Service (KMS). The encryption occurs on the servers that host EC2 instances, providing encryption of data as it moves between EC2 instances and EBS storage. Hence, options 1 and 3 are the right answers.</p> <p>Options 2 and 4 are incorrect as these relate only to S3.</p> <p>Option 5 is incorrect as you only store keys in CloudHSM and not passwords.</p> <p>Option 6 is incorrect as ACM only provides SSL certificates and not data encryption of EBS Volumes.</p> <p>&nbsp;</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/ebs/faqs/">https://aws.amazon.com/ebs/faqs/</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['<p>By using your own keys in AWS Key Management Service (KMS).</p>', '<p>By using S3 Server-Side Encryption.</p>', '<p>By using Amazon-managed keys in AWS Key Management Service (KMS).</p>', '<p>By using S3 Client-Side Encryption.</p>', '<p>By using a password stored in CloudHSM.</p>', '<p>By using the SSL certificates provided by the AWS Certificate Manager (ACM).</p>'], 'relatedLectureIds': '', 'question': "<p>A health organization is using a large Dedicated EC2 instance with multiple EBS volumes to host its health records web application. The EBS volumes must be encrypted due to the confidentiality of the data that they are handling and also to comply with the HIPAA (Health Insurance Portability and Accountability Act) standard.\xa0 \xa0</p><p>In EBS encryption, what service does AWS use to secure the volume's data at rest? (Choose 2)</p>"}, 'related_lectures': [], 'correct_response': ['a', 'c'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are a Web Developer working for a construction company. You need to develop a static website and host it on an EC2 Instance. Which of the following can be used to make your website highly available? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180984, 'original_assessment_id': 2567338, 'section': 'Designing Highly Available Network', 'prompt': {'explanation': '<p>High Availability Architectures in AWS simply means that your application or service will still work or be "available" even if one or more components failed. If you are hosting a static website in just one EC2 instance, your website will be inaccessible or not be "available" if that single EC2 instance is terminated or had a computing or network problem.&nbsp;</p><p>You can configure an Auto Scaling group to create a fleet of EC2 instances based on the traffic and deploy them to two or more Availability Zones. Set up an Elastic Load Balancer to "balance" and control the flow of traffic to these Availability Zones so that in the event of a zone failure, your website can still be accessible.</p><p>Amazon SNS, Security Group, and Amazon Kinesis are the wrong options as these services do not provide&nbsp;High Availability nor Fault Tolerance to your architecture.</p><br /><p>References:</p><p><a href="https://media.amazonwebservices.com/architecturecenter/AWS_ac_ra_ftha_04.pdf" target="_blank" rel="noopener">https://media.amazonwebservices.com/architecturecenter/AWS_ac_ra_ftha_04.pdf</a></p>', 'answers': ['Multiple Availability Zones.', 'Elastic Load Balancer', 'Amazon SNS', 'Auto Scaling group', 'Security Group', 'Amazon Kinesis'], 'question': 'You are a Web Developer working for a construction company. You need to develop a static website and host it on an EC2 Instance. <br /><br />Which of the following can be used to make your website highly available? (Choose 3)'}, 'related_lectures': [], 'correct_response': ['a', 'b', 'd'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Penetration testing of EC2 instances ___________ as per the Acceptable Use Policy of AWS.', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6181006, 'original_assessment_id': 2567362, 'section': 'Security', 'prompt': {'explanation': '<p>The AWS Acceptable Use Policy describes permitted and prohibited behavior on AWS and includes descriptions of prohibited security violations and network abuse. However, because penetration testing and other simulated events are frequently indistinguishable from these activities, AWS has established a policy for customers to request permission to conduct penetration tests and vulnerability scans to or originating from the AWS environment.</p><p>Hence, the correct answer is option 3 i.e. may be performed by the customer on their own instances with prior authorization from AWS.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/security/penetration-testing/">https://aws.amazon.com/security/penetration-testing/</a></p>', 'answers': ['can only be performed by AWS', 'are strictly prohibited', 'may be performed by the customer on their own instances with prior authorization from AWS', 'may be performed by the customer on their own instances without prior authorization from AWS'], 'question': 'Penetration testing of EC2 instances ___________ as per the Acceptable Use Policy of AWS.'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A website is running on an Auto Scaling group of On-Demand EC2 instances which are abruptly getting terminated from time to time. To automate the monitoring process, you started to create a simple script which uses the AWS CLI to find the root cause of this issue.\xa0 Which of the following is the most suitable command to use?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180988, 'original_assessment_id': 2567342, 'section': 'EC2', 'prompt': {'explanation': '<p>The <code>describe-instances</code> command shows the status of the EC2 instances including the recently terminated instances. It also returns a <code>StateReason</code> of why the instance was terminated.</p> <p><strong>Reference:</strong></p> <p><a href="http://docs.aws.amazon.com/cli/latest/reference/ec2/describe-instances.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/cli/latest/reference/ec2/describe-instances.html</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p><code>aws ec2 describe-instances</code></p>', '<p><code>aws ec2 describe-images</code></p>', '<p><code>aws ec2 get-console-screenshot</code></p>', '<p><code>aws ec2 describe-volume-status</code></p>'], 'relatedLectureIds': '', 'question': '<p>A website is running on an Auto Scaling group of On-Demand EC2 instances which are abruptly getting terminated from time to time. To automate the monitoring process, you started to create a simple script which uses the AWS CLI to find the root cause of this issue.\xa0 </p><p>Which of the following is the most suitable command to use?</p>'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T07:53:11Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Your manager instructed you to use Route53 instead of an ELB to load balance the incoming request to your web application. The system is deployed to two EC2 instances to which the traffic needs to be distributed to. You want to set a specific percentage of traffic to go to each instance. Which routing policy would you use?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180990, 'original_assessment_id': 2567346, 'section': 'Route53', 'prompt': {'explanation': '<p>Weighted routing lets you associate multiple resources with a single domain name (example.com) or subdomain name (acme.example.com) and choose how much traffic is routed to each resource. This can be useful for a variety of purposes including load balancing and testing new versions of software. You can set a specific percentage of how much traffic will be allocated to the resource by specifying the weights.</p><p>For example, if you want to send a tiny portion of your traffic to one resource and the rest to another resource, you might specify weights of 1 and 255. The resource with a weight of 1 gets 1/256th of the traffic (1/1+255), and the other resource gets 255/256ths (255/1+255).</p><p>You can gradually change the balance by changing the weights. If you want to stop sending traffic to a resource, you can change the weight for that record to 0.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html">http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html</a></p>', 'answers': ['Latency', 'Failover', 'Weighted', 'Geolocation'], 'question': 'Your manager instructed you to use Route53 instead of an ELB to load balance the incoming request to your web application. The system is deployed to two EC2 instances to which the traffic needs to be distributed to. You want to set a specific percentage of traffic to go to each instance. <br /><br />Which routing policy would you use?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': "An online stock trading portal is deployed in AWS and in order to complete the set up, you need to offload the SSL/TLS processing for your web servers using CloudHSM. This will reduce the burden on your web servers and provides extra security by storing your web server's private key in this cloud-based hardware security module.\xa0 \xa0Which of the following statements is not true about Amazon CloudHSM?", '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6181008, 'original_assessment_id': 2567364, 'section': 'CloudHSM', 'prompt': {'explanation': '<p>Take note that CloudHSM provides a secure key storage in tamper-resistant hardware available in multiple Availability Zones (AZs) and not just on one AZ. Hence, Option 4 is the incorrect answer.</p> <p>AWS CloudHSM runs in your own Amazon Virtual Private Cloud (VPC), enabling you to easily use your HSMs with applications running on your Amazon EC2 instances. With CloudHSM, you can use standard VPC security controls to manage access to your HSMs.</p> <p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://d1.awsstatic.com/product-marketing/cloudhsm/CloudHSM_Diagrams_2-final.6f427ebb14d021b9cd6120aeee72cf4d3723e89b.png" alt="" width="502" height="300" /></p> <p>Your applications connect to your HSMs using mutually authenticated SSL channels established by your HSM client software. Since your HSMs are located in Amazon datacenters near your EC2 instances, you can reduce the network latency between your applications and HSMs versus an on-premises HSM.</p> <ul> <li>AWS manages the hardware security module (HSM) appliance but does not have access to your keys</li> <li>You control and manage your own keys</li> <li>Application performance improves (due to close proximity with AWS workloads)</li> <li>Secure key storage in tamper-resistant hardware available in multiple Availability Zones (AZs)</li> <li>Your HSMs are in your Virtual Private Cloud (VPC) and isolated from other AWS networks.</li> </ul> <p>Separation of duties and role-based access control is inherent in the design of the AWS CloudHSM. AWS monitors the health and network availability of your HSMs but is not involved in the creation and management of the key material stored within your HSMs. You control the HSMs and the generation and use of your encryption keys.</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/cloudhsm/">https://aws.amazon.com/cloudhsm/</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p>AWS manages the hardware security module (HSM) appliance, but does not have access to your keys.</p>', '<p>Your HSMs are in your Virtual Private Cloud (VPC) and isolated from other AWS networks.</p>', '<p>You control and manage your own encryption keys.</p>', '<p>It provides a secure key storage in tamper-resistant hardware available in a single Availability Zone.</p>'], 'relatedLectureIds': '', 'question': "<p>An online stock trading portal is deployed in AWS and in order to complete the set up, you need to offload the SSL/TLS processing for your web servers using CloudHSM. This will reduce the burden on your web servers and provides extra security by storing your web server's private key in this cloud-based hardware security module.\xa0 \xa0</p><p>Which of the following statements is not true about Amazon CloudHSM?</p>"}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T08:02:51Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'The social media company that you are working for needs to capture the detailed information of all HTTP requests that went through their public-facing application load balancer every five minutes. They want to use this data for analyzing traffic patterns and for troubleshooting their web applications in AWS. Which of the following options meet the customer requirements?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180992, 'original_assessment_id': 2567348, 'section': 'ELB', 'prompt': {'explanation': '<p>Elastic Load Balancing provides access logs that capture detailed information about requests sent to your load balancer. Each log contains information such as the time the request was received, the client\'s IP address, latencies, request paths, and server responses. You can use these access logs to analyze traffic patterns and troubleshoot issues.</p><p>Access logging is an optional feature of Elastic Load Balancing that is disabled by default. After you enable access logging for your load balancer, Elastic Load Balancing captures the logs and stores them in the Amazon S3 bucket that you specify as compressed files. You can disable access logging at any time.</p><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-access-logs.html">http://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-access-logs.html</a></p>', 'answers': ['Enable AWS CloudTrail for their application load balancer.', 'Enable access logs on the application load balancer.', 'Add an Amazon CloudWatch Logs agent on the application load balancer.', 'Enable Amazon CloudWatch metrics on the application load balancer.'], 'question': 'The social media company that you are working for needs to capture the detailed information of all HTTP requests that went through their public-facing application load balancer every five minutes. They want to use this data for analyzing traffic patterns and for troubleshooting their web applications in AWS. <br /><br />Which of the following options meet the customer requirements?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are a Solutions Architect working for a startup company which is currently migrating their production environment to AWS. Your manager asked you to setup access to the AWS console using Identity Access Management (IAM). You have created 5 users for your system administrators. What further steps do you need to take to enable your system administrators to get access to the AWS console?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180994, 'original_assessment_id': 2567350, 'section': 'IAM', 'prompt': {'explanation': '<p>The&nbsp;AWS Management Console is the web interface used to manage your AWS resources using your web browser. To access this, your users should have a password that they can use to login to the web console.</p><ul><li>Option 1 is incorrect as the&nbsp;secret access key and access key id are used to trigger AWS API calls.</li><li>Option 2 is incorrect because the multi-factor authentication and a password policy are just additional security measures for the IAM user but these won\'t enable them to access the AWS Management Console.</li><li>Option 4 is incorrect as you could not add an IAM user to a security group. Remember that a security group is used for EC2 instances only.</li></ul><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/getting-started_how-users-sign-in.html">http://docs.aws.amazon.com/IAM/latest/UserGuide/getting-started_how-users-sign-in.html</a></p><p>&nbsp;</p>', 'answers': ['Provide the system administrators the secret access key and access key id.', 'Enable multi-factor authentication on their accounts and define a password policy.', 'Provide a password for each user created and give these passwords to your system administrators.', 'Add the administrators to the Security Group.'], 'question': 'You are a Solutions Architect working for a startup company which is currently migrating their production environment to AWS. Your manager asked you to setup access to the AWS console using Identity Access Management (IAM). You have created 5 users for your system administrators. <br /><br />What further steps do you need to take to enable your system administrators to get access to the AWS console?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have just launched a new API Gateway service which uses AWS Lambda as a serverless computing service. In what type of protocol will your API endpoint be exposed?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180996, 'original_assessment_id': 2567352, 'section': 'API Gateway', 'prompt': {'feedbacks': ['', '', '', ''], 'explanation': '<p>All of the APIs created with Amazon API Gateway expose <strong>HTTPS</strong> endpoints only. Amazon API Gateway does not support unencrypted (HTTP) endpoints. By default, Amazon API Gateway assigns an internal domain to the API that automatically uses the Amazon API Gateway certificate. When configuring your APIs to run under a custom domain name, you can provide your own certificate for the domain.</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/api-gateway/faqs/" target="_blank" rel="noopener">https://aws.amazon.com/api-gateway/faqs/</a></p>', 'relatedLectureIds': '', 'answers': ['<p>HTTP/2</p>', 'HTTPS', 'HTTP', '<p>WebSocket</p>'], 'question': '<p>You have just launched a new API Gateway service which uses AWS Lambda as a serverless computing service. In what type of protocol will your API endpoint be exposed?</p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:55:44Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'An application is hosted in an On-Demand EC2 instance and is using Amazon SDK to communicate to other AWS services such as S3, DynamoDB, and many others. As part of the upcoming IT audit, you need to ensure that all API calls to your AWS resources are logged and durably stored.\xa0 Which is the most suitable service that you should use\xa0to meet this requirement?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6180998, 'original_assessment_id': 2567354, 'section': 'CloudTrail', 'prompt': {'explanation': '<p>AWS CloudTrail increases visibility into your user and resource activity by recording AWS Management Console actions and API calls. You can identify which users and accounts called AWS, the source IP address from which the calls were made, and when the calls occurred.</p> <p>Option 1 is incorrect because&nbsp;Amazon CloudWatch is primarily used for systems monitoring based on the server metrics. It does not have the capability to track API calls to your AWS resources.</p> <p>Option 3 is incorrect because AWS X-Ray is usually used to debug and analyze your microservices applications with request tracing so you can find the root cause of issues and performance. Unlike CloudTrail, it does not record the API calls that were made to your AWS resources.</p> <p>Option 4 is incorrect because Amazon API Gateway is not used for logging each and every API call to your AWS resources. It is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale.</p> <p><strong>Reference:</strong></p> <p><a href="https://aws.amazon.com/cloudtrail/">https://aws.amazon.com/cloudtrail/</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p>Amazon CloudWatch</p>', '<p>AWS CloudTrail</p>', '<p>AWS X-Ray</p>', '<p>Amazon API Gateway</p>'], 'relatedLectureIds': '', 'question': '<p>An application is hosted in an On-Demand EC2 instance and is using Amazon SDK to communicate to other AWS services such as S3, DynamoDB, and many others. As part of the upcoming IT audit, you need to ensure that all API calls to your AWS resources are logged and durably stored.\xa0 </p><p>Which is the most suitable service that you should use\xa0to meet this requirement?</p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:58:10Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are currently in the design phase of your project where you are deciding which type of database you will use for your web application. Since the application will be deployed in AWS, you are planning to use Amazon RDS\u200b with Read Replicas to improve the read availability of the database tier.\xa0 \xa0In this scenario, which type of database does not support Read Replicas and which you should not use in your architecture? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6181018, 'original_assessment_id': 4519792, 'section': 'RDS', 'prompt': {'explanation': '<p>Read Replicas are supported by Amazon Aurora and Amazon RDS for MySQL, MariaDB and PostgreSQL. Unlike Multi-AZ deployments, Read Replicas for these engines use each\'s built-in replication technology and are subject to its strengths and limitations.</p> <p>&nbsp;</p> <p><strong>Reference:&nbsp;</strong></p> <p><a href="https://aws.amazon.com/rds/faqs/#read-replicas">https://aws.amazon.com/rds/faqs/#read-replicas</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['<p>Amazon Aurora</p>', '<p>MySQL</p>', '<p>MariaDB</p>', '<p>Oracle</p>', '<p>Microsoft SQL Server</p>', '<p>MongoDB</p>'], 'relatedLectureIds': '', 'question': '<p>You are currently in the design phase of your project where you are deciding which type of database you will use for your web application. Since the application will be deployed in AWS, you are planning to use Amazon RDS\u200b with Read Replicas to improve the read availability of the database tier.\xa0 \xa0</p><p>In this scenario, which type of database does not support Read Replicas and which you should not use in your architecture? (Choose 3)</p>'}, 'related_lectures': [], 'correct_response': ['d', 'e', 'f'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Your company has a web-based ticketing service that utilizes Amazon SQS and a fleet of EC2 instances. The EC2 instances that consume messages from the SQS queue are configured to poll the queue as often as possible to keep end-to-end throughput as high as possible. You noticed that polling the queue in tight loops is using unnecessary CPU cycles, resulting to increased operational costs due to empty responses. In this scenario, what will you do to make the system more cost-effective?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6181010, 'original_assessment_id': 2567366, 'section': 'SQS', 'prompt': {'explanation': '<p>In this scenario, the application is deployed in a fleet of EC2 instances that are polling messages from a single SQS queue.&nbsp;Amazon SQS uses short polling by default, querying only a subset of the servers (based on a weighted random distribution) to determine whether any messages are available for inclusion in the response. Short polling works for scenarios that require higher throughput. However, you can also configure the queue to use Long polling instead, to reduce cost.</p><p>The ReceiveMessageWaitTimeSeconds is the&nbsp;queue attribute that determines whether you are using Short or Long polling. By default, its value is zero which means&nbsp;it is using Short polling. If it is set to a value greater than zero, then it is Long polling. Hence, Option 2 is correct.</p><p>Quick facts about SQS Long Polling:</p><ul><li>Long polling helps reduce your cost of using Amazon SQS by reducing the number of empty responses when there are no messages available to return in reply to a <em>ReceiveMessage</em> request sent to an Amazon SQS queue and eliminating false empty responses when messages are available in the queue but aren\'t included in the response.&nbsp;</li><li>Long polling reduces the number of empty responses by allowing Amazon SQS to wait until a message is available in the queue before sending a response. Unless the connection times out, the response to the <code>ReceiveMessage</code>&nbsp;request contains at least one of the available messages, up to the maximum number of messages specified in the&nbsp;<code>ReceiveMessage</code>&nbsp;action.</li><li>Long polling eliminates false empty responses by querying all (rather than a limited number) of the servers. Long polling returns messages as soon any message becomes available.</li></ul><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-long-polling.html">https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-long-polling.html</a></p><p>&nbsp;</p>', 'answers': ['Configure Amazon SQS to use long polling by setting the ReceiveMessageWaitTimeSeconds to zero.', 'Configure Amazon SQS to use long polling by setting the ReceiveMessageWaitTimeSeconds to a number greater than zero.', 'Configure Amazon SQS to use short polling by setting the ReceiveMessageWaitTimeSeconds to a number greater than zero.', 'Configure Amazon SQS to use short polling by setting the ReceiveMessageWaitTimeSeconds to zero.'], 'question': 'Your company has a web-based ticketing service that utilizes Amazon SQS and a fleet of EC2 instances. The EC2 instances that consume messages from the SQS queue are configured to poll the queue as often as possible to keep end-to-end throughput as high as possible. You noticed that polling the queue in tight loops is using unnecessary CPU cycles, resulting to increased operational costs due to empty responses. <br /><br />In this scenario, what will you do to make the system more cost-effective?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multi-select', 'question_plain': 'The CloudWatch Logs agent provides an automated way to send log data to CloudWatch Logs from Amazon EC2 instances. This agent is comprised of what components? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6181012, 'original_assessment_id': 2567368, 'section': 'CloudWatch', 'prompt': {'explanation': '<p>The CloudWatch Logs agent provides an automated way to send log data to CloudWatch Logs from Amazon EC2 instances. The agent is comprised of the following components:</p><div><ul><li>A plug-in to the AWS CLI that pushes log data to CloudWatch Logs.</li><li>A script (daemon) that initiates the process to push data to CloudWatch Logs.</li><li>A cron job that ensures that the daemon is always running.</li></ul></div><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AgentReference.html">https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AgentReference.html</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['A plug-in to the AWS CLI that pushes log data to CloudWatch Logs.', 'A script (daemon) that initiates the process to push data to CloudWatch Logs.', 'A cron job that ensures that the daemon is always running.', 'A CloudTrail configuration that collects all logs from the instance.'], 'relatedLectureIds': '', 'question': '<p>The CloudWatch Logs agent provides an automated way to send log data to CloudWatch Logs from Amazon EC2 instances. This agent is comprised of what components? (Choose 3)</p>'}, 'related_lectures': [], 'correct_response': ['a', 'b', 'c'], 'updated': '2018-11-21T07:39:34Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A leading bank has an application that is hosted on an Auto Scaling group of EBS-backed EC2 instances. As the Solutions Architect, you need to provide the ability to fully restore the data stored in their EBS volumes by using EBS snapshots.\xa0 \xa0Which of the following approaches provide the lowest cost for Amazon Elastic Block Store snapshots?', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6181014, 'original_assessment_id': 2567370, 'section': 'EBS', 'prompt': {'explanation': '<p>To meet the requirement on this scenario, you can just maintain a single snapshot of the EBS volume since its latest snapshot is both incremental and complete.</p> <p>You can back up the data on your Amazon EBS volumes to Amazon S3 by taking point-in-time snapshots. Snapshots are&nbsp;<em>incremental</em>&nbsp;backups, which means that only the blocks on the device that have changed after your most recent snapshot are saved. This minimizes the time required to create the snapshot and saves on storage costs by not duplicating data.</p> <p>When you delete a snapshot, only the data unique to that snapshot is removed. Each snapshot contains all of the information needed to restore your data (from the moment the snapshot was taken) to a new EBS volume.</p> <p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/images/snapshot_1a.png" alt="" width="767" height="758" /></p> <p>&nbsp;</p> <p><strong>Reference:</strong></p> <p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['Maintain two snapshots: the original snapshot and the latest incremental snapshot.', 'Maintain a volume snapshot; subsequent snapshots will overwrite one another.', 'Just maintain a single snapshot of the EBS volume since the latest snapshot is both incremental and complete.', 'Maintain the most current snapshot and then archive the original and incremental snapshots to Amazon Glacier.'], 'relatedLectureIds': '', 'question': '<p>A leading bank has an application that is hosted on an Auto Scaling group of EBS-backed EC2 instances. As the Solutions Architect, you need to provide the ability to fully restore the data stored in their EBS volumes by using EBS snapshots.\xa0 \xa0</p><p>Which of the following approaches provide the lowest cost for Amazon Elastic Block Store snapshots?</p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T08:06:44Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are working for a large financial firm in the country. They have an AWS environment which contains several Reserved EC2 instances that are hosting to a web application that has been decommissioned last week. To save cost, you need to stop incurring charges for the Reserved instances as soon as possible. What cost-effective steps will you take in this circumstance? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T07:39:34Z', 'id': 6181016, 'original_assessment_id': 2567372, 'section': 'EC2', 'prompt': {'explanation': '<div> <p>The correct options are:</p> <ul> <li>Go to the AWS Reserved Instance Marketplace and sell the Reserved Instances.</li> <li>Terminate the Reserved instances as soon as possible to avoid getting billed at the on-demand price when it expires</li> </ul> <br /> <p>The Reserved Instance Marketplace is a platform that supports the sale of third-party and AWS customers\' unused Standard Reserved Instances, which vary in terms of lengths and pricing options. For example, you may want to sell Reserved Instances after moving instances to a new AWS region, changing to a new instance type, ending projects before the term expiration, when your business needs change, or if you have unneeded capacity.</p> <p>Option 1 is incorrect because a stopped instance can still be restarted. Take note that when a Reserved Instance expires, any instances that were covered by the Reserved Instance are billed at the on-demand price which costs significantly higher. Since the application is already decommissioned, there is no point of keeping the unused instances. It is also possible that there are associated Elastic IP addresses, which will incur charges if they are associated with stopped instances</p> <p>Option 2 is incorrect as you don\'t need to close down your AWS account.</p> <p>Option 5 is incorrect as you have to use&nbsp;AWS Reserved Instance Marketplace to sell your instances.</p> <p>&nbsp;</p> </div> <p>Resources:</p> <p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ri-market-general.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ri-market-general.html</a></p> <p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html</a></p>', 'feedbacks': ['', '', '', '', ''], 'answers': ['Stop the Reserved instances as soon as possible.', 'Contact AWS to cancel your AWS subscription.', 'Go to the AWS Reserved Instance Marketplace and sell the Reserved instances.', '<p>Terminate the Reserved instances as soon as possible to avoid getting billed at the on-demand price when it expires </p>', 'Go to the Amazon.com online shopping website and sell the Reserved instances.'], 'relatedLectureIds': '', 'question': 'You are working for a large financial firm in the country. They have an AWS environment which contains several Reserved EC2 instances that are hosting to a web application that has been decommissioned last week. To save cost, you need to stop incurring charges for the Reserved instances as soon as possible. <br><br>What cost-effective steps will you take in this circumstance? (Choose 2)'}, 'related_lectures': [], 'correct_response': ['c', 'd'], 'updated': '2018-11-21T07:39:34Z'}], 'previous': None, 'next': None}, 'title': 'AWS Certified Solutions Architect Associate Practice Test 5'}, {'type': 'practice-test', 'quiz_data': {'count': 65, 'results': [{'assessment_type': 'multiple-choice', 'question_plain': 'You are a Solutions Architect working for a software development company. You are planning to launch a fleet of EBS-backed EC2 instances and want to automatically assign each instance with a static private IP address which does not change even if the instances are restarted. What should you do to accomplish this?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181048, 'original_assessment_id': 2567374, 'section': 'EC2', 'prompt': {'explanation': '<p>In EC2-Classic, your EC2 instance receives a private IPv4 address from the EC2-Classic range each time it\'s started. In EC2-VPC on the other hand, your EC2 instance receives a static private IPv4 address from the address range of your default VPC. Hence, the correct answer is Option 3 and not Option 5.</p><p>Options 1 and 2 are incorrect due to the fact that&nbsp;Availability Zones do not provide static private IP addresses to EC2 instances.</p><p>Option 4 is incorrect as a Placement Group is just a grouping of instances.</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-vpc.html#differences-ec2-classic-vpc">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-vpc.html#differences-ec2-classic-vpc</a></p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-instance-addressing.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-instance-addressing.html</a></p><p>&nbsp;</p><p>&nbsp;</p>', 'answers': ['Launch the instances to a single Availability Zone.', 'Launch the instances to multiple Availability Zones.', 'Launch the instances in the Amazon Virtual Private Cloud (VPC).', 'Launch the instances in a Placement Group.', 'Launch the instances in EC2-Classic.'], 'question': 'You are a Solutions Architect working for a software development company. You are planning to launch a fleet of EBS-backed EC2 instances and want to automatically assign each instance with a static private IP address which does not change even if the instances are restarted. <br /><br />What should you do to accomplish this?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are a Solutions Architect for a large manufacturing company. They instructed you to come up with a solution that uses EC2 Instances with Elastic Load Balancing. Which of the following protocols can be used to ensure that traffic is secure from the back-end instances to the Elastic Load Balancer? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181058, 'original_assessment_id': 2567384, 'section': 'ELB', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['HTTP', 'HTTPS', 'TCP', 'SSL'], 'explanation': '<p>HTTPS and SSL provide a secure connection between the client and your back-end instances.</p><p>If you use HTTPS or SSL for your back-end connections, you can enable authentication of your registered instances. You can then use the authentication process to ensure that the instances accept only encrypted communication, and to ensure that each registered instance has the correct public key.</p><p>&nbsp;</p><p>Resources:</p><p><a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-listener-config.html#https-ssl-listeners">https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-listener-config.html#https-ssl-listeners</a></p>', 'question': 'You are a Solutions Architect for a large manufacturing company. They instructed you to come up with a solution that uses EC2 Instances with Elastic Load Balancing. Which of the following protocols can be used to ensure that traffic is secure from the back-end instances to the Elastic Load Balancer? (Choose 2)'}, 'related_lectures': [], 'correct_response': ['b', 'd'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A multinational corporate and investment bank is regularly processing steady workloads of accruals, loan interests, and other critical financial calculations every night at 10 PM to 3 AM on their on-premise data center for their corporate clients. Once the process is done, the results are then uploaded to the Oracle General Ledger which means that the processing should not be delayed nor interrupted. The CTO has decided to move their IT infrastructure to AWS to save cost and to improve the scalability of their digital financial services.\xa0 \xa0As the Senior Solutions Architect, how can you implement a cost-effective architecture in AWS for their financial system?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181050, 'original_assessment_id': 2567376, 'section': 'EC2', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['<p>Use On-Demand EC2 instances which allows you to pay for the instances that you launch and use by the second.</p>', '<p>Use Reserved Instances which provides a compute capacity that is always available for a term from one to three years.</p>', '<p>Use Scheduled Reserved Instances which provides compute capacity that is always available on the specified recurring schedule, for a one-year term.\xa0 </p>', '<p>Use Spot Instances which can significantly lower your Amazon EC2 costs.</p>', '<p>Use Dedicated Hosts which provide a physical host that is fully dedicated to running your instances, and bring your existing per-socket, per-core, or per-VM software licenses to reduce costs.</p>', '<p>Use Dedicated Instances that provide a compute capacity which runs on single-tenant hardware and are paid by the hour.</p>'], 'explanation': '<p>Scheduled Reserved Instances (Scheduled Instances) enable you to purchase capacity reservations that recur on a daily, weekly, or monthly basis, with a specified start time and duration, for a one-year term. You reserve the capacity in advance, so that you know it is available when you need it. You pay for the time that the instances are scheduled, even if you do not use them.</p> <p>Scheduled Instances are a good choice for workloads that do not run continuously, but do run on a regular schedule. For example, you can use Scheduled Instances for an application that runs during business hours or for batch processing that runs at the end of the week.</p> <p>&nbsp;</p> <p><strong>References:</strong></p> <p><a href="https://aws.amazon.com/blogs/aws/new-scheduled-reserved-instances/">https://aws.amazon.com/blogs/aws/new-scheduled-reserved-instances/</a></p> <p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-scheduled-instances.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-scheduled-instances.html</a></p> <p>&nbsp;</p>', 'question': '<p>A multinational corporate and investment bank is regularly processing steady workloads of accruals, loan interests, and other critical financial calculations every night at 10 PM to 3 AM on their on-premise data center for their corporate clients. Once the process is done, the results are then uploaded to the Oracle General Ledger which means that the processing should not be delayed nor interrupted. The CTO has decided to move their IT infrastructure to AWS to save cost and to improve the scalability of their digital financial services.\xa0 \xa0</p><p>As the Senior Solutions Architect, how can you implement a cost-effective architecture in AWS for their financial system?\xa0 </p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are the Solutions Architect of a software development company where you are required to connect the on-premise infrastructure to their AWS cloud. Which of the following AWS service can you use to accomplish this? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181056, 'original_assessment_id': 2567382, 'section': 'VPC', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', ''], 'answers': ['IPsec VPN connection', '<p>Amazon Connect</p>', 'AWS Direct Connect', '<p>AWS On-Premise Connect</p>', 'AWS VPN CloudHub'], 'explanation': '<p>You can connect your VPC to remote networks by using a VPN connection which can be Direct Connect, IPsec VPN connection,&nbsp;AWS VPN CloudHub, or a third party software VPN appliance. Hence, Options 1, 3 and 5 are correct.</p> <p>Option 2 is incorrect because Amazon Connect is not a VPN connectivity option. It is actually a self-service, cloud-based contact center service in AWS that makes it easy for any business to deliver better customer service at lower cost. Amazon Connect is based on the same contact center technology used by Amazon customer service associates around the world to power millions of customer conversations.&nbsp;</p> <p>Option 4 is incorrect as there is no such thing as AWS On-Premise Connect.</p> <p>&nbsp;</p> <p>References:</p> <p><a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpn-connections.html">https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpn-connections.html</a></p> <p><a href="https://aws.amazon.com/connect/">https://aws.amazon.com/connect/</a></p> ', 'question': 'You are the Solutions Architect of a software development company where you are required to connect the on-premise infrastructure to their AWS cloud. Which of the following AWS service can you use to accomplish this? (Choose 3)'}, 'related_lectures': [], 'correct_response': ['a', 'c', 'e'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as a Senior Solutions Architect in a startup company. Your current project is about a movie streaming app where you are required to launch several EC2 instances on multiple availability zones. Which of the following will configure your load balancer to distribute incoming requests evenly to all EC2 instances across multiple Availability Zones?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181052, 'original_assessment_id': 2567378, 'section': 'ELB', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Elastic Load Balancing request routing', 'An Amazon Route53 weighted routing policy', 'Cross-zone load balancing', 'An Amazon Route 53 latency routing policy', '<p>Elastic Load Balancing Redirects </p>', '<p>An Amazon Route 53 failover routing policy</p>'], 'explanation': '<p>The right answer is to enable&nbsp;<em>cross-zone load balancing.</em></p> <p>If the load balancer nodes for your Classic Load Balancer can distribute requests regardless of Availability Zone, this is known as&nbsp;<em>cross-zone load balancing</em>. With cross-zone load balancing enabled, your load balancer nodes distribute incoming requests evenly across the Availability Zones enabled for your load balancer. Otherwise, each load balancer node distributes requests only to instances in its Availability Zone.</p> <p>For example, if you have 10 instances in Availability Zone us-west-2a and 2 instances in us-west-2b, the requests are distributed evenly across all 12 instances if cross-zone load balancing is enabled. Otherwise, the 2 instances in us-west-2b serve the same number of requests as the 10 instances in us-west-2a.</p> <p>Cross-zone load balancing reduces the need to maintain equivalent numbers of instances in each enabled Availability Zone, and improves your application\'s ability to handle the loss of one or more instances. However, we still recommend that you maintain approximately equivalent numbers of instances in each enabled Availability Zone for higher fault tolerance.</p> <p>&nbsp;</p> <p>References:</p> <p><a href="http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/enable-disable-crosszone-lb.html">http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/enable-disable-crosszone-lb.html</a></p> <p>&nbsp;</p>', 'question': '<p>You are working as a Senior Solutions Architect in a startup company. Your current project is about a movie streaming app where you are required to launch several EC2 instances on multiple availability zones. Which of the following will configure your load balancer to distribute incoming requests evenly to all EC2 instances across multiple Availability Zones?</p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'As a Junior AWS Migration Engineer in a hospital chain handling their consolidated patient history recording system, you have the task of designing a multi-tier web application architecture that consists of EC2 instances and an Amazon RDS database instance.\xa0 \xa0Which type of VPC setup should you provision if you are using AWS RDS service?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181054, 'original_assessment_id': 2567380, 'section': 'RDS', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', ''], 'answers': ['The VPC must have at least one subnet.', 'The VPC must have at least one subnet in one Availability Zone.', '<p>Your VPC must have at least 2 subnets in at least two of the Availability Zones.\xa0 </p>', '<p>A VPC peering connection. </p>', '<p>None of the above. </p>'], 'explanation': '<p>If you are using Amazon RDS, your VPC must have at least two subnets in at least two of the Availability Zones in the region where you want to deploy your DB instance. A subnet is a segment of a VPC\'s IP address range that you can specify and that lets you group instances based on your security and operational needs. </p><p>The reason why you need&nbsp;at least two subnets in at least two of the Availability Zones in the region is that if the primary DB instance of a Multi-AZ deployment fails, Amazon RDS can promote the corresponding standby database and subsequently create a new standby using an IP address of the subnet in one of the other Availability Zones.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_VPC.WorkingWithRDSInstanceinaVPC.html">http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_VPC.WorkingWithRDSInstanceinaVPC.html</a></p>', 'question': '<p>As a Junior AWS Migration Engineer in a hospital chain handling their consolidated patient history recording system, you have the task of designing a multi-tier web application architecture that consists of EC2 instances and an Amazon RDS database instance.\xa0 \xa0</p><p>Which type of VPC setup should you provision if you are using AWS RDS service?\xa0 </p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Your boss has asked you to launch a new MySQL RDS which ensures that you are available to recover from a database crash. Which of the below is not a recommended practice for RDS?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181062, 'original_assessment_id': 2567388, 'section': 'RDS', 'prompt': {'explanation': '<p>Using MyISAM as the storage engine for MySQL is not recommended hence, this option is incorrect. The recommended storage engine for MySQL is InnoDB and not&nbsp;MyISAM.</p><p>Options 1, 3, and 4 are best practices in the AWS MySQL RDS documentation. Again, InnoDB is the recommended storage engine for MySQL. However, in case you require intense, full-text search capability, use MyISAM storage engine instead.</p><p>&nbsp;</p><p>Resources:</p><p><a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_BestPractices.html#CHAP_BestPractices.MySQLStorage" target="_blank" rel="noopener">https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_BestPractices.html#CHAP_BestPractices.MySQLStorage</a></p>', 'answers': ['Ensure that automated backups are enabled for the RDS', 'Use MyISAM as the storage engine for MySQL.', 'Use InnoDB as the storage engine for MySQL.', 'Partition your large tables so that file sizes does not exceed the 16 TB limit.'], 'question': 'Your boss has asked you to launch a new MySQL RDS which ensures that you are available to recover from a database crash. <br /><br />Which of the below is not a recommended practice for RDS?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A fast food company is using AWS to host their online ordering system which uses an Auto Scaling group of EC2 instances deployed across multiple Availability Zones with an Application Load Balancer in front. To better handle the incoming traffic from various digital devices, you are planning to implement a new routing system where requests which have a URL of &lt;server&gt;/api/android are forwarded to one specific target group named "Android-Target-Group". Conversely, requests which have a URL of &lt;server&gt;/api/ios are forwarded to another separate target group named "iOS-Target-Group".\xa0 \xa0How can you implement this change in AWS?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181064, 'original_assessment_id': 2567390, 'section': 'ELB', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>You can use path conditions to define rules that forward requests to different target groups based on the URL in the request (also known as&nbsp;<em>path-based routing</em>).&nbsp;This type of routing is the most appropriate solution for this scenario hence, Option 3 is correct.</p> <p>Each path condition has one path pattern. If the URL in a request matches the path pattern in a listener rule exactly, the request is routed using that rule.&nbsp;</p> <p>A path pattern is case-sensitive, can be up to 128 characters in length, and can contain any of the following characters. You can include up to three wildcard characters.</p> <div> <ul> <li>A&ndash;Z, a&ndash;z, 0&ndash;9</li> <li>_ - . $ / ~ " \' @ : +</li> <li>&amp; (using &amp;amp;)</li> <li>* (matches 0 or more characters)</li> <li>? (matches exactly 1 character)</li> </ul> </div> <div> <p>Example path patterns</p> <ul> <li><code>/img/*</code></li> <li><code>/js/*</code></li> </ul> </div> <p>Option 1 is incorrect because host-based routing defines rules that forward requests to different target groups based on the host name in the host header instead of the URL, which is what is needed in this scenario.</p> <p>Option 2 is incorrect because a Classic Load Balancer does not support path-based routing. You must use an Application Load Balancer.</p> <p>Option 4 is incorrect because a&nbsp;Network Load Balancer is used for applications that need extreme network performance and static IP. It also does not support path-based routing which is what is needed in this scenario. Furthermore, the statement mentions host-based routing yet, the description is about path-based routing.</p> <p><strong>References:</strong></p> <p><a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html#application-load-balancer-benefits">https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html#application-load-balancer-benefits</a></p> <p><a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-listeners.html#path-conditions"> https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-listeners.html#path-conditions</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p>Use host conditions to define rules that forward requests to different target groups based on the host name in the host header. This enables you to support multiple domains using a single load balancer.</p>', '<p>Replace your ALB with a Classic Load Balancer then use path conditions to define rules that forward requests to different target groups based on the URL in the request.</p>', '<p>Use path conditions to define rules that forward requests to different target groups based on the URL in the request.</p>', '<p>Replace your ALB with a Network Load Balancer then use host conditions to define rules that forward requests to different target groups based on the URL in the request.</p>'], 'question': '<p>A fast food company is using AWS to host their online ordering system which uses an Auto Scaling group of EC2 instances deployed across multiple Availability Zones with an Application Load Balancer in front. To better handle the incoming traffic from various digital devices, you are planning to implement a new routing system where requests which have a URL of &lt;server&gt;/api/android are forwarded to one specific target group named "Android-Target-Group". Conversely, requests which have a URL of &lt;server&gt;/api/ios are forwarded to another separate target group named "iOS-Target-Group".\xa0 \xa0</p><p>How can you implement this change in AWS?</p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T08:07:55Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as a Solution Architect for a startup company in Silicon Valley. Their application architecture is currently setup to store both the access key ID and the secret access key in a plain text file on a custom Amazon Machine Image(AMI). The EC2 instances, which are created by using this AMI, are using the stored access keys to connect to a DynamoDB table. What should you do to make the current architecture more secure?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181066, 'original_assessment_id': 2567392, 'section': 'IAM', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['Put the access keys in Amazon Glacier instead.', 'Put the access keys in an Amazon S3 bucket instead.', 'Remove the stored access keys in the AMI. Create a new IAM role with permissions to access the DynamoDB table and assign it to the EC2 instances.', 'Do nothing. The architecture is already secure because the access keys are already in the Amazon Machine Image.'], 'explanation': '<p>You should use an IAM role to manage&nbsp;<em>temporary</em>&nbsp;credentials for applications that run on an EC2 instance. When you use an IAM role, you don\'t have to distribute long-term credentials (such as a user name and password or access keys) to an EC2 instance.</p><p>Instead, the role supplies temporary permissions that applications can use when they make calls to other AWS resources. When you launch an EC2 instance, you specify an IAM role to associate with the instance. Applications that run on the instance can then use the role-supplied temporary credentials to sign API requests.</p><p>Hence, the best option here is to remove the stored access keys first in the AMI. Then, create a new IAM role with permissions to access the DynamoDB table and assign it to the EC2 instances.</p><p>Options 1 and 2 are incorrect because S3 and Glacier are mainly used as a storage option. It is better to use an IAM role instead of storing access keys in these storage services.</p><p>Option 4 is incorrect because you can make the architecture more secure by using IAM.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html">https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html</a></p>', 'question': 'You are working as a Solution Architect for a startup company in Silicon Valley. Their application architecture is currently setup to store both the access key ID and the secret access key in a plain text file on a custom Amazon Machine Image(AMI). The EC2 instances, which are created by using this AMI, are using the stored access keys to connect to a DynamoDB table. <br>What should you do to make the current architecture more secure?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Which instance type is best to use for workloads that require high, sequential read and write access to very large data sets on local storage?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181158, 'original_assessment_id': 2567486, 'section': 'EC2', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['Storage Optimized Instances', 'Memory Optimized Instances', 'Compute Optimized Instances', 'General Purpose Instances'], 'explanation': '<div><p>Storage optimized instances are designed for workloads that require high, sequential read and write access to very large data sets on local storage. They are optimized to deliver tens of thousands of low-latency, random I/O operations per second (IOPS) to applications.</p><p>&nbsp;</p></div><p>References:</p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/storage-optimized-instances.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/storage-optimized-instances.html</a></p><p>&nbsp;</p>', 'question': 'Which instance type is best to use for workloads that require high, sequential read and write access to very large data sets on local storage?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'An application is using serverless services to process financial data using Lambda. Due to the vast number of data being processed, you were concerned if your current AWS resources can handle the load.\xa0 \xa0In AWS Lambda, what is the maximum execution duration per request?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181060, 'original_assessment_id': 2567386, 'section': 'Lambda', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['3 seconds', '<p>15 minutes</p>', '24 hours', 'No limit'], 'explanation': '<p>The maximum execution duration per request in AWS Lambda is 900 seconds, which is equivalent to 15 minutes.</p> <p><strong>Reference:&nbsp;</strong></p> <p><a href="https://docs.aws.amazon.com/lambda/latest/dg/limits.html">https://docs.aws.amazon.com/lambda/latest/dg/limits.html</a></p>', 'question': '<p>An application is using serverless services to process financial data using Lambda. Due to the vast number of data being processed, you were concerned if your current AWS resources can handle the load.\xa0 \xa0</p><p>In AWS Lambda, what is the maximum execution duration per request?</p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are trying to enable Cross-Region Replication to your S3 bucket but this option is disabled.Which of the following options is a valid reason for this?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181068, 'original_assessment_id': 2567394, 'section': 'S3', 'prompt': {'explanation': '<p>To enable the cross-region replication feature in S3, the following items should be met:</p><ol><li>The source and destination buckets must have <span style="text-decoration: underline;">versioning</span> enabled.</li><li>The source and destination buckets must be in different AWS Regions.</li><li>Amazon S3 must have permissions to replicate objects from that source bucket to the destination bucket on your behalf.</li></ol><br /><ul><li>Options 1 and 4 are wrong as this feature is available to all types of S3 classes.</li><li>Option 2 is incorrect as this CRR feature is available to all&nbsp;Support Plans.</li></ul><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html</a></p>', 'answers': ['The Cross-Region Replication feature is only available for Amazon S3 - RRS.', 'This is a premium feature which is only for AWS Enterprise accounts.', 'In order to use the Cross-Region Replication feature in S3, you need to first enable versioning on the bucket.', 'The Cross-Region Replication feature is only available for Amazon S3 - Infrequent Access.'], 'question': 'You are trying to enable Cross-Region Replication to your S3 bucket but this option is disabled.<br /><br />Which of the following options is a valid reason for this?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'In a tech company that you are working for, there is a requirement to allow one IAM user to modify the configuration of one of your Elastic Load Balancers (ELB). This access is required only once. Which of the following would be the best way to allow this access?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181070, 'original_assessment_id': 2567396, 'section': 'IAM', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['Open up the port that ELB uses in a security group and then give the user access to that security group via a policy.', 'Create a new IAM Role then associate it to the IAM user. Attach a policy allowing access to modify the ELB and once it is done, remove the IAM role to the user.', 'Create a new IAM user that has access to modify the ELB. Delete that user when the work is completed.', 'Provide the user temporary access to the root account for 8 hours only. Afterwards, change the password once the activity is completed.'], 'explanation': '<p>In this scenario, the best option is to use IAM Role to provide access. You can create a new IAM Role then associate it to the IAM user. Attach a policy allowing access to modify the ELB and once it is done, remove the IAM role to the user.</p><p>An IAM&nbsp;<em>role</em>&nbsp;is similar to a user in that it is an AWS identity with permission policies that determine what the identity can and cannot do in AWS. However, instead of being uniquely associated with one person, a role is intended to be assumable by anyone who needs it. Also, a role does not have standard long-term credentials (password or access keys) associated with it. Instead, if a user assumes a role, temporary security credentials are created dynamically and provided to the user.</p><p>You can use roles to delegate access to users, applications, or services that don\'t normally have access to your AWS resources. For example, you might want to grant users in your AWS account access to resources they don\'t usually have, or grant users in one AWS account access to resources in another account. Or you might want to allow a mobile app to use AWS resources, but not want to embed AWS keys within the app (where they can be difficult to rotate and where users can potentially extract them). Sometimes you want to give AWS access to users who already have identities defined outside of AWS, such as in your corporate directory. Or, you might want to grant access to your account to third parties so that they can perform an audit on your resources.</p><p>Resources:</p><p><a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user.html">https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user.html</a></p>', 'question': 'In a tech company that you are working for, there is a requirement to allow one IAM user to modify the configuration of one of your Elastic Load Balancers (ELB). This access is required only once. <br><br>Which of the following would be the best way to allow this access?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have 2 SUSE Linux Enterprise Server instances located in different subnets in the same VPC. These EC2 instances should be able to communicate with each other, but you always get a timeout when you try to ping from one instance to another. In addition, the route tables seem to be valid and have the entry for the Target ‘local’ for your VPC CIDR.\xa0 \xa0Which of the following could be a valid reason for this issue?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181072, 'original_assessment_id': 2567398, 'section': 'Networking', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['The two EC2 Instances have different versions of the SUSE Linux AMI.', 'You have not configured the Security Group to allow the required traffic between the two subnets. ', 'The EC2 instances do not have Public IPs attached to them.', 'The EC2 Instances do not have Elastic IPs.'], 'explanation': '<p>To ensure that ping commands can go through between EC2 instances, security groups need to be configured. The ping utility uses the ICMP protocol, so this needs to be set in the Inbound Rules of your security group to ensure that the ping packets can be routed to the EC2 instances.&nbsp;</p><br /><p>Resources:</p><p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html"  target="_blank" >http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html</a></p><p>&nbsp;</p>', 'question': '<p>You have 2 SUSE Linux Enterprise Server instances located in different subnets in the same VPC. These EC2 instances should be able to communicate with each other, but you always get a timeout when you try to ping from one instance to another. In addition, the route tables seem to be valid and have the entry for the Target ‘local’ for your VPC CIDR.\xa0 \xa0</p><p>Which of the following could be a valid reason for this issue?</p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T08:09:29Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are instructed by your manager to create a publicly accessible EC2 instance by using an Elastic IP (EIP) address and also to give him a report on how much it will cost to use that EIP. Which of the following statements is correct regarding the pricing of EIP?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181074, 'original_assessment_id': 2567400, 'section': 'EIP', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['There is no cost if the instance is running and it has only one associated EIP. ', 'There is no cost if the instance is terminated and it has only one associated EIP. ', 'There is no cost if the instance is stopped and it has only one associated EIP. ', 'There is no cost if the instance is running and it has at least two associated EIP. '], 'explanation': '<p>An Elastic IP address doesn&rsquo;t incur charges as long as the following conditions are true:</p><ul><li>-The Elastic IP address is associated with an Amazon EC2 instance.</li><li>-The instance associated with the Elastic IP address is running.</li><li>-The instance has only one Elastic IP address attached to it.</li></ul><br /><p>If you&rsquo;ve stopped or terminated an EC2 instance with an associated Elastic IP address and you don&rsquo;t need that Elastic IP address anymore, consider disassociating or releasing the Elastic IP address .</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/premiumsupport/knowledge-center/elastic-ip-charges/">https://aws.amazon.com/premiumsupport/knowledge-center/elastic-ip-charges/</a></p><p>&nbsp;</p>', 'question': '<p>You are instructed by your manager to create a publicly accessible EC2 instance by using an Elastic IP (EIP) address and also to give him a report on how much it will cost to use that EIP. <br><br>Which of the following statements is correct regarding the pricing of EIP?</p>'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'In Amazon RDS, database snapshots and automated backups are stored in:', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181076, 'original_assessment_id': 2567402, 'section': 'RDS', 'prompt': {'explanation': '<p>Amazon RDS DB snapshots and automated backups are stored in S3.</p><p>You can use the AWS Management Console, the ModifyDBInstance API, or the modify-db-instance command to manage the period of time your automated backups are retained by modifying the RetentionPeriod parameter. If you desire to turn off automated backups altogether, you can do so by setting the retention period to 0 (not recommended).</p><p>You can manage your user-created DB Snapshots via the "Snapshots" section of the Amazon RDS Console. Alternatively, you can see a list of the user-created DB Snapshots for a given DB Instance using the DescribeDBSnapshots API or describe-db-snapshots command and delete snapshots with the DeleteDBSnapshot API or delete-db-snapshot command.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/rds/faqs/">https://aws.amazon.com/rds/faqs/</a></p><p>&nbsp;</p><p>&nbsp;</p>', 'answers': ['Amazon S3', 'Amazon ECS Volume', 'Amazon RDS', 'Amazon EMR'], 'question': 'In Amazon RDS, database snapshots and automated backups are stored in:'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A startup company wants to launch a fleet of EC2 instances on AWS. Your manager wants to ensure that the Java programming language is installed automatically when the instance is launched. In which of the below configurations can you achieve this requirement?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181078, 'original_assessment_id': 2567404, 'section': 'EC2', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['User data', 'EC2Config service', 'IAM roles', 'AWS Config'], 'explanation': '<p>When you launch an instance in Amazon EC2, you have the option of passing <strong>user data</strong> to the instance that can be used to perform common automated configuration tasks and even run scripts after the instance starts. You can write and run scripts that install new packages, software, or tools in your instance when it is launched.</p> <p>You can pass two types of user data to Amazon EC2: shell scripts and cloud-init directives. You can also pass this data into the launch wizard as plain text, as a file (this is useful for launching instances using the command line tools), or as base64-encoded text (for API calls).</p> <p><strong>Reference:</strong></p> <p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/user-data.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/user-data.html</a></p> <p>&nbsp;</p>', 'question': 'A startup company wants to launch a fleet of EC2 instances on AWS. Your manager wants to ensure that the Java programming language is installed automatically when the instance is launched. In which of the below configurations can you achieve this requirement?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T08:10:29Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'It is the budget season for a DevOps consulting firm where you work as a Senior Technical Operations Lead. Your company promises to give a bonus if you were able to reduce company expenses from the bills payment app you are handling. For you to know if the company will give you a pay raise and bonus, you need to check your AWS Billing dashboard to compare your last year’s expenditures against the current year.\xa0 \xa0Which of the following is not a feature of the service?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181080, 'original_assessment_id': 2567406, 'section': 'Trusted Advisor', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['Analyzing costs with graphs using the Cost Explorer tool', 'Provide forecasts of your estimated costs with Budgets', 'AWS Cost and Usage reports', 'Service Limits'], 'explanation': '<p>All of these are features&nbsp;in Billing and Cost Management service except for option 4: Service Limits, which is handled by AWS Trusted Advisor.&nbsp;</p><p>The Billing and Cost Management service provides features that you can use to estimate and plan your AWS costs, receive alerts if your costs exceed a threshold that you set, assess your biggest investments in AWS resources, and, if you work with multiple AWS accounts, simplify your accounting.</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/billing-what-is.html">https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/billing-what-is.html</a></p><p><a href="https://aws.amazon.com/premiumsupport/trustedadvisor/">https://aws.amazon.com/premiumsupport/trustedadvisor/</a></p>', 'question': '<p>It is the budget season for a DevOps consulting firm where you work as a Senior Technical Operations Lead. Your company promises to give a bonus if you were able to reduce company expenses from the bills payment app you are handling. For you to know if the company will give you a pay raise and bonus, you need to check your AWS Billing dashboard to compare your last year’s expenditures against the current year.\xa0 \xa0</p><p>Which of the following is not a feature of the service?\xa0 </p>'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'As a Solutions Architect, you have been requested to set up a highly decoupled application in AWS. Which of the following can help you accomplish this goal?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181084, 'original_assessment_id': 2567410, 'section': 'SQS', 'prompt': {'explanation': '<p>Amazon Simple Queue Service (SQS) is a fully managed message queuing service that makes it easy to decouple and scale microservices, distributed systems, and serverless applications. Building applications from individual components that each perform a discrete function improves scalability and reliability, and is best practice design for modern applications. SQS makes it simple and cost-effective to decouple and coordinate the components of a cloud application. Using SQS, you can send, store, and receive messages between software components at any volume, without losing messages or requiring other services to be always available.</p><p>&nbsp;</p><p>Resources:</p><p><a href="https://aws.amazon.com/sqs/">https://aws.amazon.com/sqs/</a></p><p>&nbsp;</p>', 'answers': ['An SQS queue to allow a second EC2 instance to process a failed instance’s job', 'An Elastic Load Balancer to send web traffic to healthy EC2 instances', 'IAM user credentials on EC2 instances to grant permissions to modify an SQS queue', 'An Auto Scaling group to recover from EC2 instance failures'], 'question': 'As a Solutions Architect, you have been requested to set up a highly decoupled application in AWS. Which of the following can help you accomplish this goal? '}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': "You are working for a global news network where you have set up a CloudFront distribution for your web application. However, you noticed that your application's origin server is being hit for each request instead of the AWS Edge locations, which serve the cached objects. The issue occurs even for the commonly requested objects. What could be a possible cause of this issue?", '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181086, 'original_assessment_id': 2567412, 'section': 'CloudFront', 'prompt': {'explanation': '<p>In this scenario, the main culprit is that the Cache-Control max-age directive is set to a low value, which is why the request is always directed to your origin server. Hence, option 3 is correct.&nbsp;</p><p>Option 1 is incorrect because the issue also occurs even for the commonly requested objects. This means that these objects were successfully requested before but due to a low&nbsp;Cache-Control max-age directive value, it causes this issue in Cloudfront.</p><p>Options 2 and 4 are incorrect because they are not related to the issue in caching.</p><p>You can control how long your objects stay in a CloudFront cache before CloudFront forwards another request to your origin. Reducing the duration allows you to serve dynamic content. Increasing the duration means your users get better performance because your objects are more likely to be served directly from the edge cache. A longer duration also reduces the load on your origin.</p><p>Typically, CloudFront serves an object from an edge location until the cache duration that you specified passes &mdash; that is, until the object expires. After it expires, the next time the edge location gets a user request for the object, CloudFront forwards the request to the origin server to verify that the cache contains the latest version of the object.</p><p>The&nbsp;<code>Cache-Control</code>&nbsp;and&nbsp;<code>Expires</code>&nbsp;headers control how long objects stay in the cache.&nbsp;The&nbsp;<code>Cache-Control max-age</code>&nbsp;directive lets you specify how long (in seconds) you want an object to remain in the cache before CloudFront gets the object again from the origin server. The minimum expiration time CloudFront supports is 0 seconds for web distributions and 3600 seconds for RTMP distributions.</p><p>References:&nbsp;</p><p><a href="http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html">http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html</a></p>', 'answers': ['An object is only cached by Cloudfront once a successful request has been made hence, the objects were not requested before, which is why the request is still directed to the origin server.', 'The file sizes of the cached objects are too large for Cloudfront to handle.', 'The Cache-Control max-age directive is set to a low value.', 'You did not add an SSL certificate.'], 'question': "You are working for a global news network where you have set up a CloudFront distribution for your web application. However, you noticed that your application's origin server is being hit for each request instead of the AWS Edge locations, which serve the cached objects. The issue occurs even for the commonly requested objects. <br /><br />What could be a possible cause of this issue?"}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'AWS hosts a variety of public datasets such as satellite imagery, geospatial, or genomic data that you want to use to your web application hosted in Amazon EC2. If you use these datasets, how much will it cost you?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181088, 'original_assessment_id': 2567414, 'section': 'Billing and Cost Management', 'prompt': {'explanation': '<div><p>AWS hosts a variety of public datasets that anyone can access for <strong>free</strong>.</p><p>Previously, large datasets such as satellite imagery or genomic data have required hours or days to locate, download, customize, and analyze. When data is made publicly available on AWS, anyone can analyze any volume of data without needing to download or store it themselves.&nbsp;</p></div><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/public-datasets/" target="_blank" rel="noopener">https://aws.amazon.com/public-datasets/</a></p>', 'answers': ['A one-time charge of $10.', '$10 per month for each dataset.', '$10 per month for all datasets.', 'No charge.'], 'question': 'AWS hosts a variety of public datasets such as satellite imagery, geospatial, or genomic data that you want to use to your web application hosted in Amazon EC2. <br /><br />If you use these datasets, how much will it cost you?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A business reporting web application needs an OLAP database to store its analytical data. You recommended to use Amazon Redshift, which is a fully managed, petabyte-scale data warehouse service in the cloud.\xa0 \xa0What block size does Redshift use for its columnar storage?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181090, 'original_assessment_id': 2567416, 'section': 'Redshift', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['1 KB', '2 KB', '32 KB', '1 MB'], 'explanation': '<p>Typical database block sizes range from 2 KB to 32 KB. Amazon Redshift uses a block size of 1 MB, which is more efficient and further reduces the number of I/O requests needed to perform any database loading or other operations that are part of query execution.</p><br /><p>References:</p><p><a href="http://docs.aws.amazon.com/redshift/latest/dg/c_columnar_storage_disk_mem_mgmnt.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/redshift/latest/dg/c_columnar_storage_disk_mem_mgmnt.html</a></p>', 'question': '<p>A business reporting web application needs an OLAP database to store its analytical data. You recommended to use Amazon Redshift, which is a fully managed, petabyte-scale data warehouse service in the cloud.\xa0 \xa0</p><p>What block size does Redshift use for its columnar storage?</p>'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as a Cloud Engineer in a leading technology consulting firm which is using a fleet of Windows-based EC2 instances with IPv4 addresses launched in a private subnet. Several software installed in the EC2 instances are required to be updated via the Internet.\xa0 \xa0Which of the following services can provide you with a highly available solution to safely allow the instances to fetch the software patches from the Internet but prevent outside network from initiating a connection?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181156, 'original_assessment_id': 2567484, 'section': 'VPC', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['<p>Egress-Only Internet Gateway\xa0 </p>', '<p>VPC Endpoint\xa0 </p>', 'NAT Gateway', '<p>NAT Instance\xa0 </p>'], 'explanation': '<p>AWS offers two kinds of NAT devices &mdash; a NAT gateway or a NAT instance. It is recommended to use NAT gateways, as they provide better availability and bandwidth over NAT instances. The NAT Gateway service is also a managed service that does not require your administration efforts. A NAT instance is launched from a NAT AMI.</p> <p>Just like a NAT instance, you can use a network address translation (NAT) gateway to enable instances in a private subnet to connect to the internet or other AWS services, but prevent the internet from initiating a connection with those instances.</p> <p>Option 1 is incorrect because an Egress-only Internet gateway is primarily used for VPCs that use IPv6 to enable instances in a private subnet to connect to the Internet or other AWS services, but prevent the Internet from initiating a connection with those instances, just like what NAT Instance and NAT Gateway do. The scenario explicitly says that the EC2 instances are using IPv4 addresses which is why Egress-only Internet gateway is invalid, even though it can provide the required high availability.</p> <p>Option 2 is incorrect because a VPC endpoint simply enables you to privately connect your VPC to supported AWS services and VPC endpoint services powered by PrivateLink without requiring an Internet gateway, NAT device, VPN connection, or AWS Direct Connect connection.</p> <p>Option 4 is incorrect because although a NAT instance can also enable instances in a private subnet to connect to the Internet or other AWS services and prevent the Internet from initiating a connection with those instances, it is not as highly available compared to a NAT Gateway.</p> <p><strong>References:</strong></p> <p><a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-nat-gateway.html">https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-nat-gateway.html</a></p> <p><a href="https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-comparison.html">https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-comparison.html</a></p> <p><a href="https://docs.aws.amazon.com/vpc/latest/userguide/egress-only-internet-gateway.html">https://docs.aws.amazon.com/vpc/latest/userguide/egress-only-internet-gateway.html</a></p>', 'question': '<p>You are working as a Cloud Engineer in a leading technology consulting firm which is using a fleet of Windows-based EC2 instances with IPv4 addresses launched in a private subnet. Several software installed in the EC2 instances are required to be updated via the Internet.\xa0 \xa0</p><p>Which of the following services can provide you with a highly available solution to safely allow the instances to fetch the software patches from the Internet but prevent outside network from initiating a connection?\xa0 </p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Your company has developed a financial analytics web application hosted in a Docker container using MEAN (MongoDB, Express.js, AngularJS, and Node.js) stack. You want to easily port that web application to AWS Cloud. Which of the following services can be used to fulfill this requirement?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181094, 'original_assessment_id': 2567420, 'section': 'Elastic Beanstalk', 'prompt': {'explanation': '<p>Elastic Beanstalk supports the deployment of web applications from Docker containers. With Docker containers, you can define your own runtime environment. You can choose your own platform, programming language, and any application dependencies (such as package managers or tools), that aren\'t supported by other platforms. Docker containers are self-contained and include all the configuration information and software your web application requires to run.</p><p>By using Docker with Elastic Beanstalk, you have an infrastructure that automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring. You can manage your web application in an environment that supports the range of services that are integrated with Elastic Beanstalk, including but not limited to VPC, RDS, and IAM.</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create_deploy_docker.html">https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create_deploy_docker.html</a></p><p>&nbsp;</p>', 'answers': ['AWS Elastic Load Balancer', 'AWS SNS', 'AWS SQS', 'AWS Elastic Beanstalk'], 'question': 'Your company has developed a financial analytics web application hosted in a Docker container using MEAN (MongoDB, Express.js, AngularJS, and Node.js) stack. You want to easily port that web application to AWS Cloud. <br /><br />Which of the following services can be used to fulfill this requirement?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multi-select', 'question_plain': 'In an investment bank where you work as a Cloud Engineer, there is a new project to move your Cardholder Data Environment (CDE) over to AWS. You will need to take steps to secure your cloud infrastructure to meet the compliance requirements and policies, which is why you have decided to use AWS Identity and Access Management. This service is used to manage which items? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181092, 'original_assessment_id': 2567418, 'section': 'IAM', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', ''], 'answers': ['Security Groups', 'API Keys', 'Multi-Factor Authentication', 'Roles', '<p>Penetration Testing </p>'], 'explanation': '<p>AWS Identity and Access Management (IAM) enables you to securely control access to AWS services and resources for your users. Using IAM, you can create and manage AWS users, roles, and groups, and use permissions to allow and deny their access to AWS resources. It also allows you to provision API Keys and Multi-Factor Authentication to your users.</p> <p>Option 1 is incorrect because client-side data encryption is the responsibility of the customers and not AWS. In addition, this is not covered by IAM.</p> <p>Option 5 is incorrect because penetration testing is an activity done by the client and does not usually make use of IAM. AWS policy only permits testing on the following resources: EC2, RDS, Aurora, Cloudfront, API Gateway, Lambda, Lightsail, and DNS Zone Walking.</p> <p><strong>References:</strong></p> <p><a href="https://aws.amazon.com/iam/">https://aws.amazon.com/iam/</a></p> <p><a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html">https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html</a></p> <p><a href="https://aws.amazon.com/security/penetration-testing/">https://aws.amazon.com/security/penetration-testing/</a></p>', 'question': '<p>In an investment bank where you work as a Cloud Engineer, there is a new project to move your Cardholder Data Environment (CDE) over to AWS. You will need to take steps to secure your cloud infrastructure to meet the compliance requirements and policies, which is why you have decided to use AWS Identity and Access Management. This service is used to manage which items? (Choose 3)</p>'}, 'related_lectures': [], 'correct_response': ['b', 'c', 'd'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a computer animation film studio that has a web application running on an Amazon EC2 instance. It uploads 5 GB video objects to an Amazon S3 bucket. Video uploads are taking longer than expected, which impacts the performance of your application. Which method will help improve the performance of your application?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181096, 'original_assessment_id': 2567422, 'section': 'S3', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>The main issue is the slow upload time of the video objects to Amazon S3. To address this issue, you can use Multipart upload in S3 to improve the throughput. It allows you to upload parts of your object in parallel thus, decreasing the time it takes to upload big objects. Each part is a contiguous portion of the object\'s data.</p> <p>You can upload these object parts independently and in any order. If transmission of any part fails, you can retransmit that part without affecting other parts. After all parts of your object are uploaded, Amazon S3 assembles these parts and creates the object. In general, when your object size reaches 100 MB, you should consider using multipart uploads instead of uploading the object in a single operation.</p> <p>Using multipart upload provides the following advantages:</p> <ol> <li>Improved throughput - You can upload parts in parallel to improve throughput.</li> <li>Quick recovery from any network issues - Smaller part size minimizes the impact of restarting a failed upload due to a network error.</li> <li>Pause and resume object uploads - You can upload object parts over time. Once you initiate a multipart upload, there is no expiry; you must explicitly complete or abort the multipart upload.</li> <li>Begin an upload before you know the final object size - You can upload an object as you are creating it.</li> </ol> <p><strong>References:</strong></p> <p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/uploadobjusingmpu.html">https://docs.aws.amazon.com/AmazonS3/latest/dev/uploadobjusingmpu.html</a></p> <p><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/qfacts.html">http://docs.aws.amazon.com/AmazonS3/latest/dev/qfacts.html</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'answers': ['Enable Enhanced Networking to your EC2 Instances.', 'Use Amazon S3 Multipart Upload API.', 'Leverage on Amazon CloudFront and use HTTP POST method to reduce latency.', '<p>Use Amazon Elastic Block Store Provisioned IOPS and an Amazon EBS-optimized instance.</p>'], 'question': '<p>You are working for a computer animation film studio that has a web application running on an Amazon EC2 instance. It uploads 5 GB video objects to an Amazon S3 bucket. Video uploads are taking longer than expected, which impacts the performance of your application. <br><br>Which method will help improve the performance of your application?</p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T08:11:42Z'}, {'assessment_type': 'multi-select', 'question_plain': 'Which DNS record types does Amazon Route 53 support? (Select all that applies)', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181130, 'original_assessment_id': 2567456, 'section': 'Route53', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['A (address record)', 'AAAA (IPv6 address record)', 'CNAME (canonical name record)', 'MX (mail exchange record)', 'SRV (service locator)', 'SPF (session policy forwarder)'], 'explanation': '<p>All options are correct except for option 6 because there is no such thing as SPF (session policy forwarder). There is, however, a record type called: SPF (sender policy framework).</p><p>Amazon Route 53 currently supports the following DNS record types:</p><ul><li>A (address record)</li><li>AAAA (IPv6 address record)</li><li>CNAME (canonical name record)</li><li>CAA (certification authority authorization)</li><li>MX (mail exchange record)</li><li>NAPTR (name authority pointer record)</li><li>NS (name server record)</li><li>PTR (pointer record)</li><li>SOA (start of authority record)</li><li>SPF (sender policy framework)</li><li>SRV (service locator)</li><li>TXT (text record)</li></ul><p>&nbsp;</p><p>Resources:</p><p><a href="https://aws.amazon.com/route53/faqs/">https://aws.amazon.com/route53/faqs/</a></p>', 'question': 'Which DNS record types does Amazon Route 53 support? (Select all that applies)'}, 'related_lectures': [], 'correct_response': ['a', 'b', 'c', 'd', 'e'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A mobile application stores pictures in Amazon Simple Storage Service (S3) and allows application sign-in using an OpenID Connect-compatible identity provider. Which AWS Security Token Service approach to temporary access should you use for this scenario?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181098, 'original_assessment_id': 2567424, 'section': 'IAM', 'prompt': {'explanation': '<p>With web identity federation, you don\'t need to create custom sign-in code or manage your own user identities. Instead, users of your app can sign in using a well-known identity provider (IdP) &mdash;such as Login with Amazon, Facebook, Google, or any other OpenID Connect (OIDC)-compatible IdP, receive an authentication token, and then exchange that token for temporary security credentials in AWS that map to an IAM role with permissions to use the resources in your AWS account. Using an IdP helps you keep your AWS account secure because you don\'t have to embed and distribute long-term security credentials with your application.</p><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc.html</a></p>', 'answers': ['SAML-based Identity Federation', 'Cross-Account Access', 'AWS Identity and Access Management roles', 'Web Identity Federation'], 'question': 'A mobile application stores pictures in Amazon Simple Storage Service (S3) and allows application sign-in using an OpenID Connect-compatible identity provider. <br /><br />Which AWS Security Token Service approach to temporary access should you use for this scenario?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': "As the Solutions Architect, you have built a photo-sharing site for an entertainment company. The site was hosted using 3 EC2 instances in a single availability zone with a Classic Load Balancer in front to evenly distribute the incoming load.\xa0 \xa0What should you do to enable your Classic Load Balancer to bind a user's session to a specific instance?", '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181100, 'original_assessment_id': 2567426, 'section': 'ELB', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['Sticky Sessions', 'Availability Zone', 'Placement Group', 'Security Group'], 'explanation': '<div> <p>By default, a Classic Load Balancer routes each request independently to the registered instance with the smallest load. However, you can use the&nbsp;<em>sticky session</em>&nbsp;feature (also known as&nbsp;<em>session affinity</em>), which enables the load balancer to bind a user\'s session to a specific instance. This ensures that all requests from the user during the session are sent to the same instance.</p> <p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://udemy-images.s3.amazonaws.com/redactor/raw/2018-10-28_00-42-12-120ae3a1821b473c8a0c3de2d13b7227.png" /></p> <p>The key to managing sticky sessions is to determine how long your load balancer should consistently route the user\'s request to the same instance. If your application has its own session cookie, then you can configure Elastic Load Balancing so that the session cookie follows the duration specified. If your application does not have its own session cookie, then you can configure Elastic Load Balancing to create a session cookie by specifying your own stickiness duration.</p> <p><strong>Reference:</strong></p> </div> <p><a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-sticky-sessions.html">https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-sticky-sessions.html</a></p> <p>&nbsp;</p> <p>&nbsp;</p>', 'question': "<p>As the Solutions Architect, you have built a photo-sharing site for an entertainment company. The site was hosted using 3 EC2 instances in a single availability zone with a Classic Load Balancer in front to evenly distribute the incoming load.\xa0 \xa0</p><p>What should you do to enable your Classic Load Balancer to bind a user's session to a specific instance?\xa0 </p>"}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as an IT Consultant and one of your clients consults you about their VPC. They have a web application which consists of an Application Load Balancer, a MySQL database running in RDS, and an Auto-Scaling Group with EC2 instances. They asked you about the security measures that AWS provides in their infrastructure. Based on the Shared Responsibility Model, which of the following is part of AWS responsibility?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181102, 'original_assessment_id': 2567428, 'section': 'AWS Shared Responsibility Model', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['Firewall configuration.', 'Protection of your EC2 instances against network address spoofing or packet sniffing.', 'Encryption of all communication between EC2 instances and ELB.', '<p>Installation of the latest security patches on ELB\xa0and EC2 instances.</p>'], 'explanation': '<p>In the Shared Responsibility Model, AWS is responsible for protecting the infrastructure that runs all of the services offered in the AWS Cloud. This infrastructure is composed of the hardware, software, networking, and facilities that run AWS Cloud services which includes protection from Network Address Spoofing and Packet Sniffing. Hence, option 2 is correct.</p><p>Options 1, 3, and 4 are incorrect as all of these are the responsibility of the customer. Refer to the model diagram and reference links below for more information:</p><p><img src="https://d1.awsstatic.com/security-center/NewSharedResponsibilityModel.749924fb27d7c6de5cd59376dbaab323f86ce5dd.png" width="661" height="337" /></p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/compliance/shared-responsibility-model/">https://aws.amazon.com/compliance/shared-responsibility-model/</a></p><p><a href="https://aws.amazon.com/answers/networking/vpc-security-capabilities/">https://aws.amazon.com/answers/networking/vpc-security-capabilities/</a></p>', 'question': 'You are working as an IT Consultant and one of your clients consults you about their VPC. They have a web application which consists of an Application Load Balancer, a MySQL database running in RDS, and an Auto-Scaling Group with EC2 instances. They asked you about the security measures that AWS provides in their infrastructure. <br><br>Based on the Shared Responsibility Model, which of the following is part of AWS responsibility? '}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are a Solutions Architect of a tech company. You are having an issue whenever you try to connect to your newly created EC2 instance using a Remote Desktop connection from your computer. Upon checking, you have verified that the instance has a public IP and the Internet gateway and route tables are in place. What else should you do for you to resolve this issue?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181104, 'original_assessment_id': 2567430, 'section': 'EC2', 'prompt': {'explanation': '<p>Since you are using a Remote Desktop connection to access your EC2 instance, you have to ensure that the&nbsp;Remote Desktop Protocol is allowed in the security group. By default, the server listens on TCP port 3389 and UDP port 3389.</p><p>Option 1 is incorrect as the port 22 is used for SSH connections and not for RDP.</p><p>Options 3 and 4 are incorrect as the EC2 instance is newly created and hence, unlikely to cause the issue. You have to check the security group first if it allows the Remote Desktop Protocol (3389) before investigating if there is indeed an issue on the specific instance.</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/troubleshooting-windows-instances.html#rdp-issues">https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/troubleshooting-windows-instances.html#rdp-issues</a></p><p>&nbsp;</p>', 'answers': ['You should adjust the security group to allow traffic from port 22', 'You should adjust the security group to allow traffic from port 3389', 'You should restart the EC2 instance since there might be some issue with the instance', 'You should create a new instance since there might be some issue with the instance'], 'question': 'You are a Solutions Architect of a tech company. You are having an issue whenever you try to connect to your newly created EC2 instance using a Remote Desktop connection from your computer. Upon checking, you have verified that the instance has a public IP and the Internet gateway and route tables are in place. <br /><br />What else should you do for you to resolve this issue?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You were hired as an IT Consultant in a startup cryptocurrency company that wants to go global with their international money transfer app. Your project is to make sure that the database of the app is highly available on multiple regions.\xa0 \xa0What are the benefits of adding Multi-AZ deployments in Amazon RDS? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181082, 'original_assessment_id': 2567408, 'section': 'RDS', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', ''], 'answers': ['It makes the database fault-tolerant to an Availability Zone failure.', 'Significantly increases the database performance.', 'Creates a primary DB Instance and synchronously replicates the data to a standby instance in a different Availability Zone (AZ) in a different region.', 'Increased database availability in the case of system upgrades like OS patching or DB Instance scaling.', 'Provides SQL optimization.'], 'explanation': '<p>The correct answers are options 1 &amp; 4:</p> <ul> <li>Increased database availability in the case of system upgrades like OS patching or DB Instance scaling.</li> <li>It makes the database fault-tolerant to an Availability Zone failure</li> </ul><br /> <p>Option 3 is almost correct. RDS synchronously replicates the data to a standby instance in a different Availability Zone (AZ) that is in the same region and not in a different one.</p> <p>Options 2 and 5 are incorrect as it does not affect the performance nor provide SQL optimization.</p> <p>Amazon RDS Multi-AZ deployments provide enhanced availability and durability for Database (DB) Instances, making them a natural fit for production database workloads. When you provision a Multi-AZ DB Instance, Amazon RDS automatically creates a primary DB Instance and synchronously replicates the data to a standby instance in a different Availability Zone (AZ). Each AZ runs on its own physically distinct, independent infrastructure, and is engineered to be highly reliable.</p> <p>In case of an infrastructure failure, Amazon RDS performs an automatic failover to the standby (or to a read replica in the case of Amazon Aurora), so that you can resume database operations as soon as the failover is complete. Since the endpoint for your DB Instance remains the same after a failover, your application can resume database operation without the need for manual administrative intervention.</p> <p>&nbsp;</p> <p>References:</p> <p><a href="https://aws.amazon.com/rds/details/multi-az/" target="_blank" rel="noopener">https://aws.amazon.com/rds/details/multi-az/</a></p>', 'question': '<p>You were hired as an IT Consultant in a startup cryptocurrency company that wants to go global with their international money transfer app. Your project is to make sure that the database of the app is highly available on multiple regions.\xa0 \xa0</p><p>What are the benefits of adding Multi-AZ deployments in Amazon RDS? (Choose 2)\xa0 </p>'}, 'related_lectures': [], 'correct_response': ['a', 'd'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as a Senior Infrastructure Consultant for a financial services startup, which has recently migrated its applications and websites to AWS. The company is experiencing some budget constraints, and the owner wants you to use AWS Trusted Advisor to identify all of the unused and idle AWS resources that can be eliminated.\xa0 \xa0Which of the following is included in the five categories that AWS Trusted Advisor analyzes in your AWS environment?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181108, 'original_assessment_id': 2567434, 'section': 'Trusted Advisor', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['CPU Optimization', 'Scaling Limits', 'Stability', '<p>Cost Optimization</p>', 'Security Limits', 'All of the above.'], 'explanation': '<p>Remember that the AWS Trusted Advisor analyzes your AWS environment and provides best practice recommendations in these five categories: <strong>C</strong>ost Optimization, <strong>P</strong>erformance, <strong>F</strong>ault Tolerance, <strong>S</strong>ecurity and <strong>S</strong>ervice Limits. You can use a mnemonic, such as CPFSS, to memorize these five categories.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/premiumsupport/trustedadvisor/">https://aws.amazon.com/premiumsupport/trustedadvisor/</a></p><p>&nbsp;</p>', 'question': '<p>You are working as a Senior Infrastructure Consultant for a financial services startup, which has recently migrated its applications and websites to AWS. The company is experiencing some budget constraints, and the owner wants you to use AWS Trusted Advisor to identify all of the unused and idle AWS resources that can be eliminated.\xa0 \xa0</p><p>Which of the following is included in the five categories that AWS Trusted Advisor analyzes in your AWS environment?\xa0 \xa0</p>'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have created a VPC with a single subnet then you launched an On-Demand EC2 instance in that subnet. You have attached Internet gateway (IGW) to the VPC and verified that the EC2 instance has a public IP. The main route table of the VPC is as shown below:However, the instance still cannot be reached from the Internet when you tried to connect to it from your computer. Which of the following should be made to the route table to fix this issue?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181110, 'original_assessment_id': 2567436, 'section': 'VPC', 'prompt': {'explanation': '<p>Apparently, the route table does not have an entry for the Internet Gateway. This is why you cannot connect to the EC2 instance. To fix this, you have to add a route with a destination of&nbsp;<code>0.0.0.0/0</code>&nbsp;for IPv4 traffic or&nbsp;<code class="code">::/0</code>&nbsp;for IPv6 traffic, and then a target of the Internet gateway ID (<code class="code">igw-xxxxxxxx</code>).</p><p>This should be the correct route table configuration after adding the new entry.</p><p><img src="https://udemy-images.s3.amazonaws.com/redactor/raw/2018-01-29_10-12-42-b725ca3ed0b358d7a00e8b0fd1c1bc51.png" width="693" height="342" /></p><br /><p>References:</p><p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Route_Tables.html">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Route_Tables.htm</a><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Route_Tables.html" target="_blank" rel="noopener">l</a></p>', 'answers': ['Add this new entry to the route table: 0.0.0.0/27 -> Your Internet Gateway', 'Modify the above route table: 10.0.0.0/27 -> Your Internet Gateway', ' Add the following entry to the route table: 10.0.0.0/27 -> Your Internet Gateway', 'Add a new entry to the route table - 0.0.0.0/27 -> Internet Gateway', 'Add this new entry to the route table: 0.0.0.0/0 -> Your Internet Gateway'], 'question': 'You have created a VPC with a single subnet then you launched an On-Demand EC2 instance in that subnet. You have attached Internet gateway (IGW) to the VPC and verified that the EC2 instance has a public IP. The main route table of the VPC is as shown below:<br /><br /><img src="https://udemy-images.s3.amazonaws.com/redactor/raw/2018-01-29_09-51-47-e9ccf269ea2ff9fafe4a307c1257507d.png" alt="" width="700" height="400" /><br /><br />However, the instance still cannot be reached from the Internet when you tried to connect to it from your computer. Which of the following should be made to the route table to fix this issue?'}, 'related_lectures': [], 'correct_response': ['e'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'The company that you are working for had instructed you to create a cost-effective cloud solution for their online movie ticketing service. Your team had designed a solution of using a fleet of Spot EC2 instances to host the new ticketing web application. You received a Spot Instance at a bid of $0.06/hr. After 45 minutes, the Spot price increases to $0.08/hr and then your instance is terminated by AWS. What was the total EC2 compute cost of running your Spot Instances?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181112, 'original_assessment_id': 2567438, 'section': 'Billing and Cost Management', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['$0.00', '$0.06', '$0.08', '$0.07'], 'explanation': '<p>In this scenario, you don\'t need to pay at all hence, option 1 is correct.</p><p>If your Spot instance is terminated or stopped by Amazon EC2 in the first instance hour, <span style="text-decoration: underline;">you will not be charged for that usage</span>. However, if you terminate the instance yourself, you will be charged to the nearest second.</p><p>If the Spot instance is terminated or stopped by Amazon EC2 in any subsequent hour, you will be charged for your usage to the nearest second. If you are running on Windows and you terminate the instance yourself, you will be charged for an entire hour.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/ec2/faqs/">https://aws.amazon.com/ec2/faqs/</a></p>', 'question': 'The company that you are working for had instructed you to create a cost-effective cloud solution for their online movie ticketing service. Your team had designed a solution of using a fleet of Spot EC2 instances to host the new ticketing web application. You received a Spot Instance at a bid of $0.06/hr. After 45 minutes, the Spot price increases to $0.08/hr and then your instance is terminated by AWS. What was the total EC2 compute cost of running your Spot Instances?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as a Solutions Architect for a leading energy company which has an on-premise application that uses a message-oriented middleware product. There is a requirement to migrate this application to AWS and in order to do this, you recommended to use Amazon SQS as the message queuing service for their decoupled application architecture. In this scenario, what is the main function of an SQS message?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181114, 'original_assessment_id': 2567440, 'section': 'SQS', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['A sequential message mainly used for push-mobile notification', 'A set of instructions stored in an SQS queue that can be up to 512KB in size', 'A notification sent via SNS', 'A set of instructions stored in an SQS queue that can be up to 256KB in size'], 'explanation': '<p>Amazon SQS messages are items in the SQS queue that can contain up to 256 KB of text data, including XML, JSON and unformatted text. </p> <p>Amazon SQS provides several advantages over building your own software for managing message queues or using commercial or open-source message queuing systems that require significant up-front time for development and configuration.</p> <p>Amazon SQS requires no administrative overhead and little configuration that works on a massive scale, processing billions of messages per day. You can scale the amount of traffic you send to Amazon SQS up or down without any configuration. Amazon SQS also provides extremely high message durability, giving you and your stakeholders added confidence.</p> <p><strong>References:</strong></p> <p><a href="https://aws.amazon.com/sqs/faqs/">https://aws.amazon.com/sqs/faqs/</a></p> <p><a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-limits.html">https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-limits.html</a></p>', 'question': '<p>You are working as a Solutions Architect for a leading energy company which has an on-premise application that uses a message-oriented middleware product. There is a requirement to migrate this application to AWS and in order to do this, you recommended to use Amazon SQS as the message queuing service for their decoupled application architecture. In this scenario, what is the main function of an SQS message?\xa0 </p>'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Your company would like to store their old yet confidential corporate files that are infrequently accessed. What cost-efficient solution in AWS should you recommend?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181116, 'original_assessment_id': 2567442, 'section': 'Glacier', 'prompt': {'explanation': '<p>Amazon Glacier is a secure, durable, and extremely low-cost cloud storage service for data archiving and long-term backup. It is designed to deliver 99.999999999% durability, and provides comprehensive security and compliance capabilities that can help meet even the most stringent regulatory requirements. Amazon Glacier provides query-in-place functionality, allowing you to run powerful analytics directly on your archive data at rest.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/glacier/faqs/">https://aws.amazon.com/glacier/faqs/</a></p><p>&nbsp;</p>', 'answers': ['Amazon Storage Gateway', 'Amazon Glacier', 'Amazon EBS', 'Amazon S3'], 'question': 'Your company would like to store their old yet confidential corporate files that are infrequently accessed. What cost-efficient solution in AWS should you recommend?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are planning to launch an application that tracks the GPS coordinates of delivery trucks in your country. The coordinates are transmitted from each delivery truck every five seconds. You need to design an architecture that will enable real-time processing of these coordinates from multiple consumers. The aggregated data will be analyzed in a separate reporting application.Which AWS service should you use for this scenario?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181118, 'original_assessment_id': 2567444, 'section': 'Kinesis', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>Amazon Kinesis makes it easy to collect, process, and analyze real-time, streaming data so you can get timely insights and react quickly to new information. It offers key capabilities to cost-effectively process streaming data at any scale, along with the flexibility to choose the tools that best suit the requirements of your application.</p> <p>With Amazon Kinesis, you can ingest real-time data such as video, audio, application logs, website clickstreams, and IoT telemetry data for machine learning, analytics, and other applications. Amazon Kinesis enables you to process and analyze data as it arrives and responds instantly instead of having to wait until all your data are collected before the processing can begin.</p> <p><strong>Reference:&nbsp;</strong></p> <p><a href="https://aws.amazon.com/kinesis/">https://aws.amazon.com/kinesis/</a></p> <p>&nbsp;</p>', 'feedbacks': ['', '', '', ''], 'answers': ['Amazon Kinesis', 'AWS Data Pipeline', 'Amazon AppStream', 'Amazon Simple Queue Service'], 'question': 'You are planning to launch an application that tracks the GPS coordinates of delivery trucks in your country. The coordinates are transmitted from each delivery truck every five seconds. You need to design an architecture that will enable real-time processing of these coordinates from multiple consumers. The aggregated data will be analyzed in a separate reporting application.<br><br>Which AWS service should you use for this scenario?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T08:13:18Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as an AWS Engineer in a major telecommunications company in which you are tasked to make a network monitoring system. You launched an EC2 instance to host the monitoring system and used CloudWatch to monitor, store, and access the log files of your instance.\xa0 \xa0Which of the following provides an automated way to send log data to CloudWatch Logs from your Amazon EC2 instance?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181106, 'original_assessment_id': 2567432, 'section': 'CloudWatch', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['<p>CloudWatch Logs agent </p>', '<p>CloudTrail\xa0 </p>', '<p>VPC Flow Logs\xa0 </p>', '<p>CloudTrail Logs agent\xa0 </p>'], 'explanation': '<p>CloudWatch Logs agent provides an automated way to send log data to CloudWatch Logs from Amazon EC2 instances hence, Option 1 is the correct answer. </p> <p>The CloudWatch Logs agent is comprised of the following components:</p> <ul> <li>A plug-in to the AWS CLI that pushes log data to CloudWatch Logs.</li> <li>A script (daemon) that initiates the process to push data to CloudWatch Logs.</li> <li>A cron job that ensures that the daemon is always running.</li> </ul> <p>Option 2 is incorrect as CloudTrail is mainly used for tracking the API calls of your AWS resources and not for sending EC2 logs to CloudWatch.</p> <p>Option 3 is incorrect as VPC Flow logs is mainly used for tracking the traffic coming into the VPC and not for EC2 instance monitoring.</p> <p>Option 4 is incorrect because CloudTrail Logs agent does not exist.</p> <p><strong>Reference: </strong></p> <p><a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AgentReference.html">https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AgentReference.html</a></p>', 'question': '<p>You are working as an AWS Engineer in a major telecommunications company in which you are tasked to make a network monitoring system. You launched an EC2 instance to host the monitoring system and used CloudWatch to monitor, store, and access the log files of your instance.\xa0 \xa0</p><p>Which of the following provides an automated way to send log data to CloudWatch Logs from your Amazon EC2 instance?\xa0 </p>'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have a new web application that hosts videos to an on-premise server and needs a new storage service to store the generated thumbnail photos. These thumbnails are shown in the website and are easily reproducible using the original video. In the coming months, you are expecting traffic growth to your website and your IT Manager wants to ensure your storage costs are minimized.Which type of cost-effective storage service should you use for storing the thumbnails?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181120, 'original_assessment_id': 2567446, 'section': 'S3', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['Amazon S3 - Infrequently Accessed Storage.', 'Amazon S3 - Reduced Redundancy Storage (RRS).', 'Amazon Glacier', 'Amazon S3 - Standard'], 'explanation': '<p>The keyword in the question is that the thumbnails to be stored are easily&nbsp;<strong>reproducible</strong>. This means that in this case, durability is not a top priority as the data stored can be generated again. Hence, the best option here is the Reduced Redundancy Storage (RRS).</p> <p>Reduced Redundancy Storage (RRS) is an Amazon S3 storage option that enables customers to store noncritical, reproducible data at lower levels of redundancy than Amazon S3&rsquo;s standard storage. It provides a highly available solution for distributing or sharing content that is durably stored elsewhere, or for storing thumbnails, transcoded media, or other processed data that can be easily reproduced. The RRS option stores objects on multiple devices across multiple facilities, providing 400 times the durability of a typical disk drive, but does not replicate objects as many times as standard Amazon S3 storage.</p> <ul> <li>Option 1 is incorrect - although the Infrequently Accessed Storage is low cost, it is mainly used for long-term storage, backups, and as a data store for disaster recovery.</li><br /> <li>Option 3 is incorrect - Amazon Glacier is mainly used for data archives.</li><br /> <li>Option 4 is incorrect - although the Standard option can be used for this scenario, it is not cost-effective given that the data being stored does not require high durability.</li> </ul> <p>&nbsp;</p> </div> <p>References:</p> <p><a href="https://aws.amazon.com/s3/reduced-redundancy/" target="_blank" rel="noopener">https://aws.amazon.com/s3/reduced-redundancy/</a></p>', 'question': '<p>You have a new web application that hosts videos to an on-premise server and needs a new storage service to store the generated thumbnail photos. These thumbnails are shown in the website and are easily reproducible using the original video. In the coming months, you are expecting traffic growth to your website and your IT Manager wants to ensure your storage costs are minimized.<br><br>Which type of cost-effective storage service should you use for storing the thumbnails?</p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'An online shopping platform has been deployed to AWS using Elastic Beanstalk. They simply uploaded their Node.js application, and Elastic Beanstalk automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring. Since the entire deployment process is automated, the DevOps team is not sure where to get the application log files of their shopping platform.\xa0 In Elastic Beanstalk, where does it store the application files and server log files?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181122, 'original_assessment_id': 2567448, 'section': 'Elastic Beanstalk', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Amazon Redshift', 'AWS S3', 'AWS Cloudtrail', 'AWS DynamoDB', 'Amazon RDS', '<p>In the instance store of the underlying EC2 instance</p>'], 'explanation': '<p>AWS Elastic Beanstalk stores your application files and optionally, server log files in Amazon S3. If you are using the AWS Management Console, the AWS Toolkit for Visual Studio, or AWS Toolkit for Eclipse, an Amazon S3 bucket will be created in your account and the files you upload will be automatically copied from your local client to Amazon S3. Optionally, you may configure Elastic Beanstalk to copy your server log files every hour to Amazon S3. You do this by editing the environment configuration settings.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/elasticbeanstalk/faqs/">https://aws.amazon.com/elasticbeanstalk/faqs/</a></p><p>&nbsp;</p>', 'question': '<p>An online shopping platform has been deployed to AWS using Elastic Beanstalk. They simply uploaded their Node.js application, and Elastic Beanstalk automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring. Since the entire deployment process is automated, the DevOps team is not sure where to get the application log files of their shopping platform.\xa0 </p><p>In Elastic Beanstalk, where does it store the application files and server log files?</p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are working as a Solutions Architect in a global investment bank which requires corporate IT governance and cost oversight of all of their AWS resources across their divisions around the world. Their corporate divisions want to maintain administrative control of the discrete AWS resources they consume and ensure that those resources are separate from other divisions. Which of the following options will support the autonomy of each corporate divisions while enabling the corporate IT to maintain governance and cost oversight? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181126, 'original_assessment_id': 2567452, 'section': 'Billing and Cost Management', 'prompt': {'explanation': '<p>In this scenario, the combined use of IAM and Consolidated Billing will support the autonomy of each corporate division while enabling the corporate IT to maintain governance and cost oversight.&nbsp;</p><p>You can use an IAM role to delegate access to resources that are in different AWS accounts that you own. You share resources in one account with users in a different account. By setting up cross-account access in this way, you don\'t need to create individual IAM users in each account. In addition, users don\'t have to sign out of one account and sign into another in order to access resources that are in different AWS accounts.&nbsp;</p><p>You can use the consolidated billing feature in AWS Organizations to consolidate payment for multiple AWS accounts or multiple AISPL accounts. With consolidated billing, you can see a combined view of AWS charges incurred by all of your accounts. You also can get a cost report for each member account that is associated with your master account. Consolidated billing is offered at no additional charge. AWS and AISPL accounts can\'t be consolidated together.</p><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/consolidated-billing.html">http://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/consolidated-billing.html</a></p><p><a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html">https://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html</a></p>', 'answers': ['Use AWS Trusted Advisor', 'Enable IAM cross-account access for all corporate IT administrators in each child account.', 'Create separate VPCs for each division within the corporate IT AWS account.', 'Use AWS Consolidated Billing by creating AWS Organizations to link the divisions’ accounts to a parent corporate account.', 'Create separate Availability Zones for each division within the corporate IT AWS account.'], 'question': 'You are working as a Solutions Architect in a global investment bank which requires corporate IT governance and cost oversight of all of their AWS resources across their divisions around the world. Their corporate divisions want to maintain administrative control of the discrete AWS resources they consume and ensure that those resources are separate from other divisions. <br /><br />Which of the following options will support the autonomy of each corporate divisions while enabling the corporate IT to maintain governance and cost oversight? (Choose 2)'}, 'related_lectures': [], 'correct_response': ['b', 'd'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Is the data stored in Amazon Simple Storage Service encrypted by default?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181128, 'original_assessment_id': 2567454, 'section': 'S3', 'prompt': {'explanation': '<div><p>Data in Amazon S3 is not encrypted by default. Hence, Options 1, 2, and 3 are incorrect.</p><p>Option 4 is incorrect as although Amazon S3 is secure by default, which means that only the bucket and object owners originally have access to Amazon S3 resources they create, the data itself is not encrypted. Remember, being \'secure\' and \'encrypted\' are two different things.&nbsp;</p><p>Amazon S3 supports user authentication to control access to data. You can use access control mechanisms such as bucket policies and Access Control Lists (ACLs) to selectively grant permissions to users and groups of users. Amazon S3 console highlights your publicly accessible buckets, indicates the source of public accessibility, and also warns you if changes to your bucket policies or bucket ACLs would make your bucket publicly accessible.</p><p>You can securely upload/download your data to Amazon S3 via SSL endpoints using the HTTPS protocol. If you need extra security, you can use the Server Side Encryption (SSE) option to encrypt data stored at rest. You can configure your Amazon S3 buckets to automatically encrypt objects before storing them if the incoming storage requests do not have any encryption information. Alternatively you can use your own encryption libraries to encrypt data before storing it in Amazon S3.</p></div><div>&nbsp;</div><p>Resources:</p><p><a href="https://aws.amazon.com/s3/faqs/">https://aws.amazon.com/s3/faqs/</a></p>', 'answers': ['Yes, S3 is encrypted by default with Server-Side Encryption with Customer-Provided Keys (SSE-C) ', 'Yes, S3 is encrypted by default with Server-Side Encryption with AWS KMS-Managed Keys (SSE-KMS)', 'Yes, S3 is encrypted by default with Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3)', 'Amazon S3 is secure by default. Only the bucket and object owners originally have access to Amazon S3 resources they create.', 'No, it is not encrypted by default'], 'question': 'Is the data stored in Amazon Simple Storage Service encrypted by default?'}, 'related_lectures': [], 'correct_response': ['e'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Which type of networking connection in AWS allows you to connect two Virtual Private Cloud networks?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181134, 'original_assessment_id': 2567460, 'section': 'VPC', 'prompt': {'explanation': '<p>A VPC peering connection is a networking connection between two VPCs that enables you to route traffic between them privately. Instances in either VPC can communicate with each other as if they are within the same network. You can create a VPC peering connection between your own VPCs, with a VPC in another AWS account, or with a VPC in a different AWS Region.</p><p>AWS uses the existing infrastructure of a VPC to create a VPC peering connection; it is neither a gateway nor a VPN connection, and does not rely on a separate piece of physical hardware. There is no single point of failure for communication or a bandwidth bottleneck.</p><p>&nbsp;</p><p>References:</p><p><a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-peering.html">https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-peering.html</a></p><p>&nbsp;</p>', 'answers': ['VPC Connection', 'VPN Connection', 'Direct Connect', 'VPC Peering'], 'question': 'Which type of networking connection in AWS allows you to connect two Virtual Private Cloud networks?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A top university has recently launched its online learning portal where the students can take e-learning courses from the comforts of their homes. The portal is on a large On-Demand EC2 instance with a single Amazon Aurora database.\xa0 \xa0How can you improve the availability of your Aurora database to prevent any unnecessary downtime of the online portal?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181176, 'original_assessment_id': 4505304, 'section': 'Aurora', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>Amazon Aurora MySQL and Amazon Aurora PostgreSQL support Amazon Aurora Replicas, which share the same underlying volume as the primary instance. Updates made by the primary are visible to all Amazon Aurora Replicas. With Amazon Aurora MySQL, you can also create MySQL Read Replicas based on MySQL&rsquo;s binlog-based replication engine. In MySQL Read Replicas, data from your primary instance is replayed on your replica as transactions. For most use cases, including read scaling and high availability, we recommend using Amazon Aurora Replicas.</p> <p>Hence, the right answer here is Option 1.</p> <p>Option 2 is incorrect because Aurora is a database engine for RDS and not deployed on a typical EC2 instance.</p> <p>Option 3 is incorrect because Hash Joins are mainly used if you need to join a large amount of data by using an equijoin and not for improving availability.</p> <p>Option 4 is incorrect because the Asynchronous Key Prefetch is mainly used to improve the performance of queries that join tables across indexes.</p> <p><strong>References: </strong></p> <p><a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/AuroraMySQL.BestPractices.html ">https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/AuroraMySQL.BestPractices.html </a></p> <p><a href="https://aws.amazon.com/rds/aurora/faqs/">https://aws.amazon.com/rds/aurora/faqs/</a></p>', 'feedbacks': ['', '', '', ''], 'answers': ['<p>Create Amazon Aurora Replicas.</p>', '<p>Deploy Aurora to two Auto-Scaling groups of EC2 instances across two Availability Zones with an elastic load balancer which handles load balancing.</p>', '<p>Enable Hash Joins to improve the database query performance.</p>', '<p>Use an Asynchronous Key Prefetch in Amazon Aurora to improve the performance of queries that join tables across indexes.</p>'], 'question': '<p>A top university has recently launched its online learning portal where the students can take e-learning courses from the comforts of their homes. The portal is on a large On-Demand EC2 instance with a single Amazon Aurora database.\xa0 \xa0</p><p>How can you improve the availability of your Aurora database to prevent any unnecessary downtime of the online portal?</p>'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T08:15:00Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Your company is launching a new web portal for its clients. It needs to be launched to a new VPC and will be composed of web servers that will host the UI app and the REST API services, including two database servers. The web portal will be accessed by the clients through the Internet.In this scenario, which of the VPC configuration wizard options would you use?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181136, 'original_assessment_id': 2567462, 'section': 'VPC', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', ''], 'answers': ['VPC with a Single Public Subnet Only', 'VPC with Public and Private Subnets', 'VPC with Public and Private Subnets and Hardware VPN Access', 'VPC with a Private Subnet Only and Hardware VPN Access', 'Default VPC'], 'explanation': '<p>Since the web portal consists of both web and database servers, it is best to launch the web servers into the public subnet and the database server into the private subnet. Hence, Option 2 is the right answer.</p><p>Although you can use a single public subnet for your web and database servers, it will be a massive security risk as you are exposing your database publicly to the Internet.</p><br /><p>References:<a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Route_Tables.html" target="_blank" rel="noopener"><br /></a><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario2.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario2.html</a>&nbsp;</p>', 'question': 'Your company is launching a new web portal for its clients. It needs to be launched to a new VPC and will be composed of web servers that will host the UI app and the REST API services, including two database servers. The web portal will be accessed by the clients through the Internet.<br><br>In this scenario, which of the VPC configuration wizard options would you use?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You deployed a web application to an EC2 instance that adds a variety of photo effects to a picture uploaded by the users. The application will put the generated photos to an S3 bucket by sending PUT requests to the S3 API.\xa0 \xa0What is the best option for this scenario considering that you need to have API credentials to be able to send a request to the S3 API?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181138, 'original_assessment_id': 2567464, 'section': 'EC2', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['Encrypt the API credentials and store in any directory of the EC2 instance.', 'Create a role in IAM. Afterwards, assign this role to a new EC2 instance.', 'Store your API credentials in Amazon Glacier.', 'Store the API credentials in the root web application directory of the EC2 instance.'], 'explanation': '<p>The best option is to create a role in IAM. Afterwards, assign this role to a new EC2 instance.&nbsp;Applications must sign their API requests with AWS credentials. Therefore, if you are an application developer, you need a strategy for managing credentials for your applications that run on EC2 instances.</p><p>You can securely distribute your AWS credentials to the instances, enabling the applications on those instances to use your credentials to sign requests while protecting your credentials from other users. However, it\'s challenging to securely distribute credentials to each instance, especially those that AWS creates on your behalf such as Spot Instances or instances in Auto Scaling groups. You must also be able to update the credentials on each instance when you rotate your AWS credentials.</p><p>In this scenario, you have to use IAM roles so that your applications can securely make API requests from your instances without requiring you to manage the security credentials that the applications use. Instead of creating and distributing your AWS credentials, you can delegate permission to make API requests using IAM roles.</p><ul><li>Options 1 and 4 are incorrect. Though you can store and use the API credentials in the EC2 instance, it will be difficult to manage just as mentioned above. You have to use IAM Roles.</li><br /><li>Option 3 is incorrect as Amazon Glacier is used for data archives and not for managing API credentials.</li></ul><br /><p>References:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html</a></p>', 'question': '<p>You deployed a web application to an EC2 instance that adds a variety of photo effects to a picture uploaded by the users. The application will put the generated photos to an S3 bucket by sending PUT requests to the S3 API.\xa0 \xa0</p><p>What is the best option for this scenario considering that you need to have API credentials to be able to send a request to the S3 API?</p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T08:14:13Z'}, {'assessment_type': 'multi-select', 'question_plain': 'As a Senior Cloud Security Consultant in a securities &amp; investment firm covering forex trading applications, one of your responsibilities is to manage AWS user identities and their varying levels of access to AWS resources. In IAM, AWS users can be created and assigned individual security credentials (e.g. passphrases, SSH keys, MFA), granted permission to access AWS, or removed at any time. What are the different types of IAM identities? (Choose 3)', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181132, 'original_assessment_id': 2567458, 'section': 'IAM', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['Roles', 'Users', 'EC2 Instances', 'Groups', 'Security Groups', 'Accounts'], 'explanation': '<p>There are 3 IAM identities: Users, Groups, and Roles.</p><ul><li>An IAM user is an entity that you create in AWS. The IAM user represents the person or service that uses the IAM user to interact with AWS. A primary use for IAM users is to give people the ability to sign in to the AWS Management Console for interactive tasks and to make programmatic requests to AWS services using the API or CLI.&nbsp;</li><br /><li>An IAM group is a collection of IAM users. You can use groups to specify permissions for a collection of users, which can make these permissions easier to manage for the users. For example, you could have a group called&nbsp;<em>Admins</em>&nbsp;and give that group the types of permissions that administrators typically need.&nbsp;</li><br /><li>An IAM role is very similar to a user in that it is an identity with permission policies that determine what the identity can and cannot do in AWS. However, a role does not have any credentials (password or access keys) associated with it.&nbsp;</li></ul><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id.html">http://docs.aws.amazon.com/IAM/latest/UserGuide/id.html</a></p><p>&nbsp;</p>', 'question': '<p>As a Senior Cloud Security Consultant in a securities &amp; investment firm covering forex trading applications, one of your responsibilities is to manage AWS user identities and their varying levels of access to AWS resources. In IAM, AWS users can be created and assigned individual security credentials (e.g. passphrases, SSH keys, MFA), granted permission to access AWS, or removed at any time. What are the different types of IAM identities? (Choose 3)\xa0 </p>'}, 'related_lectures': [], 'correct_response': ['a', 'b', 'd'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You have several EC2 Reserved Instances in your account that needs to be decommissioned and shut down since they are no longer required. The data is still required by the Audit team. Which of the following steps can be taken for this scenario? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181140, 'original_assessment_id': 2567466, 'section': 'EC2', 'prompt': {'explanation': '<p>You can create a snapshot of the instance to save its data and then sell the instance to the&nbsp;Reserved Instance Marketplace.</p><p>The Reserved Instance Marketplace is a platform that supports the sale of third-party and AWS customers\' unused Standard Reserved Instances, which vary in terms of length and pricing options. For example, you may want to sell Reserved Instances after moving instances to a new AWS region, changing to a new instance type, ending projects before the term expiration, when your business needs change, or if you have unneeded capacity.</p><br /><p>References:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ri-market-general.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ri-market-general.html</a></p>', 'answers': ['Convert the EC2 instance to On-Demand instances', 'You can opt to sell these EC2 instances on the AWS Reserved Instance Marketplace', 'Take snapshots of the EBS volumes and terminate the EC2 instances.', 'Convert the EC2 instances to Spot instances'], 'question': 'You have several EC2 Reserved Instances in your account that needs to be decommissioned and shut down since they are no longer required. The data is still required by the Audit team. <br /><br />Which of the following steps can be taken for this scenario? (Choose 2)'}, 'related_lectures': [], 'correct_response': ['b', 'c'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Your IT Manager asks you to create a decoupled application whose process includes dependencies on EC2 instances and servers located in your company’s on-premises data center. Which of these options are you least likely to recommend as part of that process?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181142, 'original_assessment_id': 2567470, 'section': 'IAM', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['SQS polling from an EC2 instance deployed with an IAM role', 'An SWF workflow', 'SQS polling from an EC2 instance using IAM user credentials', '<p>Establish a Direct Connect connection from your on-premises network and VPC</p>'], 'explanation': '<p>For decoupled applications, it is best to use SWF and SQS which are both available in all options. Note that this question asks you for the option that you are&nbsp;<strong>LEAST</strong> likely to recommend.</p> <p>If you notice the 3rd option, it uses IAM user credentials for the EC2 instances which is not the recommended way to do so. It should use an IAM role instead. Hence, the correct answer is option 3.</p> <p>The Options 1, 2, and 4 are the recommended steps to satisfy the given requirement. You have to establish first a Direct Connect connection from your data center to your VPC to allow the on-premise servers to connect to SQS. You can either use SWF or SQS to create a decoupled application and you have to use an IAM Role, not an IAM&nbsp;user credential, on the EC2 instance to allow polling to the SQS queue.</p> <p>&nbsp;</p> <p><strong>Reference:</strong></p> <p><a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html">http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html</a></p>', 'question': 'Your IT Manager asks you to create a decoupled application whose process includes dependencies on EC2 instances and servers located in your company’s on-premises data center. <br><br>Which of these options are you least likely to recommend as part of that process?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'All Amazon EC2 instances are assigned 2 IP addresses at launch. Which of these two addresses can only be reached from within the Amazon EC2 network?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181144, 'original_assessment_id': 2567472, 'section': 'EC2', 'prompt': {'explanation': '<p>A private IPv4 address is an IP address that\'s not reachable over the Internet. You can use private IPv4 addresses for communication between instances in the same VPC network.</p><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-instance-addressing.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-instance-addressing.html</a></p><p>&nbsp;</p>', 'answers': ['Multiple IP address', 'Public IP address', 'Private IP address', 'Elastic IP Address'], 'question': 'All Amazon EC2 instances are assigned 2 IP addresses at launch. Which of these two addresses can only be reached from within the Amazon EC2 network?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A large Philippine-based Business Process Outsourcing company is building a two-tier web application in their VPC to serve dynamic transaction-based content. The data tier is leveraging an Online Transactional Processing (OLTP) database but for the web tier, they are still deciding what service they will use. What AWS services should you leverage to build an elastic and scalable web tier?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181146, 'original_assessment_id': 2567474, 'section': 'Highly Available Network Design', 'prompt': {'explanation': '<p>Amazon RDS is a great database service to use for online transaction processing (OLTP) applications. However, the question says that it needs a list of AWS services for the web tier and not the database tier. As such, options 2, 3 and 4 are invalid as these options contain RDS and DynamoDB.</p><p>To build an elastic and a highly-available web tier, you can use Amazon EC2, Auto Scaling, and Elastic Load Balancing. You can deploy your web servers to a fleet of EC2 instances to an Auto Scaling group, which will automatically monitor&nbsp;your applications and automatically adjust capacity to maintain steady, predictable performance at the lowest possible cost. Load balancing is an effective way to increase the availability of a system. Instances that fail can be replaced seamlessly behind the load balancer while other instances continue to operate. Elastic Load Balancing can be used to balance across instances in multiple availability zones of a region.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://media.amazonwebservices.com/architecturecenter/AWS_ac_ra_ftha_04.pdf">https://media.amazonwebservices.com/architecturecenter/AWS_ac_ra_ftha_04.pdf</a></p><p>&nbsp;</p>', 'answers': ['Elastic Load Balancing, Amazon EC2, and Auto Scaling', 'Elastic Load Balancing, Amazon RDS with Multi-AZ, and Amazon S3', 'Amazon RDS with Multi-AZ and Auto Scaling', 'Amazon EC2, Amazon DynamoDB, and Amazon S3'], 'question': 'A large Philippine-based Business Process Outsourcing company is building a two-tier web application in their VPC to serve dynamic transaction-based content. The data tier is leveraging an Online Transactional Processing (OLTP) database but for the web tier, they are still deciding what service they will use. <br /><br />What AWS services should you leverage to build an elastic and scalable web tier?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multi-select', 'question_plain': 'You are a Solutions Architect in an intelligence agency that is currently hosting a learning and training portal in AWS. Your manager instructed you to launch a large EC2 instance with an attached EBS Volume and enable Enhanced Networking. What are the valid case scenarios in using Enhanced Networking? (Choose 2)', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181124, 'original_assessment_id': 2567450, 'section': 'EC2', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', '', '', ''], 'answers': ['When you need a higher packet per second (PPS) performance', 'When you need a low packet-per-second performance', 'When you need high latency networking', 'When you need a consistently lower inter-instance latencies', '<p>When you need a dedicated connection to your on-premise data center\xa0 </p>', '<p>When you need consistently higher inter-instance latencies </p>'], 'explanation': '<p>Enhanced networking uses single root I/O virtualization (SR-IOV) to provide high-performance networking capabilities on supported instance types. SR-IOV is a method of device virtualization that provides higher I/O performance and lower CPU utilization when compared to traditional virtualized network interfaces. Enhanced networking provides higher bandwidth, higher packet per second (PPS) performance and consistently lower inter-instance latencies. There is no additional charge for using enhanced networking.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/enhanced-networking.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/enhanced-networking.html</a></p><p>&nbsp;</p>', 'question': '<p>You are a Solutions Architect in an intelligence agency that is currently hosting a learning and training portal in AWS. Your manager instructed you to launch a large EC2 instance with an attached EBS Volume and enable Enhanced Networking. What are the valid case scenarios in using Enhanced Networking? (Choose 2)\xa0 </p>'}, 'related_lectures': [], 'correct_response': ['a', 'd'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You have designed and built a new AWS architecture. After deploying your application to an On-demand EC2 instance, you found that there is an issue in your application when connecting to port 443. After troubleshooting the issue, you added port 443 to the security group of the instance.How long will it take before the changes are applied to all of the resources in your VPC?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181148, 'original_assessment_id': 2567476, 'section': 'VPC', 'prompt': {'explanation': '<p>A&nbsp;<em>security group</em>&nbsp;acts as a virtual firewall for your instance to control inbound and outbound traffic. When you launch an instance in a VPC, you can assign up to five security groups to the instance. Security groups act at the instance level, not the subnet level. Therefore, each instance in a subnet in your VPC could be assigned to a different set of security groups. If you don\'t specify a particular group at launch time, the instance is automatically assigned to the default security group for the VPC.</p><p>Changes made in a Security Group is immediately implemented.&nbsp;</p><p>&nbsp;</p><p>References:</p><p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html</a></p>', 'answers': ['Roughly around 5-8 minutes in order for the security rules to propagate.', 'Immediately after a reboot of the EC2 instances which belong to that security group.', 'Immediately.', 'It takes exactly one minute for the rules to apply to all availability zones within the AWS region.'], 'question': 'You have designed and built a new AWS architecture. After deploying your application to an On-demand EC2 instance, you found that there is an issue in your application when connecting to port 443. After troubleshooting the issue, you added port 443 to the security group of the instance.<br /><br />How long will it take before the changes are applied to all of the resources in your VPC?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'What is the correct indication that an object was indeed successfully stored when you put objects in Amazon S3?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181150, 'original_assessment_id': 2567478, 'section': 'S3', 'prompt': {'explanation': '<p>If you triggered an S3 API call and got HTTP 200 result code and MD5 checksum, then it is considered as a successful upload. The S3 API will return an error code in case the upload is unsuccessful.</p><p>Option 2 is incorrect because although S3 is durable, it is not an assurance that all objects uploaded using S3 API calls will be successful.</p><p>Options 3 and 4 are incorrect because you don\'t receive an SMS nor an email notification by default, unless you added an event notification.</p><p>References:&nbsp;</p><p><a href="https://docs.aws.amazon.com/AmazonS3/latest/API/RESTObjectPOST.html">https://docs.aws.amazon.com/AmazonS3/latest/API/RESTObjectPOST.html</a></p>', 'answers': ['HTTP 200 result code and MD5 checksum.', 'Amazon S3 has 99.999999999% durability hence, there is no need to confirm that data was inserted.', 'You will receive an SMS from Amazon SNS informing you that the object is successfully stored.', 'You will receive an email from Amazon SNS informing you that the object is successfully stored.'], 'question': 'What is the correct indication that an object was indeed successfully stored when you put objects in Amazon S3?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'How do you move an EBS volume that is currently attached to a Spot EC2 instance from a specific Availability Zone to an EC2 instance located in a different Availability Zone?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181152, 'original_assessment_id': 2567480, 'section': 'EBS', 'prompt': {'explanation': '<p>The first step is to create a snapshot of the EBS volume. Create a volume using this snapshot and then specify the new Availability Zone accordingly.</p><p>&nbsp;</p><p>Resources:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html</a></p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-restoring-volume.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-restoring-volume.html</a></p><p>&nbsp;</p>', 'answers': ['Create a new EBS volume in another Availability Zone and then specify the current EBS volume as the source.', 'Detach the EBS volume and attach it to an EC2 instance residing in another Availability Zone.', 'First, create a snapshot of the EBS volume. Afterwards, create a volume using the snapshot in the other Availability Zone.', 'First, create a new volume in the other Availability Zone. Next, perform a disk copy of the contents from the source volume to the new volume that you have created.'], 'question': 'How do you move an EBS volume that is currently attached to a Spot EC2 instance from a specific Availability Zone to an EC2 instance located in a different Availability Zone?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'There is a technical requirement by a financial firm that does online credit card processing to have a secure application environment on AWS. They are trying to decide on whether to use KMS or CloudHSM. Which of the following statements is right when it comes to CloudHSM and KMS?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181154, 'original_assessment_id': 2567482, 'section': 'CloudHSM', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['No major difference. They both do the same thing.', 'AWS CloudHSM does not support the processing, storage, and transmission of credit card data by a merchant or service provider, as it has not been validated as being compliant with Payment Card Industry (PCI) Data Security Standard (DSS); hence, you will need to use KMS.', 'You should consider using AWS CloudHSM over AWS KMS if you require your keys stored in dedicated, third-party validated hardware security modules under your exclusive control.', 'AWS CloudHSM should always be used for any payment transactions.'], 'explanation': '<p>AWS Key Management Service (KMS) is a multi-tenant, managed service that allows you to use and manage encryption keys.&nbsp;AWS CloudHSM is a cloud-based hardware security module (HSM) that enables you to easily generate and use your own encryption keys on the AWS Cloud. Both services offer a high level of security for your cryptographic keys. AWS CloudHSM provides a dedicated, FIPS 140-2 Level 3 HSM under your exclusive control, directly in your Amazon Virtual Private Cloud (VPC).</p><p>You should consider using AWS CloudHSM over AWS KMS if you require:</p><ul><li>Keys stored in dedicated, third-party validated hardware security modules under your exclusive control.</li><li>FIPS 140-2 compliance.</li><li>Integration with applications using PKCS#11, Java JCE, or Microsoft CNG interfaces.</li><li>High-performance in-VPC cryptographic acceleration (bulk crypto).</li></ul><p>&nbsp;</p><p>Resources:</p><p><a href="https://aws.amazon.com/cloudhsm/faqs/">https://aws.amazon.com/cloudhsm/faqs/</a></p><p><a href="https://aws.amazon.com/cloudhsm/">https://aws.amazon.com/cloudhsm/</a></p><p><a href="https://aws.amazon.com/kms/">https://aws.amazon.com/kms/</a></p><p>&nbsp;</p>', 'question': 'There is a technical requirement by a financial firm that does online credit card processing to have a secure application environment on AWS. They are trying to decide on whether to use KMS or CloudHSM. <br><br>Which of the following statements is right when it comes to CloudHSM and KMS?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Which of the following must be done before your newly created IAM User can successfully make API calls to your AWS Services?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181160, 'original_assessment_id': 2567488, 'section': 'IAM', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['Add a new policy to the new user.', 'Enable Multi-Factor Authentication for the user.', 'Assign an API Policy to the user.', 'Create a set of Access Keys for the user.'], 'explanation': '<p>By default, a brand new IAM user has no password and no access key (neither an access key ID nor a secret access key)&mdash;no credentials of any kind. You must create the type of credentials for an IAM user based on what the user will be doing.</p> <p>Users need their own access keys to make programmatic calls to AWS from the AWS Command Line Interface (AWS CLI), Tools for Windows PowerShell, the AWS SDKs, or direct HTTP calls using the APIs for individual AWS services.</p> <p>To fill this need, you can create, modify, view, or rotate access keys (access key IDs and secret access keys) for IAM users. When you create an access key, IAM returns the access key ID and secret access key. You should save these in a secure location and give them to the user.</p> <p>&nbsp;</p> <p>References:</p> <p><a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html">https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html</a></p> <p><a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users.html">https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users.html</a></p> <p>&nbsp;</p>', 'question': 'Which of the following must be done before your newly created IAM User can successfully make API calls to your AWS Services?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'A tech company is running two production web servers hosted on Reserved EC2 instances with EBS-backed root volumes. These instances have a consistent CPU load of 90%. Traffic is being distributed to these instances by an Elastic Load Balancer. In addition, they also have Multi-AZ RDS MySQL databases for their production, test, and development environments.\xa0 What recommendation would you make to reduce cost in this AWS environment without affecting availability and performance of mission-critical systems? Choose the best answer.', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181162, 'original_assessment_id': 2567490, 'section': 'RDS', 'prompt': {'relatedLectureIds': '', 'explanation': '<p>One thing that you have to notice here is that the company is using Multi-AZ databases in all of their environments, including their development and test environment. This is costly and unnecessary as these two environments are not critical. It is better to use&nbsp;Multi-AZ for production environments to reduce costs.&nbsp;</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/rds/details/multi-az/">https://aws.amazon.com/rds/details/multi-az/</a><br /><br /></p>', 'feedbacks': ['', '', '', ''], 'answers': ['Consider using On-demand instances instead of Reserved EC2 instances', 'Consider not using a Multi-AZ RDS deployment for the development and test database', 'Consider using Spot instances instead of reserved EC2 instances', 'Consider removing the Elastic Load Balancer'], 'question': '<p>A tech company is running two production web servers hosted on Reserved EC2 instances with EBS-backed root volumes. These instances have a consistent CPU load of 90%. Traffic is being distributed to these instances by an Elastic Load Balancer. In addition, they also have Multi-AZ RDS MySQL databases for their production, test, and development environments.\xa0 </p><p>What recommendation would you make to reduce cost in this AWS environment without affecting availability and performance of mission-critical systems? Choose the best answer.</p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T08:16:05Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as a Solutions Architect in a well-funded financial startup. The CTO instructed you to launch a cryptocurrency mining server on a Reserved EC2 instance in us-east-1 region which is using IPv6. Due to the financial data the server contains, the system should be secured to avoid any unauthorized access and to meet the regulatory compliance requirements.\xa0 In this scenario, which VPC feature allows the EC2 instance to communicate to the Internet but prevents inbound traffic?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181164, 'original_assessment_id': 2567492, 'section': 'Networking', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['<p>NAT Gateway</p>', '<p>NAT instances</p>', '<p>Egress-only Internet gateway</p>', '<p>Internet Gateway</p>'], 'explanation': '<p>An egress-only Internet gateway is a horizontally scaled, redundant, and highly available VPC component that allows outbound communication over IPv6 from instances in your VPC to the Internet, and prevents the Internet from initiating an IPv6 connection with your instances.</p> <p>Take note that an egress-only Internet gateway is for use with IPv6 traffic only. To enable outbound-only Internet communication over IPv4, use a NAT gateway instead.</p> <p><strong>Reference: </strong></p> <p><a href="https://docs.aws.amazon.com/vpc/latest/userguide/egress-only-internet-gateway.html">https://docs.aws.amazon.com/vpc/latest/userguide/egress-only-internet-gateway.html</a></p>', 'question': '<p>You are working as a Solutions Architect in a well-funded financial startup. The CTO instructed you to launch a cryptocurrency mining server on a Reserved EC2 instance in us-east-1 region which is using IPv6. Due to the financial data the server contains, the system should be secured to avoid any unauthorized access and to meet the regulatory compliance requirements.\xa0 </p><p>In this scenario, which VPC feature allows the EC2 instance to communicate to the Internet but prevents inbound traffic?\xa0</p>'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'An AWS account has an ID of 0499802888. Which of the following URLs would you provide to the IAM user to be able to access the AWS Console?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181166, 'original_assessment_id': 2567494, 'section': 'IAM', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['https://0499802888.signin.aws.amazon.com/console', '<p>https://signin.0499802888.aws.amazon.com/console</p>', 'https://signin.aws.amazon.com/console', 'https://aws.amazon.com/console'], 'explanation': '<p>To use the AWS Management Console, IAM users must provide their account ID or account alias in addition to their username and password. When you, as an administrator, create an IAM user in the console, you must send the sign-in credentials to that user, including the username and the URL to the account sign-in page.</p><p>Your unique account sign-in page URL is created automatically when you begin using IAM. You do not have to do anything to use this sign-in page.&nbsp;You can also customize the account sign-in URL for your account if you want the URL to contain your company name (or other friendly identifier) instead of your AWS account ID number.&nbsp;</p><p>AWS sign-in page URL format:</p><p><code>https://<span style="color: #0000ff;"><strong><em><code>My_AWS_Account_ID</code></em></strong></span>.signin.aws.amazon.com/console/<code></code></code></p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/console.html">https://docs.aws.amazon.com/IAM/latest/UserGuide/console.html</a></p>', 'question': 'An AWS account has an ID of 0499802888. Which of the following URLs would you provide to the IAM user to be able to access the AWS Console?'}, 'related_lectures': [], 'correct_response': ['a'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'Your company has a new online banking portal which needs to have a user session management. Which of the following can be used for session management of your application?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181168, 'original_assessment_id': 2567496, 'section': 'Session Management', 'prompt': {'explanation': '<p>There are various ways to manage user sessions including storing those sessions locally to the node responding to the HTTP request or designating a layer in your architecture which can store those sessions in a scalable and robust manner. Common approaches used include utilizing Sticky sessions through the use of Elastic Load Balancer or using a Distributed Cache for your session management.</p><p>Elasticache, Amazon RDS, and DynamoDB are the available AWS services that can provide distributed cache session management.&nbsp;</p><ul><li>Option 1 is incorrect because Amazon Redshift is used primarily as a data warehouse. The Elastic Load Balancer (ELB) and RDS can provide session management. The ELB has a sticky session feature (also known as session affinity), which enables it to bind a user\'s session to a specific instance.&nbsp;A drawback for using storing sessions on an individual node is that in the event of a failure, you are likely to lose the sessions that were resident on the failed node. In addition, in the event that the number of your web servers change, for example a scale-up scenario, it&rsquo;s possible that the traffic may be unequally spread across the web servers as active sessions may exist on particular servers. If not mitigated properly, this can hinder the scalability of your applications.&nbsp;</li><li><br /><p>Option 2 is incorrect because the AWS Storage Gateway is primarily used for data storage and not for distributed session management.</p></li><li><p>Option 3 is incorrect because CloudWatch is used for monitoring AWS service.</p></li></ul><p>References:</p><p><a href="https://aws.amazon.com/caching/session-management/" target="_blank" rel="noopener">https://aws.amazon.com/caching/session-management/</a></p><p><a href="https://aws.amazon.com/caching/database-caching/" target="_blank" rel="noopener">https://aws.amazon.com/caching/database-caching/</a></p>', 'answers': ['Elastic Load Balancer, Elasticache, and Redshift', 'AWS Storage Gateway, Elasticache, and Elastic Load Balancer', 'CloudWatch, RDS, and DynamoDB', 'Elasticache, Amazon RDS, and DynamoDB'], 'question': 'Your company has a new online banking portal which needs to have a user session management. Which of the following can be used for session management of your application?'}, 'related_lectures': [], 'correct_response': ['d'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a company that is trying to reduce their storage costs for their application logs. They are storing all of their log files to an Amazon S3 bucket which they rarely access. There are third-party security audits every year which randomly check these files and require the company to make these files accessible within 24 hours upon request.What is the best and most cost-efficient solution to use in this scenario?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181170, 'original_assessment_id': 2567498, 'section': 'Glacier', 'prompt': {'explanation': '<p>In this scenario, you will need a storage option that is both low cost and at the same time, allows you to retrieve your data within 24 hours. Options 2 and 3 are valid answers here because&nbsp;Amazon Glacier and&nbsp; Amazon S3 Standard - Infrequent Access have a much lower price than the Standard S3 storage class.</p><p>However, Amazon Glacier is cheaper than the Infrequent Access and its standard retrievals typically complete within 3 &ndash; 5 hours which is sufficient enough for the 24-hour retrieval limit in the scenario. This is why option 2 is the correct answer.</p><p>&nbsp;</p><p>References:</p><p><a href="https://aws.amazon.com/glacier/faqs/">https://aws.amazon.com/glacier/faqs/</a></p><p>&nbsp;</p>', 'answers': ['Amazon S3 - Standard', 'Amazon Glacier', 'Amazon S3 Standard - Infrequent Access', 'Amazon S3 - Reduced Redundancy Storage'], 'question': 'You are working for a company that is trying to reduce their storage costs for their application logs. They are storing all of their log files to an Amazon S3 bucket which they rarely access. There are third-party security audits every year which randomly check these files and require the company to make these files accessible within 24 hours upon request.<br /><br />What is the best and most cost-efficient solution to use in this scenario?'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working for a startup that builds Internet of Things (IOT) devices and monitoring application. They are using IOT sensors to monitor all data by using Amazon Kinesis configured with default settings. You then send the data to an Amazon S3 bucket after 2 days. When you checked the data in S3, there are only data for the last day and nothing for the first day. What is the root cause of this issue?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181172, 'original_assessment_id': 2567500, 'section': 'Kinesis', 'prompt': {'explanation': '<p>By default, records of a stream in Amazon Kinesis are accessible for up to 24 hours from the time they are added to the stream. You can raise this limit to up to 7 days by enabling extended data retention.</p><p>&nbsp;</p><p>References:&nbsp;</p><p><a href="https://aws.amazon.com/kinesis/data-streams/faqs/">https://aws.amazon.com/kinesis/data-streams/faqs/</a></p><p>&nbsp;</p>', 'answers': ['Amazon S3 bucket has encountered a data loss.', 'Someone has manually deleted the record in Amazon S3.', 'By default, data records in Kinesis are only accessible for 24 hours from the time they are added to a stream.', 'The access of the Kinesis stream to the S3 bucket is insufficient.'], 'question': 'You are working for a startup that builds Internet of Things (IOT) devices and monitoring application. They are using IOT sensors to monitor all data by using Amazon Kinesis configured with default settings. You then send the data to an Amazon S3 bucket after 2 days. When you checked the data in S3, there are only data for the last day and nothing for the first day. <br /><br />What is the root cause of this issue?'}, 'related_lectures': [], 'correct_response': ['c'], 'updated': '2018-11-21T08:07:52Z'}, {'assessment_type': 'multiple-choice', 'question_plain': 'You are working as the Solutions Architect for a global technology consultancy firm which has an application that uses multiple EC2 instances located in various AWS regions such as US East (Ohio), US West (N. California), and EU (Ireland). Your manager instructed you to set up a latency-based routing to route incoming traffic for www.tutorialsdojo.com to all the EC2 instances across all AWS regions.\xa0 \xa0Which of the following options can satisfy the given requirement?', '_class': 'assessment', 'created': '2018-11-21T08:07:52Z', 'id': 6181174, 'original_assessment_id': 2567502, 'section': 'Route53', 'prompt': {'relatedLectureIds': '', 'feedbacks': ['', '', '', ''], 'answers': ['<p>Use a Network Load Balancer to distribute the load to the multiple EC2 instances across all AWS Regions.</p>', '<p>Use Route 53 to distribute the load to the multiple EC2 instances across all AWS Regions.</p>', '<p>Use an Application Load Balancer to distribute the load to the multiple EC2 instances across all AWS Regions.</p>', '<p>This is not possible in AWS. You can only set up a latency-based routing in one AWS region.</p>'], 'explanation': '<p>If your application is hosted in multiple AWS Regions, you can improve performance for your users by serving their requests from the AWS Region that provides the lowest latency.</p> <p>To use latency-based routing, you create latency records for your resources in multiple AWS Regions. When Route 53 receives a DNS query for your domain or subdomain (example.com or apex.example.com), it determines which AWS Regions you\'ve created latency records for, determines which region gives the user the lowest latency, and then selects a latency record for that region. Route 53 responds with the value from the selected record, such as the IP address for a web server.</p> <p>&nbsp;</p> <p><strong>References: </strong></p> <p><a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html#routing-policy-latency">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html#routing-policy-latency</a></p> <p><a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/TutorialAddingLBRRegion.html"> https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/TutorialAddingLBRRegion.html</a></p>', 'question': '<p>You are working as the Solutions Architect for a global technology consultancy firm which has an application that uses multiple EC2 instances located in various AWS regions such as US East (Ohio), US West (N. California), and EU (Ireland). Your manager instructed you to set up a latency-based routing to route incoming traffic for www.tutorialsdojo.com to all the EC2 instances across all AWS regions.\xa0 \xa0</p><p>Which of the following options can satisfy the given requirement?</p>'}, 'related_lectures': [], 'correct_response': ['b'], 'updated': '2018-11-21T08:07:52Z'}], 'previous': None, 'next': None}, 'title': 'AWS Certified Solutions Architect Associate Practice Test 6'}], 'chapter': 'Exercises', 'order': '0'}]
				// console.log(json)
				for (var i = 0; i < json_data.length; i++) {
					$('.list-group-flush').append(
						`<li class="list-group-item chapter-${json_data[i]['order']}" style="background-color:#ffffff00" ><a href='#' style="color:#ec6e6e">${json_data[i]['order']}&ensp;${json_data[i]['chapter']}</a><ul></ul></li>`
					)
					for (var j = 0; j < json_data[i]['quizzes'].length; j++) {
						$(`.chapter-${json_data[i]['order']} > ul`).append(
							`<li class="d-${i}-${j}"><a href="#" style="color:#ec6e6e">${json_data[i]['quizzes'][j]['title']}</a></li>`
						)
					}
				}


			$('.list-group-flush').on('click', 'li', function (event) {
				$('.container').empty()
				$(this).addClass('active')
				event.preventDefault();
				event.stopPropagation()
				var idRe = /d-(\d{1,3})-(\d{1,3})/
				id = idRe.exec($(this).attr("class"))
				quizzes_data = json_data[Number(id[1])]['quizzes'][Number(id[2])]


				if (quizzes_data['type'] === 'simple-quiz' || quizzes_data['type'] === 'practice-test') {
					

					for (var i = 0; i < quizzes_data['quiz_data']['count']; i++) {
						$('.container').append(
							`<div class="question-list-${i} mt-4"><span><b>Question&ensp;${i}</b></span><div>${quizzes_data['quiz_data']['results'][i]['prompt']['question']}</div><div class="funkyradio"></div><div class="text-center"><button class="btn btn-primary btn-sm" id="answerBtn-${i}">Show Answer</button></div></div>`
						)
						for (var j = 0; j < quizzes_data['quiz_data']['results'][i]['prompt']['answers'].length; j++) {
							$(`.question-list-${i} .funkyradio`).append(
								`<div class="funkyradio-primary"><input type="radio" name="radio" id="radio${i}${j}"/><label for="radio${i}${j}" class="px-5 mx-1">${quizzes_data['quiz_data']['results'][i]['prompt']['answers'][j]}</label></div>`
							)
						}
					}

					$('.text-center').on('click', 'button', function (event) {
						event.preventDefault();
						var idRe2 = /answerBtn-(\d+)/
						id2 = idRe2.exec($(this).attr('id'))[1]
						$(this).html(
							`Right answer is <span style="color:red;font-size:20px" class="px-1">&ensp;${quizzes_data['quiz_data']['results'][Number(id2)]['correct_response']}</span>`
						)
						$(this).attr('class', 'btn btn-success btn-sm disabled')
try {
							for (var k = 0; k < quizzes_data['quiz_data']['results'][Number(id2)]['prompt']['feedbacks'].length; k++) {
							$(`label[for="radio${Number(id2)}${k}"]`).append(`<p class="mb-0" style="color:teal">${quizzes_data['quiz_data']['results'][Number(id2)]['prompt']['feedbacks'][k]}</p>`)
							}
}
catch(err) {
console.log("This is no feedbacks in this question")
}
							if (quizzes_data['quiz_data']['results'][Number(id2)]['prompt']['explanation'] != undefined){

							$(this).parent().parent().append(`<div class='bg-light text-info mt-3'><p>Explanation</p>${quizzes_data['quiz_data']['results'][Number(id2)]['prompt']['explanation']}</div>`)
							}

						
					 });



				}  
				
				else if (quizzes_data['type'] === 'practice') {
          for (var i = 0; i < quizzes_data['practice_data']['results'].length; i++) {
            let key = i
            $('.container').append(`<div class="questionArea-${i}"><p>${quizzes_data['practice_data']['results'][i]['body']}</p><button class="btn btn-primary btn-sm answer-${i}">Show  Answer</button></div>`)

            $(`.questionArea-${i}`).on('click', `.answer-${i}`, function(event) {
              console.log('Not bad')
              event.preventDefault();
              $(this).parent().append(`<div class="mt-5 bg-light">${quizzes_data['practice_data']['results'][key]['answer']}</div>`)
            })


            
          }
        }

				else {
				for (var i = 0; i < quizzes_data['quiz_data']['results'].length; i++) {
            $('.container').append(`<div class="codingArea-${i}"><p>${quizzes_data['quiz_data']['results'][i]['prompt']['instructions']}</p><div class="preContent bg-light"><p>提示内容</p></div><button class="btn btn-primary answer-${i}">Show  Answer</button></div>`)
            for (var j = 0; j < quizzes_data['quiz_data']['results'][i]['prompt']["initial_files"].length; j++) {
              $(".preContent").append(`<p>文件名：${quizzes_data['quiz_data']['results'][i]['prompt']["initial_files"][j]['file_name']}</p><pre>${quizzes_data['quiz_data']['results'][i]['prompt']["initial_files"][j]["content"]}</pre>`)
            }

            $(`.codingArea-${i}`).on('click', `.answer-${i}`, function(event) {
              event.preventDefault();
              $(this).parent().append(`<div class="mt-5"><pre class="bg-light">${quizzes_data['quiz_data']['results'][0]['prompt']['solution_files'][0]['content']}</pre></div>`)

            });

          }


				}


			});
		});
	</script>
	<style type="text/css">
		.sidebar-sticky {
			height: 100%
		}

		.funkyradio div {
			clear: both;
			overflow: hidden;
		}

		.funkyradio label {
			width: 100%;
			border-radius: 3px;
			border: 1px solid #D1D3D4;
			font-weight: normal;
		}

		.funkyradio input[type="radio"]:empty,
		.funkyradio input[type="checkbox"]:empty {
			display: none;
		}

		.funkyradio input[type="radio"]:empty~label,
		.funkyradio input[type="checkbox"]:empty~label {
			position: relative;
			line-height: 2.5em;
			text-indent: 3.25em;
			margin-top: 1em;
			cursor: pointer;
			-webkit-user-select: none;
			-moz-user-select: none;
			-ms-user-select: none;
			user-select: none;
		}

		.funkyradio input[type="radio"]:empty~label:before,
		.funkyradio input[type="checkbox"]:empty~label:before {
			position: absolute;
			display: block;
			top: 0;
			bottom: 0;
			left: 0;
			content: '';
			width: 2.5em;
			background: #D1D3D4;
			border-radius: 3px 0 0 3px;
		}

		.funkyradio input[type="radio"]:hover:not(:checked)~label,
		.funkyradio input[type="checkbox"]:hover:not(:checked)~label {
			color: #888;
		}

		.funkyradio input[type="radio"]:hover:not(:checked)~label:before,
		.funkyradio input[type="checkbox"]:hover:not(:checked)~label:before {
			content: '\25B6';
			text-indent: .9em;
			color: #C2C2C2;
		}

		.funkyradio input[type="radio"]:checked~label,
		.funkyradio input[type="checkbox"]:checked~label {
			color: #777;
		}

		.funkyradio input[type="radio"]:checked~label:before,
		.funkyradio input[type="checkbox"]:checked~label:before {
			content: '\25B6';
			text-indent: .9em;
			color: #333;
			background-color: #ccc;
		}

		.funkyradio input[type="radio"]:focus~label:before,
		.funkyradio input[type="checkbox"]:focus~label:before {
			box-shadow: 0 0 0 3px #999;
		}

		.funkyradio-primary input[type="radio"]:checked~label:before,
		.funkyradio-primary input[type="checkbox"]:checked~label:before {
			color: #fff;
			background-color: #337ab7;
		}

		.funkyradio-success input[type="radio"]:checked~label:before,
		.funkyradio-success input[type="checkbox"]:checked~label:before {
			color: #fff;
			background-color: #5cb85c;
		}

		.funkyradio-danger input[type="radio"]:checked~label:before,
		.funkyradio-danger input[type="checkbox"]:checked~label:before {
			color: #fff;
			background-color: #d9534f;
		}
	</style>
</body>

</html>
